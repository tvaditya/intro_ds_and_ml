{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvaditya/intro_ds_and_ml/blob/main/Classifica%C3%A7%C3%A3o_bin%C3%A1ria_Cancer_de_mama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_RSER5Lkb5"
      },
      "source": [
        "# Projeto 1: Classificação binária: Câncer de mama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tP2BcEILoLB"
      },
      "source": [
        "## Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B1WlABbCcw2B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "b85d_o8BdFub",
        "outputId": "90c57674-cd15-4feb-c173-74abe8c3a833"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.10.0+cu111'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# !pip install torch==1.4.0\n",
        "\n",
        "import torch\n",
        "torch.__version__\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UVO3Mj3qdjru"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0SD4dJ4MDMN"
      },
      "source": [
        "## Etapa 2: Base de dados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i81g-4ADedrN",
        "outputId": "1268a5ea-8562-427d-a8fd-6451f95cf554"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa2c4af7a90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PjbIvUYwfBH8"
      },
      "outputs": [],
      "source": [
        "previsores = pd.read_csv('/content/entradas_breast.csv')\n",
        "classe = pd.read_csv('/content/saidas_breast.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFDDZfZTfOq5",
        "outputId": "94495005-6a31-4676-fe00-a65028c32883"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "previsores.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "rqiQvr3HfUc4",
        "outputId": "585ef30a-b539-497e-85b7-d6d980da62c0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-909abe34-65ea-424a-b674-0e076ab7a270\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave_points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave_points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave_points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1095.0000</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8589.0</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3398.0</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>186.0000</td>\n",
              "      <td>275.0000</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4585.0</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>243.0000</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1156.0000</td>\n",
              "      <td>3445.0</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>173.00000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>198.0000</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5438.0</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>205.0000</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-909abe34-65ea-424a-b674-0e076ab7a270')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-909abe34-65ea-424a-b674-0e076ab7a270 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-909abe34-65ea-424a-b674-0e076ab7a270');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    radius_mean   texture_mean  ...   symmetry_worst   fractal_dimension_worst\n",
              "0         17.99          10.38  ...           0.4601                   0.11890\n",
              "1         20.57          17.77  ...         275.0000                   0.08902\n",
              "2         19.69          21.25  ...           0.3613                   0.08758\n",
              "3         11.42          20.38  ...           0.6638                 173.00000\n",
              "4         20.29          14.34  ...           0.2364                   0.07678\n",
              "\n",
              "[5 rows x 30 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "previsores.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kKqSDj3bfdQB",
        "outputId": "380c8de2-0dbe-4cd1-cfea-1dd910cbbcf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-412e3519-2854-4da9-977f-487809a29632\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-412e3519-2854-4da9-977f-487809a29632')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-412e3519-2854-4da9-977f-487809a29632 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-412e3519-2854-4da9-977f-487809a29632');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   0\n",
              "0  0\n",
              "1  0\n",
              "2  0\n",
              "3  0\n",
              "4  0"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "classe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jSqJh18fhL1",
        "outputId": "a45c250a-9e6a-410b-f24d-9ed8c32b4ef2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.unique(classe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "aKLO9jX0fs-3",
        "outputId": "f4a0c3f3-b491-4614-e819-dea802f0d4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        " sns.countplot(classe['0']);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UX9ZDhUMgBsv"
      },
      "outputs": [],
      "source": [
        "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores,\n",
        "                                                                                              classe,\n",
        "                                                                                              test_size = 0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SEVQyX9gR4O",
        "outputId": "1c667654-e8c2-41f4-8e8a-c1fe0bc47ed4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(426, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "previsores_treinamento.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZA6wrOMygUmg",
        "outputId": "d8997d43-fd46-48af-aee7-b41266e849ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(426, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "classe_treinamento.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKyN_plmgZzH",
        "outputId": "61cfb77f-2678-49be-9348-98d1a9e5ffd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(143, 30)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "previsores_teste.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN_AXcfggdWC",
        "outputId": "7be2f0c0-a730-4fa9-b34a-c6fde4f320ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(143, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "classe_teste.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72uvlxJrOuWd"
      },
      "source": [
        "## Etapa 3: Transformação dos dados para tensores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nk5Gjgb7hBCo",
        "outputId": "d3dbda3a-dc2f-4666-aac5-2c1a04254943"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "type(previsores_treinamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIzWASyMhMmy",
        "outputId": "98c4b7f1-1bd0-4fa5-ec02-273d3b879a02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "type(np.array(previsores_treinamento))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hqPER9AYhTpt"
      },
      "outputs": [],
      "source": [
        "previsores_treinamento = torch.tensor(np.array(previsores_treinamento), dtype=torch.float)\n",
        "classe_treinamento = torch.tensor(np.array(classe_treinamento), dtype = torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-2HrvEJh5Km",
        "outputId": "ea0fc03f-9afe-4acf-bc25-3649da5213a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "\n",
        "type(previsores_treinamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqL8ypLSh79u",
        "outputId": "3d44be2a-d48c-47c3-a09b-fb7ca387f32e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\n",
        "type(classe_treinamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "__6a-iZhiJVI"
      },
      "outputs": [],
      "source": [
        "dataset = torch.utils.data.TensorDataset(previsores_treinamento, classe_treinamento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0sP_kvViZJl",
        "outputId": "7ead6587-0ee6-4adf-cffb-531904e8adda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.TensorDataset"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "type(dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "5dIWzA4wihKD"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGDLesyDQpIb"
      },
      "source": [
        "## Etapa 4: Construção do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "1FAFgY56jmdG"
      },
      "outputs": [],
      "source": [
        " # 30 -> 16 -> 16 -> 1\n",
        "# (entradas + saida) / 2 = (30 + 1) / 2 = 16\n",
        "classificador = nn.Sequential(\n",
        "    nn.Linear(in_features=30, out_features=16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixwI_mhZlDVW",
        "outputId": "52b3447e-91ec-4535-c597-2d7e360d1cc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method Module.parameters of Sequential(\n",
              "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "classificador.parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "--bNcvlplMh9"
      },
      "outputs": [],
      "source": [
        "criterion = nn.BCELoss() #Binary Cross Entropy Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "Um6Tr3s_lXHK"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.Adam(classificador.parameters(), lr=0.001, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appMwDHtRTN5"
      },
      "source": [
        "## Etapa 5: Treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exieZFSam_eI",
        "outputId": "128009f5-b553-4959-baeb-a8e75e686976"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época   1: perda 10.78336\n",
            "Época   2: perda 2.84863\n",
            "Época   3: perda 1.67480\n",
            "Época   4: perda 1.11414\n",
            "Época   5: perda 0.63996\n",
            "Época   6: perda 0.63753\n",
            "Época   7: perda 0.58066\n",
            "Época   8: perda 0.55460\n",
            "Época   9: perda 0.55617\n",
            "Época  10: perda 0.53322\n",
            "Época  11: perda 0.55797\n",
            "Época  12: perda 0.53816\n",
            "Época  13: perda 0.52938\n",
            "Época  14: perda 0.33227\n",
            "Época  15: perda 0.51360\n",
            "Época  16: perda 0.35532\n",
            "Época  17: perda 0.49602\n",
            "Época  18: perda 0.33208\n",
            "Época  19: perda 0.29349\n",
            "Época  20: perda 0.25046\n",
            "Época  21: perda 0.29527\n",
            "Época  22: perda 0.49888\n",
            "Época  23: perda 0.47241\n",
            "Época  24: perda 0.45883\n",
            "Época  25: perda 0.27544\n",
            "Época  26: perda 0.23399\n",
            "Época  27: perda 0.26373\n",
            "Época  28: perda 0.24136\n",
            "Época  29: perda 0.28275\n",
            "Época  30: perda 0.22633\n",
            "Época  31: perda 0.19294\n",
            "Época  32: perda 0.22258\n",
            "Época  33: perda 0.20290\n",
            "Época  34: perda 0.20888\n",
            "Época  35: perda 0.20335\n",
            "Época  36: perda 0.20316\n",
            "Época  37: perda 0.18855\n",
            "Época  38: perda 0.22316\n",
            "Época  39: perda 0.23315\n",
            "Época  40: perda 0.19261\n",
            "Época  41: perda 0.17163\n",
            "Época  42: perda 0.18287\n",
            "Época  43: perda 0.17056\n",
            "Época  44: perda 0.16674\n",
            "Época  45: perda 0.18515\n",
            "Época  46: perda 0.22250\n",
            "Época  47: perda 0.17558\n",
            "Época  48: perda 0.22754\n",
            "Época  49: perda 0.19833\n",
            "Época  50: perda 0.16371\n",
            "Época  51: perda 0.16855\n",
            "Época  52: perda 0.18337\n",
            "Época  53: perda 0.17593\n",
            "Época  54: perda 0.17882\n",
            "Época  55: perda 0.18470\n",
            "Época  56: perda 0.17073\n",
            "Época  57: perda 0.15674\n",
            "Época  58: perda 0.18435\n",
            "Época  59: perda 0.14023\n",
            "Época  60: perda 0.15765\n",
            "Época  61: perda 0.16521\n",
            "Época  62: perda 0.15513\n",
            "Época  63: perda 0.13765\n",
            "Época  64: perda 0.14962\n",
            "Época  65: perda 0.15919\n",
            "Época  66: perda 0.23974\n",
            "Época  67: perda 0.16218\n",
            "Época  68: perda 0.15015\n",
            "Época  69: perda 0.15990\n",
            "Época  70: perda 0.18359\n",
            "Época  71: perda 0.14650\n",
            "Época  72: perda 0.16269\n",
            "Época  73: perda 0.12191\n",
            "Época  74: perda 0.13901\n",
            "Época  75: perda 0.13926\n",
            "Época  76: perda 0.13105\n",
            "Época  77: perda 0.12779\n",
            "Época  78: perda 0.14741\n",
            "Época  79: perda 0.20884\n",
            "Época  80: perda 0.20729\n",
            "Época  81: perda 0.22643\n",
            "Época  82: perda 0.16890\n",
            "Época  83: perda 0.11829\n",
            "Época  84: perda 0.12809\n",
            "Época  85: perda 0.12544\n",
            "Época  86: perda 0.12474\n",
            "Época  87: perda 0.15365\n",
            "Época  88: perda 0.11945\n",
            "Época  89: perda 0.15052\n",
            "Época  90: perda 0.12977\n",
            "Época  91: perda 0.16607\n",
            "Época  92: perda 0.14753\n",
            "Época  93: perda 0.09912\n",
            "Época  94: perda 0.13184\n",
            "Época  95: perda 0.10702\n",
            "Época  96: perda 0.12766\n",
            "Época  97: perda 0.12817\n",
            "Época  98: perda 0.12291\n",
            "Época  99: perda 0.13988\n",
            "Época 100: perda 0.13753\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(100):\n",
        "  running_loss = 0.\n",
        "\n",
        "  for data in train_loader:\n",
        "    inputs, labels = data\n",
        "    #print(inputs)\n",
        "    #print('-----')\n",
        "    #print(labels)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = classificador(inputs) # classificador.forward(inputs)\n",
        "    #print(outputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  print('Época %3d: perda %.5f' % (epoch+1, running_loss/len(train_loader)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITUtUdQNSJcs"
      },
      "source": [
        "## Etapa 6: Visualização dos pesos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "p0E2vbaGreGc"
      },
      "outputs": [],
      "source": [
        "# 30 -> 16 -> 16 -> 1\n",
        "params = list(classificador.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2sFTNaMroyw",
        "outputId": "be56c404-14c6-49e4-a2aa-183c0dd1ea47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-6.8758e-02, -4.5974e-02, -1.6881e-01,  5.1889e-02, -1.5407e-01,\n",
              "           9.6941e-02, -1.3697e-01, -1.2676e-01, -2.2155e-01,  1.6481e-01,\n",
              "          -3.7779e-02,  5.3912e-02, -1.2468e-01, -1.1436e-01, -1.3912e-03,\n",
              "          -2.1398e-01, -3.9141e-01,  6.5978e-04, -6.6723e-03,  1.4566e-03,\n",
              "           1.4102e-01, -2.0637e-02, -2.8877e-02,  1.4110e-01,  4.9312e-01,\n",
              "           1.3069e-01, -1.8659e-01,  4.4318e-02,  2.9165e-01,  3.7982e-02],\n",
              "         [ 1.9542e-01,  2.0732e-01,  2.8639e-01,  9.7069e-02, -1.3307e-01,\n",
              "          -8.0457e-02, -6.7914e-02, -1.2084e-01, -2.8640e-02,  2.6983e-01,\n",
              "          -6.2204e-02, -9.1055e-02, -7.9371e-03,  1.6734e-01, -7.2613e-03,\n",
              "          -9.6179e-02, -1.1189e-02,  1.8739e-01,  1.0368e-01, -1.7496e-02,\n",
              "           9.8523e-02,  6.1815e-02,  1.8995e-01,  7.5789e-03, -1.5083e-02,\n",
              "          -2.4596e-01, -1.7552e-01, -7.0061e-03, -6.5762e-02, -1.6863e-01],\n",
              "         [-1.2082e-02, -4.2609e-02, -2.4278e-01, -1.0345e-01, -8.2591e-03,\n",
              "           4.9597e-02,  3.7827e-02,  1.9156e-02, -9.8577e-02,  2.8402e-01,\n",
              "           1.5881e-01,  9.2320e-02, -1.0323e-01,  5.5662e-02, -5.5894e-04,\n",
              "          -2.9179e-01,  2.8243e-02,  9.0303e-04,  3.8270e-01, -1.5171e-04,\n",
              "           3.7270e-02, -1.8036e-01, -7.5384e-02,  9.8725e-04, -2.4923e-01,\n",
              "          -1.3240e-01, -1.7683e-01,  9.9595e-02,  2.3637e-02, -9.4252e-03],\n",
              "         [-3.6936e-01,  4.9446e-02, -1.5071e-01,  8.9715e-02, -1.7998e-01,\n",
              "          -3.6083e-02,  1.9950e-02,  6.2705e-02,  1.3708e-01, -2.3545e-01,\n",
              "           1.9331e-01, -1.5150e-01,  3.6820e-02,  1.3893e-02,  6.8357e-04,\n",
              "           5.1560e-02,  2.2120e-02, -1.9164e-02,  1.2596e-01,  6.0075e-03,\n",
              "           5.9529e-02, -1.5046e-01, -7.3884e-02,  1.4546e-02,  2.3399e-01,\n",
              "           9.5019e-02,  1.8605e-02,  2.4927e-01,  1.1270e-01,  3.9505e-01],\n",
              "         [-4.3557e-01, -4.4699e-02, -1.3858e-01, -1.3687e-01,  3.7306e-01,\n",
              "           3.5150e-02,  1.2817e-01, -3.1172e-01, -2.8485e-01,  2.2854e-01,\n",
              "          -1.7721e-01,  2.7300e-02, -1.6225e-02,  7.1856e-02,  4.3100e-02,\n",
              "          -3.4611e-01, -2.9974e-01, -2.3152e-01,  3.4410e-01,  2.3291e-01,\n",
              "          -2.9773e-01, -1.5884e-02, -1.7189e-01,  2.4209e-01, -1.2164e-02,\n",
              "          -7.7208e-02, -4.3515e-01, -1.1875e-01,  4.3487e-03,  5.0240e-01],\n",
              "         [ 3.0821e-02, -1.6578e-02,  1.1280e-01,  1.1192e-01,  5.8246e-02,\n",
              "           4.1913e-01, -5.3476e-02,  3.1163e-01,  2.2077e-01, -8.7384e-02,\n",
              "           1.5078e-01,  1.5398e-01, -1.0899e-01,  1.3198e-01, -2.7945e-03,\n",
              "           3.3207e-01,  1.8711e-01,  9.3625e-02, -2.2259e-01, -8.4005e-02,\n",
              "           2.8864e-02, -1.8328e-01,  3.8867e-02, -1.9581e-02, -1.9910e-01,\n",
              "          -1.1596e-02, -1.0407e-01,  2.6339e-01,  7.0347e-02, -2.5760e-01],\n",
              "         [-4.7504e-03,  2.3343e-02,  3.0091e-01, -1.1799e-01, -2.3138e-01,\n",
              "          -5.2386e-01, -1.7130e-02, -2.7054e-02,  2.3587e-01,  2.1960e-02,\n",
              "          -1.0893e-01, -2.3921e-01,  6.0422e-02,  5.4633e-02, -3.5509e-03,\n",
              "          -2.5552e-02,  7.9274e-02, -7.9093e-03,  3.0467e-01, -6.0303e-03,\n",
              "           1.0205e-02, -6.7911e-02,  1.9984e-01, -9.9251e-02, -2.8998e-01,\n",
              "           1.2194e-01,  2.1211e-01, -2.0562e-01, -2.5774e-01,  5.1543e-02],\n",
              "         [-2.8418e-01, -7.8714e-03, -1.3239e-01, -1.6743e-01,  3.4173e-01,\n",
              "          -4.4088e-02, -1.3729e-02, -1.8614e-02, -3.7049e-02, -4.7244e-02,\n",
              "          -8.8618e-02, -1.1590e-01,  6.8536e-02,  1.0416e-01,  4.3278e-03,\n",
              "           2.1902e-02, -1.0861e-01,  1.3687e-02, -2.8336e-01,  8.5776e-03,\n",
              "          -2.0611e-01,  9.0369e-02, -2.8925e-01,  1.0000e-01, -4.7419e-02,\n",
              "          -3.0239e-01,  3.3852e-02,  1.4056e-01, -3.9899e-02,  5.4125e-02],\n",
              "         [ 8.5856e-02, -1.6411e-01, -3.8629e-01, -4.0786e-02,  3.7577e-01,\n",
              "           1.3859e-01, -3.9488e-01, -9.2736e-02,  1.1091e-01,  1.9993e-01,\n",
              "           1.6835e-01, -3.0083e-02,  1.1013e-01,  1.0779e-01,  7.5948e-03,\n",
              "          -1.5654e-01,  8.1483e-03, -2.8046e-01,  3.7360e-01, -2.0762e-02,\n",
              "          -2.5369e-01, -5.5042e-02, -3.0013e-01,  2.0517e-01, -1.9019e-02,\n",
              "           1.8753e-01, -7.5869e-02,  1.9512e-01,  9.9419e-02,  2.6386e-01],\n",
              "         [-2.5630e-02,  1.4752e-01,  2.8781e-01,  1.2559e-02, -3.2981e-01,\n",
              "          -1.2364e-01, -7.6542e-02,  1.6670e-01,  5.1938e-02,  1.1205e-01,\n",
              "           1.1327e-01, -1.7646e-01,  1.5192e-01, -1.7099e-01, -1.0401e-02,\n",
              "           2.4548e-02,  1.6948e-01,  1.2621e-01,  1.3625e-01, -1.9759e-01,\n",
              "           1.8699e-01, -1.4237e-01,  3.1062e-01, -7.8164e-02,  1.3725e-01,\n",
              "           9.0337e-03,  1.7212e-03, -8.4802e-02,  9.8053e-02, -1.4832e-01],\n",
              "         [-1.4014e-01, -5.6345e-02,  4.2161e-02,  2.3259e-02, -4.9597e-02,\n",
              "          -9.0061e-02, -1.4940e-01, -1.2599e-01,  2.6111e-01,  5.4235e-02,\n",
              "          -1.2114e-01,  5.5599e-02, -1.1246e-01,  1.7389e-01, -2.1837e-03,\n",
              "          -9.9499e-02, -7.0865e-02, -3.4323e-01, -1.7855e-01,  1.7811e-03,\n",
              "          -2.0458e-01, -1.0200e-01,  4.9655e-02,  1.2549e-01,  3.1910e-01,\n",
              "          -1.6357e-01,  3.1755e-01,  2.1876e-01, -1.2922e-01, -2.8016e-02],\n",
              "         [ 6.7762e-02, -1.6538e-02,  1.1783e-01,  1.3570e-01, -5.1763e-02,\n",
              "           2.3318e-01, -1.0425e-01,  2.5288e-01,  1.9977e-01, -9.4546e-02,\n",
              "           4.0562e-03,  9.2027e-02, -1.7273e-02, -3.2931e-01, -1.4668e-02,\n",
              "           3.7461e-01,  2.0964e-03,  3.3210e-01, -1.9388e-01, -1.7987e-01,\n",
              "           2.0306e-01, -4.8392e-02,  2.9248e-01, -1.4335e-01, -2.2953e-01,\n",
              "           1.9208e-01,  4.4103e-02,  8.2241e-02,  1.4347e-01, -4.5820e-01],\n",
              "         [ 1.1821e-01,  5.7466e-02, -2.5654e-01, -5.6209e-02,  1.4862e-01,\n",
              "           2.0140e-01,  2.7292e-01,  2.7956e-02, -9.0503e-02, -2.5079e-01,\n",
              "           1.2432e-01, -4.3815e-02,  1.0919e-01,  6.9885e-02, -3.5241e-03,\n",
              "          -4.9244e-02,  3.0922e-03,  2.2875e-02, -2.8040e-01,  1.5266e-01,\n",
              "           6.1663e-02,  1.4810e-01, -2.5095e-02,  4.3756e-02, -4.3097e-02,\n",
              "           1.0931e-01,  2.2541e-02, -2.6103e-01,  7.5664e-02,  1.1719e-01],\n",
              "         [ 8.9904e-02, -1.1065e-01, -1.0539e-01,  2.0717e-02,  6.2355e-02,\n",
              "           1.0249e-02, -1.2570e-01,  7.4305e-02, -4.1034e-02, -1.8381e-01,\n",
              "           1.8162e-01, -8.9867e-02, -1.6678e-01,  1.6748e-01,  5.0678e-03,\n",
              "           1.6544e-02,  1.5902e-01, -1.1872e-01,  4.1115e-01,  6.3081e-03,\n",
              "           1.2233e-01, -2.8966e-02, -8.4761e-02,  1.5564e-01, -2.3602e-02,\n",
              "          -2.3686e-01, -6.8182e-02,  1.0181e-01,  1.1609e-01,  2.4330e-02],\n",
              "         [ 5.7720e-02, -2.3591e-02,  4.5249e-02, -1.2951e-01, -1.8455e-16,\n",
              "          -6.3272e-13,  7.3982e-11, -9.7318e-40, -2.5950e-02,  2.1700e-23,\n",
              "          -6.8727e-05, -2.1424e-02, -2.5863e-02, -3.5407e-02,  2.0858e-39,\n",
              "           1.5876e-39, -1.5474e-02, -1.0430e-39,  2.1490e-39, -1.3229e-40,\n",
              "           7.1263e-02,  8.6057e-02, -1.0550e-01, -1.7020e-01, -8.6160e-13,\n",
              "          -7.3700e-04,  2.7531e-06, -2.9554e-20, -1.4369e-06, -4.0315e-18],\n",
              "         [ 5.3569e-39,  9.5109e-40, -3.2673e-39,  2.9163e-39, -3.7278e-39,\n",
              "           6.0502e-39,  4.5806e-39,  4.3560e-39,  3.9955e-39, -4.6621e-39,\n",
              "           1.0964e-39, -2.7346e-12, -7.1512e-09, -4.9207e-39,  2.2374e-39,\n",
              "          -4.7572e-38, -2.3219e-39,  3.6393e-39,  3.3310e-39,  4.4581e-41,\n",
              "          -1.8839e-40, -1.0213e-39,  3.6990e-39, -1.2359e-27, -3.4976e-40,\n",
              "           5.3474e-42,  3.0349e-40,  6.3292e-39, -4.2911e-39, -6.4905e-39]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-1.4600e-01,  2.5992e-01, -2.4396e-01, -2.4689e-01, -7.8148e-01,\n",
              "          1.9811e-01,  1.7916e-01, -2.7091e-01, -3.7150e-01,  4.3308e-01,\n",
              "         -2.8282e-01,  4.1587e-01, -2.8888e-01, -4.7781e-02, -1.1200e-03,\n",
              "         -4.3940e-39], requires_grad=True), Parameter containing:\n",
              " tensor([[-1.8817e-02, -2.5119e-02, -1.4728e-02,  4.1630e-02, -8.0131e-03,\n",
              "          -1.8645e-03, -1.8664e-02,  5.6236e-39, -1.5539e-01, -1.8350e-01,\n",
              "          -2.0228e-01,  5.7261e-02,  1.6629e-01,  2.1726e-01,  3.4539e-02,\n",
              "          -2.1995e-39],\n",
              "         [ 3.6016e-02, -1.6548e-01,  6.1439e-02,  3.2403e-03,  2.4334e-02,\n",
              "           1.3656e-01,  5.4474e-39, -1.0806e-39,  8.2869e-03, -2.5236e-01,\n",
              "          -4.9484e-02, -5.4535e-02, -1.7171e-01,  2.3478e-01,  2.2949e-39,\n",
              "           5.6732e-39],\n",
              "         [ 2.4004e-01, -4.4722e-02,  1.4993e-01,  1.5460e-01,  3.6686e-01,\n",
              "          -1.0214e-01, -4.6205e-02, -7.8649e-02,  2.3791e-01,  5.0054e-02,\n",
              "          -4.3466e-04, -4.4574e-03,  2.2135e-01,  9.2165e-02,  6.6199e-02,\n",
              "          -7.1820e-03],\n",
              "         [-1.0895e-01,  7.9534e-02,  4.7395e-02, -2.0077e-01, -4.8053e-02,\n",
              "           5.5593e-02,  3.0290e-02, -6.2191e-02,  1.9659e-01,  8.5788e-02,\n",
              "          -3.0686e-01,  2.8669e-01,  1.6382e-01,  1.3542e-01,  9.9777e-02,\n",
              "           1.0746e-02],\n",
              "         [ 9.8536e-02, -3.4721e-03, -3.9680e-04, -2.6002e-01,  8.0582e-02,\n",
              "          -4.2798e-01,  1.1478e-01,  2.4934e-01,  3.7852e-02,  6.1207e-03,\n",
              "          -2.1695e-01,  1.1242e-01, -6.8965e-02, -7.9919e-02, -8.5177e-02,\n",
              "          -2.6790e-27],\n",
              "         [ 1.0332e-01, -4.3266e-02, -1.6671e-03, -1.6011e-01, -8.5809e-02,\n",
              "           6.0449e-02, -1.0533e-39,  1.0492e-39, -8.2694e-02, -1.0738e-01,\n",
              "          -1.0291e-01,  1.3061e-01, -1.8304e-01,  9.5021e-02,  2.9119e-04,\n",
              "          -2.3312e-39],\n",
              "         [-1.2618e-01, -4.1482e-02,  4.7272e-02, -8.9598e-03,  1.6915e-01,\n",
              "           1.5255e-01,  4.7636e-02, -1.2492e-01, -1.3816e-01, -2.0445e-01,\n",
              "           9.4767e-02,  1.2160e-02,  2.1189e-01,  2.3190e-01,  5.2271e-02,\n",
              "          -6.0353e-09],\n",
              "         [ 1.0869e-01, -2.5308e-02, -1.3754e-01, -7.9418e-02, -3.0541e-01,\n",
              "           1.2617e-01, -1.5992e-01, -1.6563e-01, -6.5963e-02,  1.3828e-01,\n",
              "           7.1923e-02,  6.2354e-02, -8.8369e-02, -1.5912e-01,  1.5951e-39,\n",
              "          -3.3255e-39],\n",
              "         [-1.2485e-01,  1.8243e-01, -1.6815e-01, -1.0232e-01,  1.7642e-01,\n",
              "           1.2671e-01,  1.3458e-01,  1.2376e-01, -8.2408e-02, -1.4126e-01,\n",
              "           7.7001e-02,  9.1588e-02, -5.5340e-02,  1.9664e-01, -1.1642e-01,\n",
              "           7.2274e-10],\n",
              "         [ 1.8906e-01,  1.1816e-01, -1.3947e-01,  9.2710e-02, -1.2201e-01,\n",
              "           5.9580e-02,  1.8520e-01, -2.2712e-01, -1.1827e-01,  2.0249e-01,\n",
              "          -2.1515e-01, -4.0119e-02, -9.4016e-02, -4.5428e-02,  1.0530e-02,\n",
              "          -9.9433e-03],\n",
              "         [ 7.1015e-02, -8.4643e-02, -6.3932e-02, -4.4491e-01, -3.5356e-01,\n",
              "          -1.9279e-03,  5.5981e-03, -2.6181e-02, -3.8081e-02, -5.1243e-02,\n",
              "           1.8403e-01, -3.6414e-02,  1.9830e-01,  1.4145e-01,  2.2407e-02,\n",
              "           1.5376e-03],\n",
              "         [ 1.1146e-01, -4.0191e-02, -1.7404e-01,  1.1071e-01, -3.6449e-02,\n",
              "           1.7326e-01, -2.0028e-39, -6.1932e-39, -2.7512e-01, -6.2609e-02,\n",
              "          -7.2098e-02,  1.5652e-01, -1.1996e-01, -2.2147e-01,  4.9138e-03,\n",
              "           1.4607e-39],\n",
              "         [ 9.3391e-02, -7.7993e-02,  7.6330e-02, -1.5228e-01, -8.9684e-02,\n",
              "          -4.0081e-01,  6.9792e-02,  4.9319e-02,  1.8446e-01, -5.3876e-02,\n",
              "           1.4730e-01,  1.3491e-01,  5.2164e-02, -1.4861e-01, -1.0636e-02,\n",
              "          -2.8871e-03],\n",
              "         [-1.3474e-01,  2.4349e-01,  6.0637e-02, -7.5726e-02, -1.8255e-01,\n",
              "           6.5965e-02, -1.5861e-01,  1.0885e-01, -1.1090e-01,  3.0289e-02,\n",
              "           3.9259e-02,  9.9004e-02, -3.8883e-02,  3.4992e-02, -7.2727e-02,\n",
              "           2.2381e-38],\n",
              "         [-5.2033e-03,  2.2353e-01,  6.1868e-02, -4.7569e-02, -1.1992e-01,\n",
              "          -5.7046e-02, -1.5012e-01, -2.5660e-02, -2.0844e-01,  1.2004e-01,\n",
              "           1.7537e-01,  2.7139e-02, -1.5402e-01, -2.0282e-01, -5.2240e-39,\n",
              "          -1.8276e-39],\n",
              "         [-1.7458e-02, -4.0691e-03,  1.1293e-02, -8.5153e-03,  5.1473e-03,\n",
              "          -1.0837e-03, -7.0239e-03, -1.1294e-02, -5.0175e-02, -4.8400e-02,\n",
              "          -1.6497e-02, -2.3168e-03, -5.8774e-02, -5.9931e-03, -5.0867e-39,\n",
              "          -2.7407e-39]], requires_grad=True), Parameter containing:\n",
              " tensor([-5.8659e-02, -2.6388e-01, -8.4171e-01,  5.2504e-01, -2.6894e-01,\n",
              "         -1.5931e-01, -1.2184e-01, -1.0973e-01,  1.0272e-01,  5.8468e-01,\n",
              "          3.5140e-01,  3.7946e-02, -5.7485e-01,  4.2154e-01,  2.1834e-01,\n",
              "          3.0161e-05], requires_grad=True), Parameter containing:\n",
              " tensor([[-0.1064, -0.1002, -0.1056,  0.1413, -0.0110, -0.0178, -0.1370, -0.0082,\n",
              "           0.1397,  0.2351,  0.1348,  0.1612, -0.0613,  0.1970,  0.0773, -0.0110]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([0.7395], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaU6bV7lrusK",
        "outputId": "65a5554d-35b4-4312-ddec-7242d21820d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# 30 -> 16 -> 16 -> 1\n",
        "pesos0 = params[0]\n",
        "pesos0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRIKPKKgr94O",
        "outputId": "b1076429-4514-4c29-e336-a44ef994eb00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-6.8758e-02, -4.5974e-02, -1.6881e-01,  5.1889e-02, -1.5407e-01,\n",
            "          9.6941e-02, -1.3697e-01, -1.2676e-01, -2.2155e-01,  1.6481e-01,\n",
            "         -3.7779e-02,  5.3912e-02, -1.2468e-01, -1.1436e-01, -1.3912e-03,\n",
            "         -2.1398e-01, -3.9141e-01,  6.5978e-04, -6.6723e-03,  1.4566e-03,\n",
            "          1.4102e-01, -2.0637e-02, -2.8877e-02,  1.4110e-01,  4.9312e-01,\n",
            "          1.3069e-01, -1.8659e-01,  4.4318e-02,  2.9165e-01,  3.7982e-02],\n",
            "        [ 1.9542e-01,  2.0732e-01,  2.8639e-01,  9.7069e-02, -1.3307e-01,\n",
            "         -8.0457e-02, -6.7914e-02, -1.2084e-01, -2.8640e-02,  2.6983e-01,\n",
            "         -6.2204e-02, -9.1055e-02, -7.9371e-03,  1.6734e-01, -7.2613e-03,\n",
            "         -9.6179e-02, -1.1189e-02,  1.8739e-01,  1.0368e-01, -1.7496e-02,\n",
            "          9.8523e-02,  6.1815e-02,  1.8995e-01,  7.5789e-03, -1.5083e-02,\n",
            "         -2.4596e-01, -1.7552e-01, -7.0061e-03, -6.5762e-02, -1.6863e-01],\n",
            "        [-1.2082e-02, -4.2609e-02, -2.4278e-01, -1.0345e-01, -8.2591e-03,\n",
            "          4.9597e-02,  3.7827e-02,  1.9156e-02, -9.8577e-02,  2.8402e-01,\n",
            "          1.5881e-01,  9.2320e-02, -1.0323e-01,  5.5662e-02, -5.5894e-04,\n",
            "         -2.9179e-01,  2.8243e-02,  9.0303e-04,  3.8270e-01, -1.5171e-04,\n",
            "          3.7270e-02, -1.8036e-01, -7.5384e-02,  9.8725e-04, -2.4923e-01,\n",
            "         -1.3240e-01, -1.7683e-01,  9.9595e-02,  2.3637e-02, -9.4252e-03],\n",
            "        [-3.6936e-01,  4.9446e-02, -1.5071e-01,  8.9715e-02, -1.7998e-01,\n",
            "         -3.6083e-02,  1.9950e-02,  6.2705e-02,  1.3708e-01, -2.3545e-01,\n",
            "          1.9331e-01, -1.5150e-01,  3.6820e-02,  1.3893e-02,  6.8357e-04,\n",
            "          5.1560e-02,  2.2120e-02, -1.9164e-02,  1.2596e-01,  6.0075e-03,\n",
            "          5.9529e-02, -1.5046e-01, -7.3884e-02,  1.4546e-02,  2.3399e-01,\n",
            "          9.5019e-02,  1.8605e-02,  2.4927e-01,  1.1270e-01,  3.9505e-01],\n",
            "        [-4.3557e-01, -4.4699e-02, -1.3858e-01, -1.3687e-01,  3.7306e-01,\n",
            "          3.5150e-02,  1.2817e-01, -3.1172e-01, -2.8485e-01,  2.2854e-01,\n",
            "         -1.7721e-01,  2.7300e-02, -1.6225e-02,  7.1856e-02,  4.3100e-02,\n",
            "         -3.4611e-01, -2.9974e-01, -2.3152e-01,  3.4410e-01,  2.3291e-01,\n",
            "         -2.9773e-01, -1.5884e-02, -1.7189e-01,  2.4209e-01, -1.2164e-02,\n",
            "         -7.7208e-02, -4.3515e-01, -1.1875e-01,  4.3487e-03,  5.0240e-01],\n",
            "        [ 3.0821e-02, -1.6578e-02,  1.1280e-01,  1.1192e-01,  5.8246e-02,\n",
            "          4.1913e-01, -5.3476e-02,  3.1163e-01,  2.2077e-01, -8.7384e-02,\n",
            "          1.5078e-01,  1.5398e-01, -1.0899e-01,  1.3198e-01, -2.7945e-03,\n",
            "          3.3207e-01,  1.8711e-01,  9.3625e-02, -2.2259e-01, -8.4005e-02,\n",
            "          2.8864e-02, -1.8328e-01,  3.8867e-02, -1.9581e-02, -1.9910e-01,\n",
            "         -1.1596e-02, -1.0407e-01,  2.6339e-01,  7.0347e-02, -2.5760e-01],\n",
            "        [-4.7504e-03,  2.3343e-02,  3.0091e-01, -1.1799e-01, -2.3138e-01,\n",
            "         -5.2386e-01, -1.7130e-02, -2.7054e-02,  2.3587e-01,  2.1960e-02,\n",
            "         -1.0893e-01, -2.3921e-01,  6.0422e-02,  5.4633e-02, -3.5509e-03,\n",
            "         -2.5552e-02,  7.9274e-02, -7.9093e-03,  3.0467e-01, -6.0303e-03,\n",
            "          1.0205e-02, -6.7911e-02,  1.9984e-01, -9.9251e-02, -2.8998e-01,\n",
            "          1.2194e-01,  2.1211e-01, -2.0562e-01, -2.5774e-01,  5.1543e-02],\n",
            "        [-2.8418e-01, -7.8714e-03, -1.3239e-01, -1.6743e-01,  3.4173e-01,\n",
            "         -4.4088e-02, -1.3729e-02, -1.8614e-02, -3.7049e-02, -4.7244e-02,\n",
            "         -8.8618e-02, -1.1590e-01,  6.8536e-02,  1.0416e-01,  4.3278e-03,\n",
            "          2.1902e-02, -1.0861e-01,  1.3687e-02, -2.8336e-01,  8.5776e-03,\n",
            "         -2.0611e-01,  9.0369e-02, -2.8925e-01,  1.0000e-01, -4.7419e-02,\n",
            "         -3.0239e-01,  3.3852e-02,  1.4056e-01, -3.9899e-02,  5.4125e-02],\n",
            "        [ 8.5856e-02, -1.6411e-01, -3.8629e-01, -4.0786e-02,  3.7577e-01,\n",
            "          1.3859e-01, -3.9488e-01, -9.2736e-02,  1.1091e-01,  1.9993e-01,\n",
            "          1.6835e-01, -3.0083e-02,  1.1013e-01,  1.0779e-01,  7.5948e-03,\n",
            "         -1.5654e-01,  8.1483e-03, -2.8046e-01,  3.7360e-01, -2.0762e-02,\n",
            "         -2.5369e-01, -5.5042e-02, -3.0013e-01,  2.0517e-01, -1.9019e-02,\n",
            "          1.8753e-01, -7.5869e-02,  1.9512e-01,  9.9419e-02,  2.6386e-01],\n",
            "        [-2.5630e-02,  1.4752e-01,  2.8781e-01,  1.2559e-02, -3.2981e-01,\n",
            "         -1.2364e-01, -7.6542e-02,  1.6670e-01,  5.1938e-02,  1.1205e-01,\n",
            "          1.1327e-01, -1.7646e-01,  1.5192e-01, -1.7099e-01, -1.0401e-02,\n",
            "          2.4548e-02,  1.6948e-01,  1.2621e-01,  1.3625e-01, -1.9759e-01,\n",
            "          1.8699e-01, -1.4237e-01,  3.1062e-01, -7.8164e-02,  1.3725e-01,\n",
            "          9.0337e-03,  1.7212e-03, -8.4802e-02,  9.8053e-02, -1.4832e-01],\n",
            "        [-1.4014e-01, -5.6345e-02,  4.2161e-02,  2.3259e-02, -4.9597e-02,\n",
            "         -9.0061e-02, -1.4940e-01, -1.2599e-01,  2.6111e-01,  5.4235e-02,\n",
            "         -1.2114e-01,  5.5599e-02, -1.1246e-01,  1.7389e-01, -2.1837e-03,\n",
            "         -9.9499e-02, -7.0865e-02, -3.4323e-01, -1.7855e-01,  1.7811e-03,\n",
            "         -2.0458e-01, -1.0200e-01,  4.9655e-02,  1.2549e-01,  3.1910e-01,\n",
            "         -1.6357e-01,  3.1755e-01,  2.1876e-01, -1.2922e-01, -2.8016e-02],\n",
            "        [ 6.7762e-02, -1.6538e-02,  1.1783e-01,  1.3570e-01, -5.1763e-02,\n",
            "          2.3318e-01, -1.0425e-01,  2.5288e-01,  1.9977e-01, -9.4546e-02,\n",
            "          4.0562e-03,  9.2027e-02, -1.7273e-02, -3.2931e-01, -1.4668e-02,\n",
            "          3.7461e-01,  2.0964e-03,  3.3210e-01, -1.9388e-01, -1.7987e-01,\n",
            "          2.0306e-01, -4.8392e-02,  2.9248e-01, -1.4335e-01, -2.2953e-01,\n",
            "          1.9208e-01,  4.4103e-02,  8.2241e-02,  1.4347e-01, -4.5820e-01],\n",
            "        [ 1.1821e-01,  5.7466e-02, -2.5654e-01, -5.6209e-02,  1.4862e-01,\n",
            "          2.0140e-01,  2.7292e-01,  2.7956e-02, -9.0503e-02, -2.5079e-01,\n",
            "          1.2432e-01, -4.3815e-02,  1.0919e-01,  6.9885e-02, -3.5241e-03,\n",
            "         -4.9244e-02,  3.0922e-03,  2.2875e-02, -2.8040e-01,  1.5266e-01,\n",
            "          6.1663e-02,  1.4810e-01, -2.5095e-02,  4.3756e-02, -4.3097e-02,\n",
            "          1.0931e-01,  2.2541e-02, -2.6103e-01,  7.5664e-02,  1.1719e-01],\n",
            "        [ 8.9904e-02, -1.1065e-01, -1.0539e-01,  2.0717e-02,  6.2355e-02,\n",
            "          1.0249e-02, -1.2570e-01,  7.4305e-02, -4.1034e-02, -1.8381e-01,\n",
            "          1.8162e-01, -8.9867e-02, -1.6678e-01,  1.6748e-01,  5.0678e-03,\n",
            "          1.6544e-02,  1.5902e-01, -1.1872e-01,  4.1115e-01,  6.3081e-03,\n",
            "          1.2233e-01, -2.8966e-02, -8.4761e-02,  1.5564e-01, -2.3602e-02,\n",
            "         -2.3686e-01, -6.8182e-02,  1.0181e-01,  1.1609e-01,  2.4330e-02],\n",
            "        [ 5.7720e-02, -2.3591e-02,  4.5249e-02, -1.2951e-01, -1.8455e-16,\n",
            "         -6.3272e-13,  7.3982e-11, -9.7318e-40, -2.5950e-02,  2.1700e-23,\n",
            "         -6.8727e-05, -2.1424e-02, -2.5863e-02, -3.5407e-02,  2.0858e-39,\n",
            "          1.5876e-39, -1.5474e-02, -1.0430e-39,  2.1490e-39, -1.3229e-40,\n",
            "          7.1263e-02,  8.6057e-02, -1.0550e-01, -1.7020e-01, -8.6160e-13,\n",
            "         -7.3700e-04,  2.7531e-06, -2.9554e-20, -1.4369e-06, -4.0315e-18],\n",
            "        [ 5.3569e-39,  9.5109e-40, -3.2673e-39,  2.9163e-39, -3.7278e-39,\n",
            "          6.0502e-39,  4.5806e-39,  4.3560e-39,  3.9955e-39, -4.6621e-39,\n",
            "          1.0964e-39, -2.7346e-12, -7.1512e-09, -4.9207e-39,  2.2374e-39,\n",
            "         -4.7572e-38, -2.3219e-39,  3.6393e-39,  3.3310e-39,  4.4581e-41,\n",
            "         -1.8839e-40, -1.0213e-39,  3.6990e-39, -1.2359e-27, -3.4976e-40,\n",
            "          5.3474e-42,  3.0349e-40,  6.3292e-39, -4.2911e-39, -6.4905e-39]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(pesos0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q42zQLHFsIWC",
        "outputId": "94b5e3c1-9691-45ab-fc7a-3c94140277c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# 30 -> 16 -> 16 -> 1\n",
        "bias0 = params[1]\n",
        "bias0.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IWG8GFjsTr5",
        "outputId": "55468793-db09-4e7a-d245-1e8d6d6e5843"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "pesos1 = params[2]\n",
        "pesos1.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfgtWyWrsbbY",
        "outputId": "7eee8c0a-9408-4357-c50b-89128a09aac0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "bias1 = params[3]\n",
        "bias1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyTjLzELSdQF"
      },
      "source": [
        "## Etapa 7: Avaliação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZafmlssFs5SG",
        "outputId": "21a5ef42-170f-450f-b970-6388de1da4de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "classificador.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C3BgZGGtJvp",
        "outputId": "ac608974-27c2-42a4-83a2-c5805f2d4472"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "type(previsores_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PuL49MUEtOrh"
      },
      "outputs": [],
      "source": [
        "previsores_teste = torch.tensor(np.array(previsores_teste), dtype=torch.float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmAqJEHHtZNC",
        "outputId": "1e0aa68f-10ff-40f0-cc80-c40d43bebed7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "type(previsores_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Fe8muTxbtc1G"
      },
      "outputs": [],
      "source": [
        "previsoes = classificador.forward(previsores_teste)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn0leHiAtqpx",
        "outputId": "5527e7a2-c1c4-4d15-d058-a4b8ee64b6d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9383e-01],\n",
              "        [1.0000e+00],\n",
              "        [3.1412e-01],\n",
              "        [9.4383e-01],\n",
              "        [1.3290e-04],\n",
              "        [8.4746e-01],\n",
              "        [9.4431e-01],\n",
              "        [9.9988e-01],\n",
              "        [6.2488e-01],\n",
              "        [6.5691e-01],\n",
              "        [9.1439e-01],\n",
              "        [9.9876e-01],\n",
              "        [6.7283e-01],\n",
              "        [9.9518e-01],\n",
              "        [9.9706e-01],\n",
              "        [8.6089e-01],\n",
              "        [9.9605e-01],\n",
              "        [1.0000e+00],\n",
              "        [2.9267e-01],\n",
              "        [9.9612e-01],\n",
              "        [7.4813e-10],\n",
              "        [1.0656e-02],\n",
              "        [5.8519e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.0273e-01],\n",
              "        [4.2905e-03],\n",
              "        [8.2606e-01],\n",
              "        [1.0000e+00],\n",
              "        [1.8561e-04],\n",
              "        [9.9753e-01],\n",
              "        [5.3080e-01],\n",
              "        [9.9999e-01],\n",
              "        [9.2115e-01],\n",
              "        [9.8746e-01],\n",
              "        [4.5453e-01],\n",
              "        [9.9757e-01],\n",
              "        [6.0572e-01],\n",
              "        [9.9787e-01],\n",
              "        [9.9748e-01],\n",
              "        [4.9014e-05],\n",
              "        [6.0460e-03],\n",
              "        [9.2253e-01],\n",
              "        [1.5413e-07],\n",
              "        [4.1097e-01],\n",
              "        [7.4316e-05],\n",
              "        [7.8655e-01],\n",
              "        [1.8864e-04],\n",
              "        [9.6268e-35],\n",
              "        [7.2074e-01],\n",
              "        [1.7409e-02],\n",
              "        [9.8417e-01],\n",
              "        [6.6992e-15],\n",
              "        [9.7841e-01],\n",
              "        [9.5640e-01],\n",
              "        [9.9138e-01],\n",
              "        [6.0331e-01],\n",
              "        [9.9975e-01],\n",
              "        [8.4215e-08],\n",
              "        [1.1872e-05],\n",
              "        [9.9004e-01],\n",
              "        [1.2390e-04],\n",
              "        [9.9692e-01],\n",
              "        [9.9319e-01],\n",
              "        [9.9602e-01],\n",
              "        [7.0414e-01],\n",
              "        [6.4712e-08],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [7.3204e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.6357e-01],\n",
              "        [1.3197e-01],\n",
              "        [9.0052e-01],\n",
              "        [7.0963e-04],\n",
              "        [9.9254e-01],\n",
              "        [9.4545e-01],\n",
              "        [9.3749e-10],\n",
              "        [1.6993e-06],\n",
              "        [4.7240e-01],\n",
              "        [8.8870e-01],\n",
              "        [4.8444e-06],\n",
              "        [2.0672e-07],\n",
              "        [9.9345e-01],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [1.3203e-01],\n",
              "        [9.9491e-01],\n",
              "        [1.5942e-03],\n",
              "        [8.1258e-01],\n",
              "        [1.6355e-02],\n",
              "        [9.7659e-01],\n",
              "        [9.7746e-01],\n",
              "        [2.6270e-02],\n",
              "        [9.9540e-01],\n",
              "        [9.9993e-01],\n",
              "        [9.9962e-01],\n",
              "        [9.9701e-01],\n",
              "        [1.3614e-02],\n",
              "        [1.0000e+00],\n",
              "        [9.9988e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9739e-01],\n",
              "        [9.7277e-01],\n",
              "        [9.1986e-01],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [9.9460e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9676e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9992e-01],\n",
              "        [8.6228e-01],\n",
              "        [8.5374e-06],\n",
              "        [9.2254e-01],\n",
              "        [2.2421e-04],\n",
              "        [9.9819e-01],\n",
              "        [6.0253e-04],\n",
              "        [9.9744e-01],\n",
              "        [9.9616e-01],\n",
              "        [9.2309e-01],\n",
              "        [7.2682e-01],\n",
              "        [9.9975e-01],\n",
              "        [9.9908e-01],\n",
              "        [4.8349e-07],\n",
              "        [9.8742e-01],\n",
              "        [3.9294e-03],\n",
              "        [3.7220e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.8113e-01],\n",
              "        [1.2626e-09],\n",
              "        [9.0756e-01],\n",
              "        [1.0000e+00],\n",
              "        [2.3129e-02],\n",
              "        [2.6838e-07],\n",
              "        [9.5877e-01],\n",
              "        [9.8706e-01],\n",
              "        [9.9965e-01],\n",
              "        [4.9300e-02],\n",
              "        [1.5985e-05],\n",
              "        [9.7282e-06],\n",
              "        [9.9503e-01],\n",
              "        [2.4759e-11]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "previsoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzALzgDet3Hr",
        "outputId": "c304a63c-5626-468c-c8f9-08c90f16528d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "previsoes = np.array(previsoes > 0.5)\n",
        "previsoes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "YVPFTbGeuSU5",
        "outputId": "5ed8edc3-3fd1-4925-90b3-651b7fa1fc3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a31e5c9f-9400-4fbe-a929-521b5bbcd985\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a31e5c9f-9400-4fbe-a929-521b5bbcd985')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a31e5c9f-9400-4fbe-a929-521b5bbcd985 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a31e5c9f-9400-4fbe-a929-521b5bbcd985');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     0\n",
              "333  1\n",
              "273  1\n",
              "201  0\n",
              "178  1\n",
              "85   0\n",
              "..  ..\n",
              "230  0\n",
              "282  0\n",
              "535  0\n",
              "436  1\n",
              "236  0\n",
              "\n",
              "[143 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "classe_teste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7jfnFtZuNVn",
        "outputId": "ca9fbded-7181-43b8-f123-28f2041d2b8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9020979020979021"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "taxa_acerto = accuracy_score(classe_teste, previsoes)\n",
        "taxa_acerto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0Z3LgbcutQD",
        "outputId": "aec349fb-179e-4058-ce7f-4c34631bd59f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[43, 11],\n",
              "       [ 3, 86]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "matriz = confusion_matrix(classe_teste, previsoes)\n",
        "matriz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "BlaTftH_uzpv",
        "outputId": "cba71521-0497-4395-ab68-94949d187eea"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.heatmap(matriz, annot=True);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7DqJGrxSoS4"
      },
      "source": [
        "# Validação cruzada e Skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm2yFq0tSIrS",
        "outputId": "8b0add12-76d8-4041-9caf-b246d12aeb6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.62.3)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "# importar o skorch , que é scikit learn + pytorch\n",
        "!pip install skorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "U_LMpyygTe6B"
      },
      "outputs": [],
      "source": [
        "from skorch import NeuralNetBinaryClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv5RXyjwg5iO"
      },
      "source": [
        "# Criar a estrutura da rede neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "0EBQksiPT-Mz"
      },
      "outputs": [],
      "source": [
        "class classificador_torch(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # 30 -> 16 -> 16 -> 1\n",
        "    self.dense0 = nn.Linear(30, 16)\n",
        "    torch.nn.init.uniform_(self.dense0.weight)\n",
        "    self.activation0 = nn.ReLU()\n",
        "    self.dense1 = nn.Linear(16, 16)\n",
        "    torch.nn.init.uniform_(self.dense1.weight)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    self.dense2 = nn.Linear(16, 1)\n",
        "    torch.nn.init.uniform_(self.dense2.weight)\n",
        "    # self.output = nn.Sigmoid() \n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dense2(X)\n",
        "    # X = self.output(X) \n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz4Ds0vNmuui"
      },
      "source": [
        "# Skorch, convertendo de PyTorch + Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "Y1vIqdk4oAnx"
      },
      "outputs": [],
      "source": [
        "previsores = np.array(previsores, dtype='float32')\n",
        "classe = np.array(classe, dtype='float32').squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "D5zoCKpjlO79"
      },
      "outputs": [],
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
        "                                                  criterion=torch.nn.BCEWithLogitsLoss, # ** ATUALIZAÇÃO **\n",
        "                                                  optimizer=torch.optim.Adam,\n",
        "                                                  lr=0.001,\n",
        "                                                  optimizer__weight_decay=0.0001,\n",
        "                                                  max_epochs=100,\n",
        "                                                  batch_size=10,\n",
        "                                                  train_split=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBUccbJYm922"
      },
      "source": [
        "# Validação cruzada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFYbVlwdm8K-",
        "outputId": "b3f3fd1e-9a37-4563-e64c-0fde7b3c4407"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1   \u001b[36m118945.4298\u001b[0m  0.0650\n",
            "      2    \u001b[36m96306.6813\u001b[0m  0.0680\n",
            "      3    \u001b[36m76948.1390\u001b[0m  0.0678\n",
            "      4    \u001b[36m61005.2824\u001b[0m  0.0849\n",
            "      5    \u001b[36m47964.5737\u001b[0m  0.0666\n",
            "      6    \u001b[36m37257.7034\u001b[0m  0.0763\n",
            "      7    \u001b[36m28374.2056\u001b[0m  0.0673\n",
            "      8    \u001b[36m20867.2861\u001b[0m  0.0667\n",
            "      9    \u001b[36m14361.3472\u001b[0m  0.0679\n",
            "     10     \u001b[36m8525.1316\u001b[0m  0.0684\n",
            "     11     \u001b[36m3337.3645\u001b[0m  0.0782\n",
            "     12      \u001b[36m406.6355\u001b[0m  0.0793\n",
            "     13      \u001b[36m127.1227\u001b[0m  0.0789\n",
            "     14       \u001b[36m90.8128\u001b[0m  0.0687\n",
            "     15       \u001b[36m85.3662\u001b[0m  0.0686\n",
            "     16       \u001b[36m73.6475\u001b[0m  0.0722\n",
            "     17       \u001b[36m62.4910\u001b[0m  0.0672\n",
            "     18       \u001b[36m48.6342\u001b[0m  0.0761\n",
            "     19       \u001b[36m41.6262\u001b[0m  0.0664\n",
            "     20       43.0964  0.0841\n",
            "     21       43.3950  0.0678\n",
            "     22       \u001b[36m39.8347\u001b[0m  0.0712\n",
            "     23       \u001b[36m31.6974\u001b[0m  0.0674\n",
            "     24       \u001b[36m29.0732\u001b[0m  0.0713\n",
            "     25       30.8460  0.0684\n",
            "     26       \u001b[36m27.3363\u001b[0m  0.0722\n",
            "     27       \u001b[36m22.3035\u001b[0m  0.0680\n",
            "     28       \u001b[36m19.5539\u001b[0m  0.0736\n",
            "     29       19.8370  0.0681\n",
            "     30       \u001b[36m16.0502\u001b[0m  0.0691\n",
            "     31       18.6731  0.0708\n",
            "     32       \u001b[36m10.9810\u001b[0m  0.0669\n",
            "     33       26.7008  0.0748\n",
            "     34        \u001b[36m9.8572\u001b[0m  0.0749\n",
            "     35       10.1600  0.0691\n",
            "     36       14.3602  0.0742\n",
            "     37        \u001b[36m9.6043\u001b[0m  0.0682\n",
            "     38       17.1617  0.0806\n",
            "     39        \u001b[36m8.2237\u001b[0m  0.0685\n",
            "     40       15.5621  0.0675\n",
            "     41       14.0671  0.0662\n",
            "     42       17.4390  0.0701\n",
            "     43       33.8514  0.0688\n",
            "     44        8.4062  0.0700\n",
            "     45       12.6811  0.0781\n",
            "     46       10.3659  0.0703\n",
            "     47       14.1148  0.0799\n",
            "     48       13.8237  0.0688\n",
            "     49       11.5184  0.0703\n",
            "     50        9.7329  0.0697\n",
            "     51        8.9482  0.0670\n",
            "     52       15.3850  0.0750\n",
            "     53       15.4551  0.0820\n",
            "     54        \u001b[36m7.9544\u001b[0m  0.0710\n",
            "     55        \u001b[36m7.4802\u001b[0m  0.0686\n",
            "     56        \u001b[36m5.4225\u001b[0m  0.0701\n",
            "     57        7.5461  0.0719\n",
            "     58       50.2427  0.0681\n",
            "     59       28.1654  0.0768\n",
            "     60        9.6582  0.0686\n",
            "     61        8.5652  0.0860\n",
            "     62        6.2369  0.0702\n",
            "     63        7.4176  0.0716\n",
            "     64       17.0093  0.0691\n",
            "     65        9.2810  0.0714\n",
            "     66       17.1895  0.0657\n",
            "     67       27.9206  0.0694\n",
            "     68        6.0544  0.0689\n",
            "     69        \u001b[36m4.7268\u001b[0m  0.0801\n",
            "     70        9.3002  0.0708\n",
            "     71        6.9132  0.0696\n",
            "     72       12.1118  0.0689\n",
            "     73        5.7530  0.0697\n",
            "     74        9.6165  0.0680\n",
            "     75        9.3845  0.0815\n",
            "     76        9.4868  0.0717\n",
            "     77       16.3353  0.0818\n",
            "     78       15.5795  0.0692\n",
            "     79       17.5209  0.0692\n",
            "     80       15.3440  0.0686\n",
            "     81       28.8441  0.0722\n",
            "     82        9.9760  0.0674\n",
            "     83        9.3766  0.0732\n",
            "     84        6.0498  0.0700\n",
            "     85        7.1788  0.0720\n",
            "     86        \u001b[36m4.6561\u001b[0m  0.0703\n",
            "     87        5.7671  0.0697\n",
            "     88        8.7993  0.0699\n",
            "     89        4.7305  0.0810\n",
            "     90       13.3912  0.0673\n",
            "     91        6.2751  0.0713\n",
            "     92       11.0610  0.0676\n",
            "     93        5.4666  0.0692\n",
            "     94        7.0798  0.0740\n",
            "     95        6.9698  0.0716\n",
            "     96        7.6685  0.0693\n",
            "     97        5.4973  0.0694\n",
            "     98       10.0489  0.0696\n",
            "     99        7.2729  0.0684\n",
            "    100       10.2540  0.0717\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1   \u001b[36m110452.5259\u001b[0m  0.0639\n",
            "      2    \u001b[36m88046.8000\u001b[0m  0.0823\n",
            "      3    \u001b[36m69455.5511\u001b[0m  0.0757\n",
            "      4    \u001b[36m54457.9887\u001b[0m  0.0686\n",
            "      5    \u001b[36m42300.9526\u001b[0m  0.0757\n",
            "      6    \u001b[36m32327.0224\u001b[0m  0.0745\n",
            "      7    \u001b[36m24019.1621\u001b[0m  0.0686\n",
            "      8    \u001b[36m16958.3426\u001b[0m  0.0772\n",
            "      9    \u001b[36m10779.3852\u001b[0m  0.0677\n",
            "     10     \u001b[36m5128.9416\u001b[0m  0.0798\n",
            "     11      \u001b[36m840.1249\u001b[0m  0.0702\n",
            "     12      \u001b[36m197.8151\u001b[0m  0.0709\n",
            "     13      \u001b[36m134.8234\u001b[0m  0.0712\n",
            "     14      \u001b[36m118.3963\u001b[0m  0.0688\n",
            "     15      \u001b[36m104.5178\u001b[0m  0.0732\n",
            "     16       \u001b[36m95.6630\u001b[0m  0.0794\n",
            "     17       \u001b[36m87.1736\u001b[0m  0.0684\n",
            "     18       \u001b[36m76.5774\u001b[0m  0.0734\n",
            "     19       \u001b[36m69.2900\u001b[0m  0.0734\n",
            "     20       \u001b[36m61.2026\u001b[0m  0.0688\n",
            "     21       \u001b[36m55.7096\u001b[0m  0.0676\n",
            "     22       \u001b[36m39.0211\u001b[0m  0.0677\n",
            "     23       \u001b[36m34.6670\u001b[0m  0.0694\n",
            "     24       \u001b[36m29.7358\u001b[0m  0.0689\n",
            "     25       32.2353  0.0683\n",
            "     26       40.6443  0.0838\n",
            "     27       38.7189  0.0762\n",
            "     28       37.0289  0.0788\n",
            "     29       \u001b[36m28.7857\u001b[0m  0.0707\n",
            "     30       \u001b[36m26.5539\u001b[0m  0.0834\n",
            "     31       \u001b[36m14.4917\u001b[0m  0.0718\n",
            "     32       27.1131  0.0687\n",
            "     33       22.1388  0.0673\n",
            "     34       19.4974  0.0734\n",
            "     35       \u001b[36m13.4938\u001b[0m  0.0857\n",
            "     36       15.0992  0.0699\n",
            "     37        \u001b[36m9.6987\u001b[0m  0.0716\n",
            "     38        \u001b[36m7.7324\u001b[0m  0.0757\n",
            "     39        \u001b[36m7.6871\u001b[0m  0.0696\n",
            "     40       10.2916  0.0763\n",
            "     41        \u001b[36m7.4400\u001b[0m  0.0703\n",
            "     42        8.8554  0.0740\n",
            "     43        \u001b[36m6.9756\u001b[0m  0.0784\n",
            "     44        \u001b[36m6.1549\u001b[0m  0.0684\n",
            "     45        7.2426  0.0686\n",
            "     46        6.2215  0.0807\n",
            "     47        \u001b[36m5.5495\u001b[0m  0.0681\n",
            "     48        7.2524  0.0859\n",
            "     49        5.7801  0.0703\n",
            "     50        \u001b[36m5.1804\u001b[0m  0.0739\n",
            "     51        6.2227  0.0698\n",
            "     52        6.7716  0.0707\n",
            "     53        8.1824  0.0775\n",
            "     54        6.1478  0.0834\n",
            "     55        \u001b[36m3.8533\u001b[0m  0.0692\n",
            "     56        8.5746  0.0706\n",
            "     57        5.7572  0.0795\n",
            "     58        4.8532  0.0694\n",
            "     59        5.1953  0.0695\n",
            "     60        \u001b[36m3.7498\u001b[0m  0.0680\n",
            "     61        5.1997  0.0759\n",
            "     62        5.8225  0.0770\n",
            "     63        6.4470  0.0714\n",
            "     64        6.5066  0.0680\n",
            "     65        5.3383  0.0696\n",
            "     66        5.0419  0.0728\n",
            "     67        5.7245  0.0696\n",
            "     68        4.9844  0.0761\n",
            "     69        6.2420  0.0685\n",
            "     70        9.0503  0.0876\n",
            "     71        6.7039  0.0699\n",
            "     72       15.5981  0.0685\n",
            "     73        7.8156  0.0681\n",
            "     74        8.3034  0.0717\n",
            "     75        \u001b[36m3.2122\u001b[0m  0.0697\n",
            "     76        \u001b[36m2.7782\u001b[0m  0.0704\n",
            "     77        4.1787  0.0730\n",
            "     78        8.0833  0.0731\n",
            "     79        3.1556  0.0702\n",
            "     80        8.3496  0.0732\n",
            "     81        5.3400  0.0703\n",
            "     82        6.4867  0.0695\n",
            "     83        7.9926  0.0778\n",
            "     84        3.3790  0.0797\n",
            "     85        5.2436  0.0701\n",
            "     86        5.4219  0.0744\n",
            "     87        9.6660  0.0677\n",
            "     88        6.0010  0.0698\n",
            "     89        4.6901  0.0708\n",
            "     90        \u001b[36m2.2959\u001b[0m  0.0719\n",
            "     91        3.5393  0.0696\n",
            "     92        7.0893  0.0701\n",
            "     93        7.3918  0.0752\n",
            "     94        5.6551  0.0789\n",
            "     95        7.5121  0.0711\n",
            "     96        3.5858  0.0701\n",
            "     97        4.7582  0.0707\n",
            "     98        4.7369  0.0815\n",
            "     99        3.6377  0.0690\n",
            "    100        4.9334  0.0717\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m74123.5979\u001b[0m  0.0651\n",
            "      2    \u001b[36m58026.0649\u001b[0m  0.0723\n",
            "      3    \u001b[36m44857.0814\u001b[0m  0.0712\n",
            "      4    \u001b[36m34387.7219\u001b[0m  0.0678\n",
            "      5    \u001b[36m26015.6651\u001b[0m  0.0657\n",
            "      6    \u001b[36m19208.0707\u001b[0m  0.0700\n",
            "      7    \u001b[36m13563.9993\u001b[0m  0.0679\n",
            "      8     \u001b[36m8737.2086\u001b[0m  0.0699\n",
            "      9     \u001b[36m4364.8841\u001b[0m  0.0697\n",
            "     10      \u001b[36m758.3640\u001b[0m  0.0745\n",
            "     11      \u001b[36m132.9201\u001b[0m  0.0750\n",
            "     12      \u001b[36m112.7437\u001b[0m  0.0776\n",
            "     13      \u001b[36m104.1083\u001b[0m  0.0683\n",
            "     14       \u001b[36m97.9032\u001b[0m  0.0711\n",
            "     15       \u001b[36m94.1513\u001b[0m  0.0706\n",
            "     16       \u001b[36m88.5995\u001b[0m  0.0712\n",
            "     17       \u001b[36m85.2403\u001b[0m  0.0789\n",
            "     18       \u001b[36m78.9571\u001b[0m  0.0745\n",
            "     19       \u001b[36m73.4855\u001b[0m  0.0689\n",
            "     20       \u001b[36m69.6753\u001b[0m  0.0674\n",
            "     21       \u001b[36m67.5348\u001b[0m  0.0676\n",
            "     22       \u001b[36m65.0280\u001b[0m  0.0675\n",
            "     23       66.7199  0.0702\n",
            "     24       \u001b[36m60.3393\u001b[0m  0.0725\n",
            "     25       \u001b[36m59.9444\u001b[0m  0.0749\n",
            "     26       60.4752  0.0757\n",
            "     27       \u001b[36m44.0947\u001b[0m  0.0734\n",
            "     28       \u001b[36m42.2603\u001b[0m  0.0668\n",
            "     29       \u001b[36m39.9630\u001b[0m  0.0710\n",
            "     30       \u001b[36m38.4251\u001b[0m  0.0691\n",
            "     31       \u001b[36m37.9954\u001b[0m  0.0724\n",
            "     32       \u001b[36m35.5217\u001b[0m  0.0698\n",
            "     33       \u001b[36m34.3965\u001b[0m  0.0680\n",
            "     34       \u001b[36m31.8967\u001b[0m  0.0655\n",
            "     35       \u001b[36m30.4162\u001b[0m  0.0747\n",
            "     36       \u001b[36m27.1768\u001b[0m  0.0659\n",
            "     37       \u001b[36m26.3448\u001b[0m  0.0668\n",
            "     38       \u001b[36m24.8807\u001b[0m  0.0726\n",
            "     39       \u001b[36m24.6667\u001b[0m  0.0697\n",
            "     40       \u001b[36m24.5964\u001b[0m  0.0813\n",
            "     41       24.7724  0.0756\n",
            "     42       \u001b[36m20.3749\u001b[0m  0.0709\n",
            "     43       \u001b[36m18.9508\u001b[0m  0.0782\n",
            "     44       22.4786  0.0720\n",
            "     45       \u001b[36m16.6930\u001b[0m  0.0688\n",
            "     46       19.1887  0.0686\n",
            "     47       23.0085  0.0680\n",
            "     48       \u001b[36m14.3650\u001b[0m  0.0685\n",
            "     49       \u001b[36m12.2594\u001b[0m  0.0721\n",
            "     50       15.0445  0.0705\n",
            "     51       13.9196  0.0777\n",
            "     52       18.6071  0.0718\n",
            "     53       14.0033  0.0774\n",
            "     54       14.7531  0.0696\n",
            "     55       \u001b[36m11.7262\u001b[0m  0.0735\n",
            "     56       12.8677  0.0756\n",
            "     57       18.7059  0.0702\n",
            "     58       22.1967  0.0723\n",
            "     59       14.2679  0.0809\n",
            "     60       12.6515  0.0706\n",
            "     61       14.1885  0.0733\n",
            "     62       \u001b[36m11.6296\u001b[0m  0.0698\n",
            "     63       12.1402  0.0702\n",
            "     64       11.9302  0.0715\n",
            "     65       \u001b[36m10.9963\u001b[0m  0.0699\n",
            "     66       18.6237  0.0696\n",
            "     67       15.4287  0.0936\n",
            "     68       12.0127  0.0712\n",
            "     69       11.3853  0.0707\n",
            "     70       13.3479  0.0700\n",
            "     71       12.4048  0.0694\n",
            "     72       14.1577  0.0701\n",
            "     73       \u001b[36m10.6000\u001b[0m  0.0678\n",
            "     74       17.1121  0.0776\n",
            "     75       16.9098  0.0833\n",
            "     76       16.1209  0.0733\n",
            "     77       11.3927  0.0704\n",
            "     78       14.6964  0.0698\n",
            "     79       11.1387  0.0714\n",
            "     80       13.2203  0.0683\n",
            "     81       \u001b[36m10.5790\u001b[0m  0.0800\n",
            "     82       12.3534  0.0689\n",
            "     83       10.8866  0.0803\n",
            "     84       12.9211  0.0707\n",
            "     85       12.2683  0.0712\n",
            "     86       \u001b[36m10.1774\u001b[0m  0.0694\n",
            "     87       12.0747  0.0745\n",
            "     88       11.3547  0.0694\n",
            "     89       14.9810  0.0702\n",
            "     90       25.7452  0.0691\n",
            "     91       19.1063  0.0700\n",
            "     92       11.5741  0.0795\n",
            "     93       13.1001  0.0703\n",
            "     94       11.8177  0.0797\n",
            "     95       16.3731  0.0733\n",
            "     96       14.6901  0.0684\n",
            "     97       30.1042  0.0701\n",
            "     98       14.7237  0.0679\n",
            "     99       14.5060  0.0722\n",
            "    100       21.6029  0.0736\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m85527.9831\u001b[0m  0.0657\n",
            "      2    \u001b[36m67459.8487\u001b[0m  0.0716\n",
            "      3    \u001b[36m52365.6470\u001b[0m  0.0697\n",
            "      4    \u001b[36m40047.0514\u001b[0m  0.0685\n",
            "      5    \u001b[36m29994.7566\u001b[0m  0.0708\n",
            "      6    \u001b[36m21725.6086\u001b[0m  0.0687\n",
            "      7    \u001b[36m14808.4608\u001b[0m  0.0748\n",
            "      8     \u001b[36m8844.5815\u001b[0m  0.0885\n",
            "      9     \u001b[36m3434.1797\u001b[0m  0.0686\n",
            "     10      \u001b[36m246.6107\u001b[0m  0.0692\n",
            "     11      \u001b[36m154.1466\u001b[0m  0.0702\n",
            "     12      \u001b[36m122.6916\u001b[0m  0.0687\n",
            "     13       \u001b[36m98.6019\u001b[0m  0.0688\n",
            "     14       \u001b[36m82.8064\u001b[0m  0.0705\n",
            "     15       \u001b[36m67.4650\u001b[0m  0.0681\n",
            "     16       \u001b[36m55.2414\u001b[0m  0.0799\n",
            "     17       \u001b[36m44.5011\u001b[0m  0.0703\n",
            "     18       55.7684  0.0700\n",
            "     19       49.3294  0.0737\n",
            "     20       49.1057  0.0688\n",
            "     21       \u001b[36m26.8178\u001b[0m  0.0738\n",
            "     22       \u001b[36m22.9407\u001b[0m  0.0787\n",
            "     23       51.5280  0.0681\n",
            "     24       26.3496  0.0723\n",
            "     25       \u001b[36m22.0695\u001b[0m  0.0760\n",
            "     26       27.5499  0.0702\n",
            "     27       25.3570  0.0682\n",
            "     28       29.0782  0.0697\n",
            "     29       31.9514  0.0686\n",
            "     30       34.5925  0.0673\n",
            "     31       22.3565  0.0673\n",
            "     32       32.4155  0.0757\n",
            "     33       26.0780  0.0743\n",
            "     34       33.2068  0.0695\n",
            "     35       30.1862  0.0672\n",
            "     36       37.1980  0.0800\n",
            "     37       24.8147  0.0689\n",
            "     38       37.3020  0.0713\n",
            "     39       28.3993  0.0687\n",
            "     40       29.7603  0.0863\n",
            "     41       31.8172  0.0668\n",
            "     42       27.4358  0.0687\n",
            "     43       30.7732  0.0673\n",
            "     44       30.8622  0.0676\n",
            "     45       39.0234  0.0710\n",
            "     46       24.5775  0.0720\n",
            "     47       22.5865  0.0714\n",
            "     48       \u001b[36m18.3442\u001b[0m  0.0671\n",
            "     49       25.4496  0.0762\n",
            "     50       35.5636  0.0755\n",
            "     51       24.6766  0.0669\n",
            "     52       38.5831  0.0680\n",
            "     53       28.7091  0.0667\n",
            "     54       32.3824  0.0672\n",
            "     55       37.8257  0.0716\n",
            "     56       29.7728  0.0675\n",
            "     57       22.1246  0.0780\n",
            "     58       21.0091  0.0687\n",
            "     59       26.6481  0.0702\n",
            "     60       46.5545  0.0661\n",
            "     61       19.3845  0.0704\n",
            "     62       20.0984  0.0702\n",
            "     63       28.3105  0.0731\n",
            "     64       42.3071  0.0763\n",
            "     65       25.9889  0.0819\n",
            "     66       22.2132  0.0681\n",
            "     67       23.7634  0.0691\n",
            "     68       22.6141  0.0665\n",
            "     69       24.2715  0.0701\n",
            "     70       28.2918  0.0735\n",
            "     71       41.7571  0.0695\n",
            "     72       26.9849  0.0733\n",
            "     73       20.9808  0.0683\n",
            "     74       25.6362  0.0673\n",
            "     75       41.8635  0.0676\n",
            "     76       20.1598  0.0658\n",
            "     77       24.9582  0.0680\n",
            "     78       48.3024  0.0846\n",
            "     79       21.0359  0.0672\n",
            "     80       28.3981  0.0660\n",
            "     81       23.8072  0.0669\n",
            "     82       23.2524  0.0680\n",
            "     83       27.1682  0.0688\n",
            "     84       25.9139  0.0682\n",
            "     85       24.7322  0.0751\n",
            "     86       23.4787  0.0675\n",
            "     87       25.6233  0.0681\n",
            "     88       23.5101  0.0671\n",
            "     89       25.9149  0.0689\n",
            "     90       27.5263  0.0686\n",
            "     91       31.9265  0.0742\n",
            "     92       20.2631  0.0781\n",
            "     93       \u001b[36m12.7913\u001b[0m  0.0706\n",
            "     94       26.6645  0.0818\n",
            "     95       24.3063  0.0689\n",
            "     96       17.9107  0.0723\n",
            "     97       \u001b[36m11.9114\u001b[0m  0.0740\n",
            "     98       18.7684  0.0716\n",
            "     99       17.9237  0.0728\n",
            "    100       22.1587  0.0685\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m91520.0893\u001b[0m  0.0644\n",
            "      2    \u001b[36m71902.4003\u001b[0m  0.0655\n",
            "      3    \u001b[36m55839.1535\u001b[0m  0.0725\n",
            "      4    \u001b[36m43007.8125\u001b[0m  0.0667\n",
            "      5    \u001b[36m32792.3478\u001b[0m  0.0686\n",
            "      6    \u001b[36m24613.8299\u001b[0m  0.0855\n",
            "      7    \u001b[36m17909.7418\u001b[0m  0.0744\n",
            "      8    \u001b[36m12253.2060\u001b[0m  0.0703\n",
            "      9     \u001b[36m7310.3108\u001b[0m  0.0698\n",
            "     10     \u001b[36m2733.9887\u001b[0m  0.0696\n",
            "     11      \u001b[36m196.8742\u001b[0m  0.0702\n",
            "     12      \u001b[36m102.3373\u001b[0m  0.0692\n",
            "     13      104.2615  0.0699\n",
            "     14       \u001b[36m92.7023\u001b[0m  0.0686\n",
            "     15       95.2268  0.0720\n",
            "     16       \u001b[36m79.6400\u001b[0m  0.0843\n",
            "     17       81.1961  0.0700\n",
            "     18       86.3336  0.0692\n",
            "     19       \u001b[36m76.6536\u001b[0m  0.0840\n",
            "     20       83.9916  0.0712\n",
            "     21       \u001b[36m74.6453\u001b[0m  0.0698\n",
            "     22       \u001b[36m71.9970\u001b[0m  0.0712\n",
            "     23       \u001b[36m69.2318\u001b[0m  0.0697\n",
            "     24       73.4856  0.0740\n",
            "     25       69.6463  0.0698\n",
            "     26       73.5891  0.0672\n",
            "     27       70.8924  0.0694\n",
            "     28       69.3165  0.0749\n",
            "     29       70.6036  0.0680\n",
            "     30       \u001b[36m67.8739\u001b[0m  0.0693\n",
            "     31       \u001b[36m60.4898\u001b[0m  0.0761\n",
            "     32       \u001b[36m36.9116\u001b[0m  0.0692\n",
            "     33       \u001b[36m36.0911\u001b[0m  0.0768\n",
            "     34       37.6244  0.0692\n",
            "     35       37.0639  0.0739\n",
            "     36       36.1702  0.0691\n",
            "     37       \u001b[36m35.8259\u001b[0m  0.0697\n",
            "     38       \u001b[36m35.7706\u001b[0m  0.0720\n",
            "     39       \u001b[36m33.4931\u001b[0m  0.0688\n",
            "     40       35.1947  0.0738\n",
            "     41       35.0454  0.0681\n",
            "     42       33.8245  0.0676\n",
            "     43       \u001b[36m31.7601\u001b[0m  0.0707\n",
            "     44       35.5102  0.0694\n",
            "     45       33.5654  0.0717\n",
            "     46       35.1011  0.0687\n",
            "     47       \u001b[36m31.4459\u001b[0m  0.0847\n",
            "     48       \u001b[36m30.7126\u001b[0m  0.0686\n",
            "     49       \u001b[36m30.4750\u001b[0m  0.0696\n",
            "     50       \u001b[36m29.1269\u001b[0m  0.0722\n",
            "     51       30.5353  0.0743\n",
            "     52       \u001b[36m27.2209\u001b[0m  0.0691\n",
            "     53       30.2015  0.0766\n",
            "     54       29.8047  0.0701\n",
            "     55       \u001b[36m26.5206\u001b[0m  0.0687\n",
            "     56       27.2169  0.0699\n",
            "     57       28.1060  0.0696\n",
            "     58       \u001b[36m24.5781\u001b[0m  0.0732\n",
            "     59       \u001b[36m21.7985\u001b[0m  0.0727\n",
            "     60       \u001b[36m20.8725\u001b[0m  0.0707\n",
            "     61       \u001b[36m19.2277\u001b[0m  0.0779\n",
            "     62       19.3825  0.0686\n",
            "     63       \u001b[36m18.7702\u001b[0m  0.0680\n",
            "     64       \u001b[36m14.7103\u001b[0m  0.0682\n",
            "     65       18.2696  0.0713\n",
            "     66       \u001b[36m13.8869\u001b[0m  0.0687\n",
            "     67       \u001b[36m13.6382\u001b[0m  0.0696\n",
            "     68       13.7997  0.0703\n",
            "     69       \u001b[36m12.4169\u001b[0m  0.0686\n",
            "     70       \u001b[36m10.9313\u001b[0m  0.0690\n",
            "     71        \u001b[36m8.7056\u001b[0m  0.0769\n",
            "     72        \u001b[36m8.4533\u001b[0m  0.0741\n",
            "     73        9.0843  0.0682\n",
            "     74        9.1380  0.0701\n",
            "     75        8.6053  0.0809\n",
            "     76        \u001b[36m8.0002\u001b[0m  0.0732\n",
            "     77        9.3789  0.0730\n",
            "     78        9.2312  0.0749\n",
            "     79        8.7994  0.0727\n",
            "     80        9.6282  0.0698\n",
            "     81       10.1741  0.0691\n",
            "     82        9.9564  0.0765\n",
            "     83       10.5028  0.0693\n",
            "     84        9.5882  0.0713\n",
            "     85        8.3771  0.0701\n",
            "     86        \u001b[36m7.8505\u001b[0m  0.0703\n",
            "     87        9.8194  0.0694\n",
            "     88        7.9474  0.0763\n",
            "     89        \u001b[36m7.3049\u001b[0m  0.0768\n",
            "     90        9.8941  0.0653\n",
            "     91        8.1932  0.0705\n",
            "     92       10.9111  0.0682\n",
            "     93        8.6424  0.0686\n",
            "     94        8.9756  0.0698\n",
            "     95        9.2138  0.0756\n",
            "     96        8.9858  0.0687\n",
            "     97        8.3793  0.0718\n",
            "     98        7.3368  0.0727\n",
            "     99        7.4023  0.0687\n",
            "    100        \u001b[36m7.1257\u001b[0m  0.0720\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m65640.8188\u001b[0m  0.0703\n",
            "      2    \u001b[36m50154.8560\u001b[0m  0.0774\n",
            "      3    \u001b[36m37678.5438\u001b[0m  0.0716\n",
            "      4    \u001b[36m27861.8529\u001b[0m  0.0674\n",
            "      5    \u001b[36m20131.4712\u001b[0m  0.0704\n",
            "      6    \u001b[36m14044.8267\u001b[0m  0.0693\n",
            "      7     \u001b[36m9137.7177\u001b[0m  0.0677\n",
            "      8     \u001b[36m5007.1961\u001b[0m  0.0765\n",
            "      9     \u001b[36m1390.4948\u001b[0m  0.0693\n",
            "     10      \u001b[36m207.2853\u001b[0m  0.0681\n",
            "     11      \u001b[36m171.8957\u001b[0m  0.0677\n",
            "     12      \u001b[36m142.7456\u001b[0m  0.0776\n",
            "     13      \u001b[36m119.3113\u001b[0m  0.0714\n",
            "     14      \u001b[36m100.6839\u001b[0m  0.0715\n",
            "     15       \u001b[36m89.8018\u001b[0m  0.0710\n",
            "     16       \u001b[36m85.0770\u001b[0m  0.0812\n",
            "     17       \u001b[36m83.4619\u001b[0m  0.0702\n",
            "     18       \u001b[36m79.0428\u001b[0m  0.0807\n",
            "     19       \u001b[36m73.5457\u001b[0m  0.0714\n",
            "     20       \u001b[36m69.3571\u001b[0m  0.0710\n",
            "     21       \u001b[36m67.2958\u001b[0m  0.0719\n",
            "     22       \u001b[36m63.1240\u001b[0m  0.0703\n",
            "     23       \u001b[36m61.1059\u001b[0m  0.0706\n",
            "     24       \u001b[36m58.4426\u001b[0m  0.0744\n",
            "     25       58.7590  0.0708\n",
            "     26       \u001b[36m58.4282\u001b[0m  0.0707\n",
            "     27       \u001b[36m55.4571\u001b[0m  0.0690\n",
            "     28       \u001b[36m43.5540\u001b[0m  0.0780\n",
            "     29       \u001b[36m42.4060\u001b[0m  0.0688\n",
            "     30       43.5357  0.0783\n",
            "     31       42.7104  0.0673\n",
            "     32       \u001b[36m42.2327\u001b[0m  0.0706\n",
            "     33       43.4425  0.0724\n",
            "     34       \u001b[36m39.4589\u001b[0m  0.0693\n",
            "     35       \u001b[36m34.2167\u001b[0m  0.0697\n",
            "     36       \u001b[36m33.6104\u001b[0m  0.0768\n",
            "     37       \u001b[36m30.3912\u001b[0m  0.0688\n",
            "     38       30.7810  0.0691\n",
            "     39       31.7277  0.0674\n",
            "     40       \u001b[36m28.0105\u001b[0m  0.0775\n",
            "     41       30.1575  0.0701\n",
            "     42       32.4345  0.0682\n",
            "     43       \u001b[36m27.9356\u001b[0m  0.0687\n",
            "     44       \u001b[36m27.1713\u001b[0m  0.0787\n",
            "     45       \u001b[36m27.0344\u001b[0m  0.0733\n",
            "     46       31.1016  0.0682\n",
            "     47       \u001b[36m24.8712\u001b[0m  0.0705\n",
            "     48       26.5386  0.0672\n",
            "     49       \u001b[36m20.2428\u001b[0m  0.0708\n",
            "     50       \u001b[36m20.0706\u001b[0m  0.0698\n",
            "     51       \u001b[36m19.7758\u001b[0m  0.0696\n",
            "     52       23.3435  0.0702\n",
            "     53       \u001b[36m17.4748\u001b[0m  0.0818\n",
            "     54       18.4060  0.0698\n",
            "     55       18.3503  0.0688\n",
            "     56       \u001b[36m15.6743\u001b[0m  0.0825\n",
            "     57       \u001b[36m12.1180\u001b[0m  0.0778\n",
            "     58       16.9691  0.0750\n",
            "     59       12.1520  0.0700\n",
            "     60       14.7496  0.0708\n",
            "     61       \u001b[36m11.2556\u001b[0m  0.0764\n",
            "     62       15.3203  0.0719\n",
            "     63       \u001b[36m11.1732\u001b[0m  0.0691\n",
            "     64       19.3810  0.0701\n",
            "     65       18.8131  0.0702\n",
            "     66       12.0203  0.0694\n",
            "     67       12.3444  0.0706\n",
            "     68       11.7561  0.0754\n",
            "     69       \u001b[36m10.1704\u001b[0m  0.0750\n",
            "     70        \u001b[36m8.1041\u001b[0m  0.0684\n",
            "     71        9.9172  0.0767\n",
            "     72        \u001b[36m6.0601\u001b[0m  0.0708\n",
            "     73        \u001b[36m5.8264\u001b[0m  0.0688\n",
            "     74        \u001b[36m5.4539\u001b[0m  0.0689\n",
            "     75        5.9244  0.0765\n",
            "     76        \u001b[36m4.6154\u001b[0m  0.0717\n",
            "     77        4.8634  0.0720\n",
            "     78        9.0314  0.0703\n",
            "     79        5.8425  0.0712\n",
            "     80        5.6343  0.0751\n",
            "     81        5.6251  0.0784\n",
            "     82        4.6298  0.0711\n",
            "     83        6.6172  0.0683\n",
            "     84        5.3854  0.0685\n",
            "     85        5.0318  0.0852\n",
            "     86        5.6901  0.0721\n",
            "     87        \u001b[36m4.6032\u001b[0m  0.0703\n",
            "     88        \u001b[36m4.5087\u001b[0m  0.0769\n",
            "     89        5.7120  0.0777\n",
            "     90        5.3708  0.0698\n",
            "     91        \u001b[36m3.9858\u001b[0m  0.0677\n",
            "     92        4.1227  0.0735\n",
            "     93        6.1639  0.0733\n",
            "     94        4.1954  0.0706\n",
            "     95        4.2726  0.0688\n",
            "     96        \u001b[36m3.8592\u001b[0m  0.0693\n",
            "     97        4.1849  0.0707\n",
            "     98        4.0626  0.0684\n",
            "     99        \u001b[36m3.5425\u001b[0m  0.0847\n",
            "    100        7.1376  0.0674\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m78018.7727\u001b[0m  0.0658\n",
            "      2    \u001b[36m61053.6582\u001b[0m  0.0699\n",
            "      3    \u001b[36m47224.6294\u001b[0m  0.0737\n",
            "      4    \u001b[36m36146.2455\u001b[0m  0.0674\n",
            "      5    \u001b[36m27180.2161\u001b[0m  0.0746\n",
            "      6    \u001b[36m19850.5824\u001b[0m  0.0675\n",
            "      7    \u001b[36m13783.5136\u001b[0m  0.0667\n",
            "      8     \u001b[36m8643.2003\u001b[0m  0.0679\n",
            "      9     \u001b[36m4098.1419\u001b[0m  0.0727\n",
            "     10     \u001b[36m1192.9508\u001b[0m  0.0679\n",
            "     11      \u001b[36m657.2006\u001b[0m  0.0693\n",
            "     12      \u001b[36m469.7193\u001b[0m  0.0698\n",
            "     13      \u001b[36m304.8783\u001b[0m  0.0756\n",
            "     14      \u001b[36m195.0727\u001b[0m  0.0669\n",
            "     15      \u001b[36m136.7889\u001b[0m  0.0693\n",
            "     16      \u001b[36m103.6074\u001b[0m  0.0684\n",
            "     17       \u001b[36m83.0676\u001b[0m  0.0760\n",
            "     18       \u001b[36m65.0775\u001b[0m  0.0708\n",
            "     19       66.3179  0.0752\n",
            "     20       \u001b[36m62.1728\u001b[0m  0.0694\n",
            "     21       \u001b[36m58.2259\u001b[0m  0.0780\n",
            "     22       \u001b[36m57.1985\u001b[0m  0.0757\n",
            "     23       \u001b[36m56.9121\u001b[0m  0.0740\n",
            "     24       \u001b[36m56.1738\u001b[0m  0.0694\n",
            "     25       \u001b[36m52.3767\u001b[0m  0.0731\n",
            "     26       \u001b[36m49.1005\u001b[0m  0.0786\n",
            "     27       \u001b[36m46.0024\u001b[0m  0.0773\n",
            "     28       \u001b[36m45.1957\u001b[0m  0.0706\n",
            "     29       47.1694  0.0721\n",
            "     30       46.5923  0.0674\n",
            "     31       \u001b[36m41.7648\u001b[0m  0.0675\n",
            "     32       \u001b[36m36.9680\u001b[0m  0.0673\n",
            "     33       42.8867  0.0777\n",
            "     34       \u001b[36m29.9346\u001b[0m  0.0680\n",
            "     35       35.7837  0.0692\n",
            "     36       40.0733  0.0687\n",
            "     37       \u001b[36m27.2188\u001b[0m  0.0682\n",
            "     38       30.6349  0.0683\n",
            "     39       30.8694  0.0714\n",
            "     40       43.5373  0.0790\n",
            "     41       27.7463  0.0696\n",
            "     42       \u001b[36m25.9772\u001b[0m  0.0699\n",
            "     43       \u001b[36m21.7993\u001b[0m  0.0684\n",
            "     44       \u001b[36m21.5986\u001b[0m  0.0678\n",
            "     45       23.6730  0.0729\n",
            "     46       22.7478  0.0786\n",
            "     47       \u001b[36m20.8977\u001b[0m  0.0682\n",
            "     48       22.0347  0.0681\n",
            "     49       \u001b[36m11.7342\u001b[0m  0.0712\n",
            "     50       12.6067  0.0682\n",
            "     51       \u001b[36m11.5024\u001b[0m  0.0749\n",
            "     52       12.2581  0.0870\n",
            "     53       12.4922  0.0702\n",
            "     54       13.6595  0.0791\n",
            "     55       12.4385  0.0703\n",
            "     56       14.3709  0.0678\n",
            "     57       13.6381  0.0683\n",
            "     58       12.6610  0.0689\n",
            "     59       \u001b[36m11.2758\u001b[0m  0.0737\n",
            "     60       13.2130  0.0710\n",
            "     61        \u001b[36m9.1959\u001b[0m  0.0684\n",
            "     62        \u001b[36m9.0572\u001b[0m  0.0774\n",
            "     63       11.4912  0.0696\n",
            "     64       13.8072  0.0696\n",
            "     65       12.4687  0.0735\n",
            "     66       10.4241  0.0737\n",
            "     67       11.5432  0.0751\n",
            "     68       13.2863  0.0775\n",
            "     69       10.2759  0.0682\n",
            "     70        9.1116  0.0687\n",
            "     71       10.0678  0.0703\n",
            "     72       10.7378  0.0767\n",
            "     73       16.9194  0.0720\n",
            "     74       14.4269  0.0787\n",
            "     75       12.8828  0.0709\n",
            "     76       13.2388  0.0698\n",
            "     77        9.5704  0.0704\n",
            "     78       11.2304  0.0789\n",
            "     79       10.8366  0.0725\n",
            "     80       11.4329  0.0753\n",
            "     81       10.8923  0.0811\n",
            "     82       11.5317  0.0685\n",
            "     83        9.7244  0.0736\n",
            "     84        9.5176  0.0716\n",
            "     85       11.2672  0.0707\n",
            "     86       10.5232  0.0794\n",
            "     87        9.9184  0.0701\n",
            "     88       11.1633  0.0718\n",
            "     89        9.0610  0.0716\n",
            "     90       11.2084  0.0695\n",
            "     91        \u001b[36m8.5174\u001b[0m  0.0739\n",
            "     92       10.9584  0.0710\n",
            "     93       10.5431  0.0668\n",
            "     94       12.6349  0.0677\n",
            "     95        8.9367  0.0792\n",
            "     96        8.8701  0.0769\n",
            "     97       12.7431  0.0719\n",
            "     98        9.4761  0.0703\n",
            "     99       13.2344  0.0701\n",
            "    100       12.3111  0.0683\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m96685.9966\u001b[0m  0.0676\n",
            "      2    \u001b[36m77375.1463\u001b[0m  0.0741\n",
            "      3    \u001b[36m61476.2443\u001b[0m  0.0684\n",
            "      4    \u001b[36m48940.8312\u001b[0m  0.0693\n",
            "      5    \u001b[36m38978.5082\u001b[0m  0.0679\n",
            "      6    \u001b[36m30953.3169\u001b[0m  0.0705\n",
            "      7    \u001b[36m24427.2196\u001b[0m  0.0658\n",
            "      8    \u001b[36m19062.0175\u001b[0m  0.0684\n",
            "      9    \u001b[36m14577.1437\u001b[0m  0.0792\n",
            "     10    \u001b[36m10716.9195\u001b[0m  0.0714\n",
            "     11     \u001b[36m7278.4556\u001b[0m  0.0678\n",
            "     12     \u001b[36m4070.7840\u001b[0m  0.0718\n",
            "     13     \u001b[36m1049.2991\u001b[0m  0.0860\n",
            "     14       \u001b[36m72.4368\u001b[0m  0.0763\n",
            "     15       73.5368  0.0700\n",
            "     16       \u001b[36m56.3301\u001b[0m  0.0685\n",
            "     17       \u001b[36m48.1526\u001b[0m  0.0675\n",
            "     18       \u001b[36m41.2652\u001b[0m  0.0667\n",
            "     19       \u001b[36m37.6105\u001b[0m  0.0686\n",
            "     20       \u001b[36m33.1472\u001b[0m  0.0732\n",
            "     21       \u001b[36m31.7554\u001b[0m  0.0677\n",
            "     22       \u001b[36m27.6894\u001b[0m  0.0805\n",
            "     23       \u001b[36m23.1847\u001b[0m  0.0681\n",
            "     24       \u001b[36m21.4020\u001b[0m  0.0684\n",
            "     25       \u001b[36m21.2005\u001b[0m  0.0729\n",
            "     26       \u001b[36m16.9158\u001b[0m  0.0752\n",
            "     27       \u001b[36m16.1163\u001b[0m  0.0696\n",
            "     28       \u001b[36m14.7725\u001b[0m  0.0651\n",
            "     29       \u001b[36m14.0685\u001b[0m  0.0701\n",
            "     30       14.7155  0.0680\n",
            "     31       \u001b[36m13.9700\u001b[0m  0.0735\n",
            "     32       \u001b[36m13.8425\u001b[0m  0.0704\n",
            "     33       \u001b[36m13.0912\u001b[0m  0.0757\n",
            "     34       \u001b[36m11.3999\u001b[0m  0.0683\n",
            "     35       11.5221  0.0683\n",
            "     36       13.7314  0.0806\n",
            "     37       13.0338  0.0760\n",
            "     38       12.4628  0.0703\n",
            "     39       12.4619  0.0706\n",
            "     40       11.8824  0.0699\n",
            "     41       13.6067  0.0695\n",
            "     42       12.3603  0.0693\n",
            "     43       12.8638  0.0813\n",
            "     44       13.9979  0.0708\n",
            "     45       15.6763  0.0699\n",
            "     46       \u001b[36m10.5220\u001b[0m  0.0737\n",
            "     47        \u001b[36m9.4492\u001b[0m  0.0705\n",
            "     48       15.2436  0.0691\n",
            "     49       16.3663  0.0755\n",
            "     50        \u001b[36m9.2572\u001b[0m  0.0799\n",
            "     51        9.5839  0.0673\n",
            "     52        9.9809  0.0684\n",
            "     53        \u001b[36m8.4558\u001b[0m  0.0678\n",
            "     54        \u001b[36m5.6119\u001b[0m  0.0711\n",
            "     55        \u001b[36m5.0709\u001b[0m  0.0753\n",
            "     56        5.6802  0.0674\n",
            "     57        \u001b[36m4.4293\u001b[0m  0.0702\n",
            "     58        7.1293  0.0687\n",
            "     59        \u001b[36m4.2888\u001b[0m  0.0672\n",
            "     60        7.1066  0.0705\n",
            "     61        \u001b[36m4.2162\u001b[0m  0.0687\n",
            "     62        7.3918  0.0803\n",
            "     63        4.2472  0.0676\n",
            "     64        5.4929  0.0803\n",
            "     65        4.5965  0.0694\n",
            "     66        4.7894  0.0692\n",
            "     67        4.3468  0.0854\n",
            "     68        7.2993  0.0679\n",
            "     69        4.9163  0.0703\n",
            "     70        5.8000  0.0690\n",
            "     71        4.9103  0.0707\n",
            "     72        5.2556  0.0678\n",
            "     73       11.8521  0.0748\n",
            "     74        7.9636  0.0683\n",
            "     75        4.8417  0.0687\n",
            "     76        4.2296  0.0685\n",
            "     77        4.7048  0.0773\n",
            "     78       11.4004  0.0829\n",
            "     79       10.6806  0.0695\n",
            "     80        4.7056  0.0687\n",
            "     81        5.1669  0.0694\n",
            "     82        4.4330  0.0696\n",
            "     83        6.9766  0.0777\n",
            "     84       11.2600  0.0716\n",
            "     85       10.5377  0.0671\n",
            "     86        5.2424  0.0689\n",
            "     87        5.2885  0.0695\n",
            "     88        7.2433  0.0674\n",
            "     89        9.8479  0.0675\n",
            "     90        4.5168  0.0665\n",
            "     91        5.3619  0.0670\n",
            "     92        \u001b[36m3.8430\u001b[0m  0.0802\n",
            "     93        5.0329  0.0685\n",
            "     94        \u001b[36m3.0804\u001b[0m  0.0693\n",
            "     95        5.0255  0.0677\n",
            "     96        4.1024  0.0743\n",
            "     97        5.2420  0.0689\n",
            "     98       14.3270  0.0678\n",
            "     99       10.4141  0.0681\n",
            "    100        3.7211  0.0755\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m75968.7838\u001b[0m  0.0638\n",
            "      2    \u001b[36m59332.0430\u001b[0m  0.0675\n",
            "      3    \u001b[36m45696.8777\u001b[0m  0.0686\n",
            "      4    \u001b[36m34789.8612\u001b[0m  0.0703\n",
            "      5    \u001b[36m26034.5026\u001b[0m  0.0684\n",
            "      6    \u001b[36m18924.1142\u001b[0m  0.0820\n",
            "      7    \u001b[36m13043.9564\u001b[0m  0.0675\n",
            "      8     \u001b[36m8037.3583\u001b[0m  0.0754\n",
            "      9     \u001b[36m3543.6119\u001b[0m  0.0699\n",
            "     10      \u001b[36m453.2841\u001b[0m  0.0687\n",
            "     11      \u001b[36m222.9069\u001b[0m  0.0675\n",
            "     12      \u001b[36m190.9088\u001b[0m  0.0695\n",
            "     13      \u001b[36m172.5221\u001b[0m  0.0699\n",
            "     14      \u001b[36m153.9153\u001b[0m  0.0699\n",
            "     15      \u001b[36m130.6381\u001b[0m  0.0734\n",
            "     16      \u001b[36m106.8239\u001b[0m  0.0707\n",
            "     17       \u001b[36m89.7672\u001b[0m  0.0686\n",
            "     18       \u001b[36m73.9687\u001b[0m  0.0700\n",
            "     19       \u001b[36m55.5859\u001b[0m  0.0752\n",
            "     20       \u001b[36m48.3040\u001b[0m  0.0783\n",
            "     21       \u001b[36m47.0762\u001b[0m  0.0696\n",
            "     22       \u001b[36m44.8565\u001b[0m  0.0696\n",
            "     23       \u001b[36m42.7985\u001b[0m  0.0689\n",
            "     24       \u001b[36m35.9775\u001b[0m  0.0744\n",
            "     25       \u001b[36m31.8250\u001b[0m  0.0764\n",
            "     26       \u001b[36m27.2269\u001b[0m  0.0706\n",
            "     27       27.4197  0.0743\n",
            "     28       29.4653  0.0709\n",
            "     29       28.8236  0.0726\n",
            "     30       34.1234  0.0754\n",
            "     31       \u001b[36m22.2166\u001b[0m  0.0701\n",
            "     32       30.5547  0.0736\n",
            "     33       27.1769  0.0804\n",
            "     34       22.4589  0.0713\n",
            "     35       \u001b[36m21.5560\u001b[0m  0.0703\n",
            "     36       26.8815  0.0778\n",
            "     37       21.6635  0.0720\n",
            "     38       \u001b[36m21.2268\u001b[0m  0.0708\n",
            "     39       \u001b[36m18.8391\u001b[0m  0.0682\n",
            "     40       \u001b[36m15.0081\u001b[0m  0.0751\n",
            "     41       \u001b[36m12.4588\u001b[0m  0.0669\n",
            "     42       13.1572  0.0706\n",
            "     43       15.3778  0.0676\n",
            "     44       \u001b[36m11.6653\u001b[0m  0.0675\n",
            "     45       12.9456  0.0665\n",
            "     46       \u001b[36m10.1009\u001b[0m  0.0754\n",
            "     47        \u001b[36m8.2129\u001b[0m  0.0767\n",
            "     48        8.8317  0.0712\n",
            "     49        8.5291  0.0720\n",
            "     50        \u001b[36m6.7472\u001b[0m  0.0678\n",
            "     51        9.1338  0.0675\n",
            "     52       12.3080  0.0682\n",
            "     53        7.9507  0.0704\n",
            "     54        7.6780  0.0704\n",
            "     55        \u001b[36m5.5079\u001b[0m  0.0678\n",
            "     56        6.6376  0.0690\n",
            "     57        5.8373  0.0705\n",
            "     58        \u001b[36m5.2411\u001b[0m  0.0743\n",
            "     59        5.5770  0.0683\n",
            "     60        6.1759  0.0725\n",
            "     61        7.0184  0.0811\n",
            "     62        6.9180  0.0684\n",
            "     63        6.8429  0.0695\n",
            "     64        6.9842  0.0750\n",
            "     65        7.2726  0.0753\n",
            "     66        8.3870  0.0693\n",
            "     67       10.5250  0.0711\n",
            "     68        6.5267  0.0723\n",
            "     69        6.2576  0.0704\n",
            "     70        6.1277  0.0700\n",
            "     71        \u001b[36m4.7874\u001b[0m  0.0700\n",
            "     72        5.2033  0.0682\n",
            "     73        4.9936  0.0719\n",
            "     74        8.1047  0.0690\n",
            "     75        7.8423  0.0794\n",
            "     76        8.5748  0.0684\n",
            "     77        9.6271  0.0860\n",
            "     78        9.8805  0.0754\n",
            "     79       11.1337  0.0698\n",
            "     80        8.4575  0.0693\n",
            "     81        7.7931  0.0718\n",
            "     82        6.0855  0.0705\n",
            "     83        \u001b[36m4.5202\u001b[0m  0.0716\n",
            "     84        5.8336  0.0696\n",
            "     85        5.1131  0.0715\n",
            "     86        4.6906  0.0715\n",
            "     87        5.8477  0.0700\n",
            "     88        5.1096  0.0772\n",
            "     89        6.1148  0.0850\n",
            "     90        5.5521  0.0706\n",
            "     91        5.0631  0.0755\n",
            "     92        5.8382  0.0717\n",
            "     93        8.9422  0.0712\n",
            "     94        6.8871  0.0739\n",
            "     95        6.7949  0.0707\n",
            "     96        5.5052  0.0702\n",
            "     97        5.2833  0.0797\n",
            "     98        9.9829  0.0868\n",
            "     99        5.0325  0.0700\n",
            "    100        6.1814  0.0726\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m74202.2338\u001b[0m  0.0825\n",
            "      2    \u001b[36m57814.1763\u001b[0m  0.0782\n",
            "      3    \u001b[36m44118.0014\u001b[0m  0.0734\n",
            "      4    \u001b[36m32745.9970\u001b[0m  0.0729\n",
            "      5    \u001b[36m23268.5462\u001b[0m  0.0704\n",
            "      6    \u001b[36m15271.3927\u001b[0m  0.0698\n",
            "      7     \u001b[36m8331.4867\u001b[0m  0.0738\n",
            "      8     \u001b[36m2329.0834\u001b[0m  0.0760\n",
            "      9      \u001b[36m605.7091\u001b[0m  0.0696\n",
            "     10      \u001b[36m558.2728\u001b[0m  0.0719\n",
            "     11      \u001b[36m497.1312\u001b[0m  0.0698\n",
            "     12      \u001b[36m445.6354\u001b[0m  0.0695\n",
            "     13      \u001b[36m397.1076\u001b[0m  0.0686\n",
            "     14      \u001b[36m357.3489\u001b[0m  0.0744\n",
            "     15      \u001b[36m318.8768\u001b[0m  0.0801\n",
            "     16      \u001b[36m287.9019\u001b[0m  0.0735\n",
            "     17      \u001b[36m253.7246\u001b[0m  0.0763\n",
            "     18      \u001b[36m219.2359\u001b[0m  0.0719\n",
            "     19      \u001b[36m190.0602\u001b[0m  0.0706\n",
            "     20      \u001b[36m167.2339\u001b[0m  0.0724\n",
            "     21      \u001b[36m142.5230\u001b[0m  0.0744\n",
            "     22      \u001b[36m120.2839\u001b[0m  0.0697\n",
            "     23       \u001b[36m82.3529\u001b[0m  0.0708\n",
            "     24       95.8357  0.0693\n",
            "     25       93.6509  0.0707\n",
            "     26       \u001b[36m70.4843\u001b[0m  0.0769\n",
            "     27       82.3415  0.0695\n",
            "     28       86.5252  0.0712\n",
            "     29       75.5237  0.0909\n",
            "     30       70.7544  0.0706\n",
            "     31       71.0747  0.0698\n",
            "     32       \u001b[36m68.9510\u001b[0m  0.0723\n",
            "     33       74.7474  0.0733\n",
            "     34       \u001b[36m68.0952\u001b[0m  0.0745\n",
            "     35       \u001b[36m64.3680\u001b[0m  0.0698\n",
            "     36       72.5382  0.0706\n",
            "     37       \u001b[36m47.2036\u001b[0m  0.0701\n",
            "     38       60.3621  0.0712\n",
            "     39       67.1006  0.0813\n",
            "     40       57.5527  0.0715\n",
            "     41       75.3490  0.0773\n",
            "     42       47.4973  0.0826\n",
            "     43       76.1887  0.0704\n",
            "     44       \u001b[36m33.4397\u001b[0m  0.0702\n",
            "     45       45.5817  0.0707\n",
            "     46       63.2587  0.0712\n",
            "     47       56.8460  0.0754\n",
            "     48       62.9564  0.0699\n",
            "     49       48.8623  0.0693\n",
            "     50       60.5306  0.0703\n",
            "     51       41.6292  0.0710\n",
            "     52       54.2963  0.0705\n",
            "     53       52.5089  0.0686\n",
            "     54       48.9152  0.0790\n",
            "     55       40.1026  0.0725\n",
            "     56       53.5243  0.0798\n",
            "     57       40.0084  0.0763\n",
            "     58       37.3599  0.0669\n",
            "     59       42.5540  0.0696\n",
            "     60       39.7181  0.0741\n",
            "     61       36.5786  0.0731\n",
            "     62       40.9962  0.0699\n",
            "     63       41.4980  0.0732\n",
            "     64       \u001b[36m29.6437\u001b[0m  0.0700\n",
            "     65       35.2976  0.0747\n",
            "     66       29.7995  0.0686\n",
            "     67       40.8654  0.0744\n",
            "     68       39.7476  0.0681\n",
            "     69       40.2245  0.0774\n",
            "     70       35.2838  0.0753\n",
            "     71       \u001b[36m27.2576\u001b[0m  0.0684\n",
            "     72       33.4095  0.0676\n",
            "     73       28.5554  0.0706\n",
            "     74       29.4914  0.0685\n",
            "     75       36.4059  0.0670\n",
            "     76       \u001b[36m25.1239\u001b[0m  0.0699\n",
            "     77       37.2040  0.0698\n",
            "     78       27.3931  0.0781\n",
            "     79       31.7886  0.0726\n",
            "     80       29.5334  0.0712\n",
            "     81       29.8291  0.0791\n",
            "     82       30.1477  0.0709\n",
            "     83       \u001b[36m23.7585\u001b[0m  0.0770\n",
            "     84       38.7657  0.0741\n",
            "     85       27.7169  0.0710\n",
            "     86       34.3535  0.0732\n",
            "     87       \u001b[36m16.6549\u001b[0m  0.0708\n",
            "     88       31.6757  0.0744\n",
            "     89       31.0759  0.0694\n",
            "     90       32.3578  0.0753\n",
            "     91       19.3140  0.0730\n",
            "     92       32.4025  0.0749\n",
            "     93       28.8016  0.0684\n",
            "     94       27.7054  0.0694\n",
            "     95       27.7610  0.0697\n",
            "     96       33.7532  0.0764\n",
            "     97       18.7764  0.0852\n",
            "     98       25.9631  0.0728\n",
            "     99       26.4612  0.0687\n",
            "    100       23.9550  0.0765\n"
          ]
        }
      ],
      "source": [
        "resultados = cross_val_score(classificador_sklearn, previsores, classe, cv = 10, scoring = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "b59ZmYdYnUdG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4552f72c-40c2-441a-e8ab-6022b19d8747"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "resultados.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "GvvC0QeEnXKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae654b9-0d36-4c42-91e6-da1e3c56f9b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.85964912, 0.80701754, 0.87719298, 0.9122807 , 0.85964912,\n",
              "       0.9122807 , 0.8245614 , 0.85964912, 0.78947368, 0.76785714])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Dy0_aD_pnas0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e25c190-f211-4a8d-dc0c-c620fe1d7b45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8469611528822055"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "media = resultados.mean()\n",
        "media"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "CzHqT10FpoZr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af09d315-2837-44c0-f81c-65c4158b5bd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.04646471599140423"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "desvio = resultados.std()\n",
        "desvio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05AngLcN3LPp"
      },
      "source": [
        "# Adicionando a camada de Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "IUoAkIYv3R9F"
      },
      "outputs": [],
      "source": [
        "class classificador_torch(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # 30 -> 16 -> 16 -> 1\n",
        "    self.dense0 = nn.Linear(30, 16)\n",
        "    torch.nn.init.uniform_(self.dense0.weight)\n",
        "    self.activation0 = nn.ReLU()\n",
        "    self.dropout0 = nn.Dropout(0.2)\n",
        "    self.dense1 = nn.Linear(16, 16)\n",
        "    torch.nn.init.uniform_(self.dense1.weight)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    self.dropout1 = nn.Dropout(0.2)\n",
        "    self.dense2 = nn.Linear(16, 1)\n",
        "    torch.nn.init.uniform_(self.dense2.weight)\n",
        "    # self.output = nn.Sigmoid() \n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dropout0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dropout1(X)\n",
        "    X = self.dense2(X)\n",
        "    # X = self.output(X) \n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "NwXGdVst4pTd"
      },
      "outputs": [],
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
        "                                                  criterion=torch.nn.BCEWithLogitsLoss, # ** ATUALIZAÇÃO **\n",
        "                                                  optimizer=torch.optim.Adam,\n",
        "                                                  lr=0.001,\n",
        "                                                  optimizer__weight_decay=0.0001,\n",
        "                                                  max_epochs=100,\n",
        "                                                  batch_size=10,\n",
        "                                                  train_split=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "I0ftiiog4r8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31d83d82-362f-48a4-b7fc-a7339b40283d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m90533.6142\u001b[0m  0.0702\n",
            "      2    \u001b[36m70963.6339\u001b[0m  0.0733\n",
            "      3    \u001b[36m56935.1206\u001b[0m  0.0805\n",
            "      4    \u001b[36m43389.7627\u001b[0m  0.0803\n",
            "      5    \u001b[36m34936.3036\u001b[0m  0.0749\n",
            "      6    \u001b[36m27848.4043\u001b[0m  0.0753\n",
            "      7    \u001b[36m20891.8739\u001b[0m  0.0857\n",
            "      8    \u001b[36m14785.6921\u001b[0m  0.0874\n",
            "      9    \u001b[36m10405.0327\u001b[0m  0.0777\n",
            "     10     \u001b[36m6880.2532\u001b[0m  0.0736\n",
            "     11     \u001b[36m3844.3898\u001b[0m  0.0779\n",
            "     12     \u001b[36m2706.5926\u001b[0m  0.0824\n",
            "     13     \u001b[36m1912.9335\u001b[0m  0.0772\n",
            "     14     \u001b[36m1870.5745\u001b[0m  0.0856\n",
            "     15     \u001b[36m1778.9524\u001b[0m  0.0778\n",
            "     16     \u001b[36m1696.6795\u001b[0m  0.0764\n",
            "     17     \u001b[36m1448.5837\u001b[0m  0.0761\n",
            "     18     1513.2154  0.0919\n",
            "     19     \u001b[36m1272.0964\u001b[0m  0.0807\n",
            "     20     \u001b[36m1038.7577\u001b[0m  0.0845\n",
            "     21     1239.5739  0.0902\n",
            "     22     1156.9341  0.0821\n",
            "     23     1098.0364  0.0748\n",
            "     24     1061.4441  0.0757\n",
            "     25     1072.3421  0.0771\n",
            "     26      \u001b[36m936.0317\u001b[0m  0.0777\n",
            "     27      944.9657  0.0774\n",
            "     28     1018.9457  0.0752\n",
            "     29      \u001b[36m719.4458\u001b[0m  0.0824\n",
            "     30      889.2458  0.0807\n",
            "     31      \u001b[36m717.1343\u001b[0m  0.0771\n",
            "     32      \u001b[36m649.5917\u001b[0m  0.0883\n",
            "     33      698.0307  0.0909\n",
            "     34      \u001b[36m607.7772\u001b[0m  0.0847\n",
            "     35      618.3419  0.0767\n",
            "     36      662.4773  0.0772\n",
            "     37      608.9000  0.0761\n",
            "     38      \u001b[36m502.6142\u001b[0m  0.0796\n",
            "     39      \u001b[36m485.4032\u001b[0m  0.0760\n",
            "     40      \u001b[36m454.1137\u001b[0m  0.0756\n",
            "     41      \u001b[36m419.4940\u001b[0m  0.0727\n",
            "     42      \u001b[36m381.4743\u001b[0m  0.0732\n",
            "     43      \u001b[36m368.3409\u001b[0m  0.0738\n",
            "     44      422.7701  0.0794\n",
            "     45      386.3189  0.0788\n",
            "     46      \u001b[36m304.2886\u001b[0m  0.0847\n",
            "     47      \u001b[36m300.5438\u001b[0m  0.0744\n",
            "     48      308.4904  0.0767\n",
            "     49      \u001b[36m290.2553\u001b[0m  0.0806\n",
            "     50      295.9656  0.0783\n",
            "     51      \u001b[36m241.1605\u001b[0m  0.0775\n",
            "     52      257.6545  0.0778\n",
            "     53      \u001b[36m227.7152\u001b[0m  0.0763\n",
            "     54      \u001b[36m186.5735\u001b[0m  0.0758\n",
            "     55      \u001b[36m185.2351\u001b[0m  0.0764\n",
            "     56      195.2262  0.0744\n",
            "     57      \u001b[36m170.5206\u001b[0m  0.0816\n",
            "     58      188.7761  0.0791\n",
            "     59      \u001b[36m154.3443\u001b[0m  0.0853\n",
            "     60      156.3477  0.0756\n",
            "     61      171.7466  0.0778\n",
            "     62      \u001b[36m143.7524\u001b[0m  0.0748\n",
            "     63      \u001b[36m133.5045\u001b[0m  0.0834\n",
            "     64      \u001b[36m126.1849\u001b[0m  0.0721\n",
            "     65      \u001b[36m113.3560\u001b[0m  0.0756\n",
            "     66      \u001b[36m103.1442\u001b[0m  0.0831\n",
            "     67      107.7157  0.0793\n",
            "     68      113.7229  0.0748\n",
            "     69      112.2401  0.0759\n",
            "     70      104.7599  0.0755\n",
            "     71      105.9710  0.0866\n",
            "     72       \u001b[36m91.8398\u001b[0m  0.0761\n",
            "     73       \u001b[36m73.7084\u001b[0m  0.0787\n",
            "     74       76.5192  0.0845\n",
            "     75       \u001b[36m72.1086\u001b[0m  0.0781\n",
            "     76       \u001b[36m70.8732\u001b[0m  0.0774\n",
            "     77       \u001b[36m63.1171\u001b[0m  0.0758\n",
            "     78       \u001b[36m57.2905\u001b[0m  0.0812\n",
            "     79       59.7894  0.0757\n",
            "     80       \u001b[36m47.8014\u001b[0m  0.0800\n",
            "     81       52.5046  0.0842\n",
            "     82       \u001b[36m41.4344\u001b[0m  0.0761\n",
            "     83       54.7425  0.0741\n",
            "     84       47.2803  0.0924\n",
            "     85       42.1713  0.0780\n",
            "     86       \u001b[36m36.5432\u001b[0m  0.0768\n",
            "     87       39.5880  0.0767\n",
            "     88       \u001b[36m32.0009\u001b[0m  0.0807\n",
            "     89       36.4360  0.0773\n",
            "     90       35.6961  0.0740\n",
            "     91       \u001b[36m26.7919\u001b[0m  0.0775\n",
            "     92       \u001b[36m24.1675\u001b[0m  0.0731\n",
            "     93       27.0506  0.0733\n",
            "     94       \u001b[36m23.5656\u001b[0m  0.0741\n",
            "     95       28.2412  0.0800\n",
            "     96       23.6395  0.0888\n",
            "     97       \u001b[36m19.8506\u001b[0m  0.0830\n",
            "     98       \u001b[36m16.5592\u001b[0m  0.0745\n",
            "     99       18.4501  0.0761\n",
            "    100       \u001b[36m11.7944\u001b[0m  0.0769\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m72777.4747\u001b[0m  0.0717\n",
            "      2    \u001b[36m56944.2957\u001b[0m  0.0777\n",
            "      3    \u001b[36m44831.3907\u001b[0m  0.0876\n",
            "      4    \u001b[36m33208.7255\u001b[0m  0.0768\n",
            "      5    \u001b[36m26257.1165\u001b[0m  0.0771\n",
            "      6    \u001b[36m19281.7858\u001b[0m  0.0751\n",
            "      7    \u001b[36m13698.4568\u001b[0m  0.0763\n",
            "      8     \u001b[36m9229.2405\u001b[0m  0.0742\n",
            "      9     \u001b[36m4815.5129\u001b[0m  0.0921\n",
            "     10     \u001b[36m2280.9645\u001b[0m  0.0767\n",
            "     11     \u001b[36m2033.9231\u001b[0m  0.0901\n",
            "     12     \u001b[36m1869.3860\u001b[0m  0.0756\n",
            "     13     \u001b[36m1764.5109\u001b[0m  0.0743\n",
            "     14     \u001b[36m1368.9145\u001b[0m  0.0767\n",
            "     15     1377.5229  0.0768\n",
            "     16     \u001b[36m1331.9500\u001b[0m  0.0727\n",
            "     17     \u001b[36m1115.9654\u001b[0m  0.0759\n",
            "     18     \u001b[36m1105.4270\u001b[0m  0.0794\n",
            "     19     1147.5637  0.0799\n",
            "     20     \u001b[36m1063.1209\u001b[0m  0.0753\n",
            "     21     \u001b[36m1007.0158\u001b[0m  0.0810\n",
            "     22     1124.5379  0.0878\n",
            "     23      \u001b[36m896.3257\u001b[0m  0.0827\n",
            "     24      \u001b[36m869.7931\u001b[0m  0.0769\n",
            "     25      \u001b[36m701.2173\u001b[0m  0.0752\n",
            "     26      732.5159  0.0835\n",
            "     27      768.0693  0.0752\n",
            "     28      720.4054  0.0753\n",
            "     29      \u001b[36m647.0219\u001b[0m  0.0758\n",
            "     30      \u001b[36m577.9894\u001b[0m  0.0773\n",
            "     31      605.4000  0.0801\n",
            "     32      \u001b[36m448.9111\u001b[0m  0.0753\n",
            "     33      469.9251  0.0804\n",
            "     34      \u001b[36m396.9828\u001b[0m  0.0782\n",
            "     35      408.6221  0.0815\n",
            "     36      \u001b[36m330.3454\u001b[0m  0.0832\n",
            "     37      422.7532  0.0758\n",
            "     38      386.9500  0.0752\n",
            "     39      376.5444  0.0761\n",
            "     40      \u001b[36m284.6530\u001b[0m  0.0753\n",
            "     41      339.3771  0.0850\n",
            "     42      297.1312  0.0802\n",
            "     43      \u001b[36m230.0735\u001b[0m  0.0769\n",
            "     44      269.7610  0.0742\n",
            "     45      274.9270  0.0803\n",
            "     46      \u001b[36m216.7155\u001b[0m  0.0796\n",
            "     47      \u001b[36m215.4458\u001b[0m  0.0874\n",
            "     48      \u001b[36m161.4636\u001b[0m  0.0764\n",
            "     49      177.0847  0.0814\n",
            "     50      177.0096  0.0758\n",
            "     51      197.9909  0.0750\n",
            "     52      \u001b[36m159.7489\u001b[0m  0.0763\n",
            "     53      \u001b[36m134.3593\u001b[0m  0.0761\n",
            "     54      171.4315  0.0801\n",
            "     55      140.7923  0.0815\n",
            "     56      149.6936  0.0869\n",
            "     57      142.0173  0.0764\n",
            "     58      \u001b[36m116.1669\u001b[0m  0.0846\n",
            "     59      135.3547  0.0783\n",
            "     60       \u001b[36m98.8224\u001b[0m  0.0858\n",
            "     61      115.0148  0.0762\n",
            "     62      101.9379  0.0942\n",
            "     63      115.0660  0.0747\n",
            "     64       \u001b[36m91.0089\u001b[0m  0.0766\n",
            "     65       \u001b[36m89.1660\u001b[0m  0.0773\n",
            "     66       \u001b[36m85.5720\u001b[0m  0.0860\n",
            "     67       \u001b[36m84.4744\u001b[0m  0.0765\n",
            "     68       \u001b[36m73.3772\u001b[0m  0.0774\n",
            "     69       84.5080  0.0769\n",
            "     70       82.0344  0.0800\n",
            "     71       \u001b[36m72.5516\u001b[0m  0.0779\n",
            "     72       \u001b[36m70.7056\u001b[0m  0.0872\n",
            "     73       \u001b[36m65.9299\u001b[0m  0.0827\n",
            "     74       \u001b[36m61.3609\u001b[0m  0.0762\n",
            "     75       \u001b[36m51.9189\u001b[0m  0.0765\n",
            "     76       \u001b[36m48.4709\u001b[0m  0.0751\n",
            "     77       50.3528  0.0836\n",
            "     78       \u001b[36m41.5523\u001b[0m  0.0786\n",
            "     79       48.2040  0.0789\n",
            "     80       \u001b[36m30.5848\u001b[0m  0.0781\n",
            "     81       34.8516  0.0771\n",
            "     82       \u001b[36m26.6319\u001b[0m  0.0795\n",
            "     83       33.9233  0.0752\n",
            "     84       27.9500  0.0868\n",
            "     85       \u001b[36m25.4409\u001b[0m  0.0814\n",
            "     86       \u001b[36m19.7958\u001b[0m  0.0752\n",
            "     87       \u001b[36m17.0870\u001b[0m  0.0762\n",
            "     88       20.0341  0.0881\n",
            "     89       21.7302  0.0763\n",
            "     90       \u001b[36m13.3497\u001b[0m  0.0779\n",
            "     91       \u001b[36m10.3860\u001b[0m  0.0748\n",
            "     92       13.9842  0.0833\n",
            "     93        \u001b[36m9.1107\u001b[0m  0.0760\n",
            "     94        \u001b[36m8.6154\u001b[0m  0.0917\n",
            "     95        9.2878  0.0767\n",
            "     96        \u001b[36m6.5041\u001b[0m  0.0767\n",
            "     97        6.8624  0.0856\n",
            "     98       15.7995  0.0772\n",
            "     99        \u001b[36m5.4185\u001b[0m  0.0740\n",
            "    100        8.5352  0.0733\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m83015.9867\u001b[0m  0.0705\n",
            "      2    \u001b[36m65963.7590\u001b[0m  0.0741\n",
            "      3    \u001b[36m51693.6975\u001b[0m  0.0796\n",
            "      4    \u001b[36m39981.7249\u001b[0m  0.0819\n",
            "      5    \u001b[36m30778.2610\u001b[0m  0.0734\n",
            "      6    \u001b[36m24039.7486\u001b[0m  0.0770\n",
            "      7    \u001b[36m17044.5850\u001b[0m  0.0758\n",
            "      8    \u001b[36m12734.0631\u001b[0m  0.0737\n",
            "      9     \u001b[36m8723.8214\u001b[0m  0.0760\n",
            "     10     \u001b[36m5005.3754\u001b[0m  0.0868\n",
            "     11     \u001b[36m3681.6532\u001b[0m  0.0758\n",
            "     12     \u001b[36m2872.4322\u001b[0m  0.0738\n",
            "     13     \u001b[36m2505.1227\u001b[0m  0.0733\n",
            "     14     2789.3615  0.0754\n",
            "     15     2784.7149  0.0770\n",
            "     16     \u001b[36m2041.7680\u001b[0m  0.0751\n",
            "     17     2248.8424  0.0746\n",
            "     18     \u001b[36m1964.7136\u001b[0m  0.0727\n",
            "     19     \u001b[36m1801.1991\u001b[0m  0.0772\n",
            "     20     \u001b[36m1702.6124\u001b[0m  0.0763\n",
            "     21     \u001b[36m1596.8001\u001b[0m  0.0714\n",
            "     22     \u001b[36m1523.8025\u001b[0m  0.0810\n",
            "     23     \u001b[36m1369.9092\u001b[0m  0.0851\n",
            "     24     1423.5220  0.0752\n",
            "     25     \u001b[36m1190.8193\u001b[0m  0.0735\n",
            "     26     \u001b[36m1165.5362\u001b[0m  0.0848\n",
            "     27     \u001b[36m1107.7812\u001b[0m  0.0805\n",
            "     28     1144.7726  0.0750\n",
            "     29     \u001b[36m1069.2860\u001b[0m  0.0767\n",
            "     30     1069.8306  0.0758\n",
            "     31     \u001b[36m1018.2747\u001b[0m  0.0735\n",
            "     32      \u001b[36m902.5800\u001b[0m  0.0836\n",
            "     33      \u001b[36m743.0362\u001b[0m  0.0757\n",
            "     34      \u001b[36m741.9751\u001b[0m  0.0767\n",
            "     35      \u001b[36m716.8657\u001b[0m  0.0827\n",
            "     36      \u001b[36m565.4709\u001b[0m  0.0755\n",
            "     37      629.8198  0.0742\n",
            "     38      580.2715  0.0761\n",
            "     39      637.0672  0.0749\n",
            "     40      \u001b[36m554.3215\u001b[0m  0.0749\n",
            "     41      \u001b[36m438.7581\u001b[0m  0.0849\n",
            "     42      \u001b[36m427.8120\u001b[0m  0.0762\n",
            "     43      478.0732  0.0760\n",
            "     44      \u001b[36m400.6749\u001b[0m  0.0769\n",
            "     45      422.7884  0.0788\n",
            "     46      \u001b[36m385.4119\u001b[0m  0.0719\n",
            "     47      \u001b[36m329.9147\u001b[0m  0.0743\n",
            "     48      368.8538  0.0851\n",
            "     49      \u001b[36m297.9875\u001b[0m  0.0746\n",
            "     50      \u001b[36m264.4633\u001b[0m  0.0814\n",
            "     51      \u001b[36m241.4208\u001b[0m  0.0745\n",
            "     52      247.1294  0.0803\n",
            "     53      \u001b[36m227.3080\u001b[0m  0.0745\n",
            "     54      \u001b[36m212.9307\u001b[0m  0.0748\n",
            "     55      \u001b[36m192.3683\u001b[0m  0.0807\n",
            "     56      233.2801  0.0751\n",
            "     57      192.5185  0.0809\n",
            "     58      \u001b[36m188.0896\u001b[0m  0.0722\n",
            "     59      \u001b[36m148.3899\u001b[0m  0.0749\n",
            "     60      193.6883  0.0818\n",
            "     61      \u001b[36m145.1932\u001b[0m  0.0861\n",
            "     62      \u001b[36m124.0407\u001b[0m  0.0784\n",
            "     63      138.3152  0.0758\n",
            "     64      135.8858  0.0818\n",
            "     65      144.1580  0.0770\n",
            "     66      126.8858  0.0729\n",
            "     67      \u001b[36m103.4334\u001b[0m  0.0760\n",
            "     68      110.2926  0.0729\n",
            "     69       \u001b[36m89.2844\u001b[0m  0.0755\n",
            "     70       92.5426  0.0707\n",
            "     71       \u001b[36m82.1285\u001b[0m  0.0713\n",
            "     72       87.8648  0.0747\n",
            "     73       \u001b[36m72.9512\u001b[0m  0.0733\n",
            "     74       \u001b[36m61.7530\u001b[0m  0.0880\n",
            "     75       70.7404  0.0748\n",
            "     76       74.6841  0.0793\n",
            "     77       62.5045  0.0744\n",
            "     78       67.4927  0.0775\n",
            "     79       \u001b[36m55.3210\u001b[0m  0.0813\n",
            "     80       \u001b[36m51.1630\u001b[0m  0.0757\n",
            "     81       56.9085  0.0748\n",
            "     82       51.3483  0.0781\n",
            "     83       \u001b[36m40.8800\u001b[0m  0.0741\n",
            "     84       \u001b[36m40.5911\u001b[0m  0.0743\n",
            "     85       \u001b[36m40.2638\u001b[0m  0.0755\n",
            "     86       \u001b[36m40.1572\u001b[0m  0.0819\n",
            "     87       \u001b[36m32.8576\u001b[0m  0.0856\n",
            "     88       35.4272  0.0742\n",
            "     89       \u001b[36m30.8192\u001b[0m  0.0751\n",
            "     90       \u001b[36m30.4646\u001b[0m  0.0834\n",
            "     91       \u001b[36m28.7768\u001b[0m  0.0846\n",
            "     92       \u001b[36m23.0396\u001b[0m  0.0801\n",
            "     93       26.5972  0.0797\n",
            "     94       \u001b[36m22.0120\u001b[0m  0.0793\n",
            "     95       \u001b[36m21.7846\u001b[0m  0.0792\n",
            "     96       \u001b[36m20.7967\u001b[0m  0.0727\n",
            "     97       23.2372  0.0743\n",
            "     98       \u001b[36m19.1183\u001b[0m  0.0789\n",
            "     99       \u001b[36m18.6756\u001b[0m  0.0852\n",
            "    100       \u001b[36m17.6264\u001b[0m  0.0765\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m98420.0045\u001b[0m  0.0807\n",
            "      2    \u001b[36m77855.3753\u001b[0m  0.0767\n",
            "      3    \u001b[36m62935.2191\u001b[0m  0.0742\n",
            "      4    \u001b[36m50220.2705\u001b[0m  0.0790\n",
            "      5    \u001b[36m38994.5702\u001b[0m  0.0755\n",
            "      6    \u001b[36m31107.9623\u001b[0m  0.0883\n",
            "      7    \u001b[36m24572.1859\u001b[0m  0.0792\n",
            "      8    \u001b[36m18530.2432\u001b[0m  0.0748\n",
            "      9    \u001b[36m14107.2197\u001b[0m  0.0779\n",
            "     10    \u001b[36m10068.6343\u001b[0m  0.0756\n",
            "     11     \u001b[36m6981.8487\u001b[0m  0.0815\n",
            "     12     \u001b[36m3686.7755\u001b[0m  0.0879\n",
            "     13     \u001b[36m2571.1974\u001b[0m  0.0771\n",
            "     14     \u001b[36m2307.2365\u001b[0m  0.0764\n",
            "     15     \u001b[36m2281.7376\u001b[0m  0.0767\n",
            "     16     \u001b[36m2187.7586\u001b[0m  0.0843\n",
            "     17     \u001b[36m2171.1783\u001b[0m  0.0814\n",
            "     18     \u001b[36m1642.7075\u001b[0m  0.0802\n",
            "     19     \u001b[36m1570.7094\u001b[0m  0.0761\n",
            "     20     1874.5212  0.0753\n",
            "     21     \u001b[36m1569.3949\u001b[0m  0.0775\n",
            "     22     \u001b[36m1477.9863\u001b[0m  0.0747\n",
            "     23     1484.1442  0.0817\n",
            "     24     1527.5952  0.0826\n",
            "     25     \u001b[36m1437.8619\u001b[0m  0.0737\n",
            "     26     \u001b[36m1299.3319\u001b[0m  0.0730\n",
            "     27     \u001b[36m1141.1693\u001b[0m  0.0849\n",
            "     28     \u001b[36m1078.3097\u001b[0m  0.0800\n",
            "     29     1202.7824  0.0753\n",
            "     30      \u001b[36m850.4144\u001b[0m  0.0728\n",
            "     31     1064.0852  0.0774\n",
            "     32     1012.1133  0.0743\n",
            "     33      907.2293  0.0754\n",
            "     34      879.3184  0.0816\n",
            "     35      933.2141  0.0766\n",
            "     36      \u001b[36m747.5223\u001b[0m  0.0772\n",
            "     37      \u001b[36m701.5401\u001b[0m  0.0882\n",
            "     38      718.6445  0.0885\n",
            "     39      \u001b[36m643.6145\u001b[0m  0.0764\n",
            "     40      673.1783  0.0757\n",
            "     41      \u001b[36m560.0785\u001b[0m  0.0772\n",
            "     42      592.6866  0.0779\n",
            "     43      \u001b[36m543.3091\u001b[0m  0.0802\n",
            "     44      \u001b[36m433.2140\u001b[0m  0.0763\n",
            "     45      \u001b[36m421.1905\u001b[0m  0.0811\n",
            "     46      \u001b[36m400.4285\u001b[0m  0.0773\n",
            "     47      437.4829  0.0727\n",
            "     48      \u001b[36m342.5482\u001b[0m  0.0759\n",
            "     49      \u001b[36m334.9832\u001b[0m  0.0746\n",
            "     50      339.9926  0.0921\n",
            "     51      \u001b[36m327.5401\u001b[0m  0.0766\n",
            "     52      \u001b[36m267.3284\u001b[0m  0.0758\n",
            "     53      318.2778  0.0910\n",
            "     54      286.5956  0.0752\n",
            "     55      \u001b[36m252.5748\u001b[0m  0.0838\n",
            "     56      255.5841  0.0761\n",
            "     57      \u001b[36m216.6976\u001b[0m  0.0789\n",
            "     58      228.3961  0.0777\n",
            "     59      \u001b[36m172.2054\u001b[0m  0.0805\n",
            "     60      204.2544  0.0813\n",
            "     61      \u001b[36m140.7550\u001b[0m  0.0777\n",
            "     62      174.3023  0.0847\n",
            "     63      161.3798  0.0764\n",
            "     64      159.1334  0.0878\n",
            "     65      141.4963  0.0849\n",
            "     66      147.7383  0.0752\n",
            "     67      149.2445  0.0788\n",
            "     68      \u001b[36m139.0733\u001b[0m  0.0822\n",
            "     69      \u001b[36m113.2290\u001b[0m  0.0785\n",
            "     70      116.9367  0.0803\n",
            "     71      \u001b[36m101.0530\u001b[0m  0.0753\n",
            "     72       \u001b[36m92.0669\u001b[0m  0.0743\n",
            "     73       95.1933  0.0770\n",
            "     74       \u001b[36m74.1266\u001b[0m  0.0763\n",
            "     75       99.8006  0.0867\n",
            "     76       76.5851  0.0700\n",
            "     77       89.8078  0.0743\n",
            "     78       80.1890  0.0756\n",
            "     79       \u001b[36m72.7142\u001b[0m  0.0755\n",
            "     80       \u001b[36m68.6981\u001b[0m  0.0768\n",
            "     81       \u001b[36m65.0501\u001b[0m  0.0763\n",
            "     82       \u001b[36m60.5692\u001b[0m  0.0752\n",
            "     83       64.6553  0.0888\n",
            "     84       \u001b[36m58.1710\u001b[0m  0.0771\n",
            "     85       58.7633  0.0767\n",
            "     86       \u001b[36m53.4659\u001b[0m  0.0861\n",
            "     87       54.1808  0.0891\n",
            "     88       \u001b[36m48.3482\u001b[0m  0.0776\n",
            "     89       \u001b[36m47.7025\u001b[0m  0.0744\n",
            "     90       \u001b[36m40.8833\u001b[0m  0.0760\n",
            "     91       40.9788  0.0771\n",
            "     92       43.2017  0.0793\n",
            "     93       \u001b[36m37.4701\u001b[0m  0.0755\n",
            "     94       40.8612  0.0754\n",
            "     95       \u001b[36m36.7122\u001b[0m  0.0777\n",
            "     96       \u001b[36m27.8681\u001b[0m  0.0771\n",
            "     97       27.9547  0.0810\n",
            "     98       33.8173  0.0791\n",
            "     99       32.2814  0.0798\n",
            "    100       31.0437  0.0875\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m79267.8958\u001b[0m  0.0798\n",
            "      2    \u001b[36m61958.5956\u001b[0m  0.0787\n",
            "      3    \u001b[36m47491.8549\u001b[0m  0.0777\n",
            "      4    \u001b[36m36690.2788\u001b[0m  0.0767\n",
            "      5    \u001b[36m28449.4279\u001b[0m  0.0726\n",
            "      6    \u001b[36m19982.4884\u001b[0m  0.0749\n",
            "      7    \u001b[36m12699.4732\u001b[0m  0.0755\n",
            "      8     \u001b[36m7080.2142\u001b[0m  0.0775\n",
            "      9     \u001b[36m4151.4357\u001b[0m  0.0763\n",
            "     10     \u001b[36m3193.1050\u001b[0m  0.0808\n",
            "     11     \u001b[36m2818.0329\u001b[0m  0.0761\n",
            "     12     2969.7173  0.0912\n",
            "     13     2903.8469  0.0742\n",
            "     14     \u001b[36m2666.6422\u001b[0m  0.0761\n",
            "     15     \u001b[36m2148.7718\u001b[0m  0.0777\n",
            "     16     \u001b[36m2070.7958\u001b[0m  0.0821\n",
            "     17     2261.4411  0.0783\n",
            "     18     \u001b[36m2024.0919\u001b[0m  0.0758\n",
            "     19     \u001b[36m1829.6779\u001b[0m  0.0750\n",
            "     20     \u001b[36m1782.7616\u001b[0m  0.0747\n",
            "     21     \u001b[36m1640.2601\u001b[0m  0.0765\n",
            "     22     \u001b[36m1634.8074\u001b[0m  0.0738\n",
            "     23     \u001b[36m1425.8817\u001b[0m  0.1079\n",
            "     24     1790.7495  0.0855\n",
            "     25     \u001b[36m1347.3828\u001b[0m  0.0738\n",
            "     26     \u001b[36m1340.6524\u001b[0m  0.0730\n",
            "     27     \u001b[36m1188.6966\u001b[0m  0.0838\n",
            "     28     1252.1696  0.0788\n",
            "     29     \u001b[36m1050.0240\u001b[0m  0.0771\n",
            "     30     1134.7695  0.0799\n",
            "     31      \u001b[36m981.8186\u001b[0m  0.0783\n",
            "     32      \u001b[36m788.6280\u001b[0m  0.0803\n",
            "     33      969.7858  0.0763\n",
            "     34      798.8343  0.0750\n",
            "     35      \u001b[36m763.8435\u001b[0m  0.0757\n",
            "     36      \u001b[36m726.4481\u001b[0m  0.0769\n",
            "     37      734.0462  0.0946\n",
            "     38      \u001b[36m571.9598\u001b[0m  0.0828\n",
            "     39      590.2098  0.0779\n",
            "     40      \u001b[36m525.4890\u001b[0m  0.0766\n",
            "     41      \u001b[36m454.9927\u001b[0m  0.0789\n",
            "     42      480.8633  0.0751\n",
            "     43      \u001b[36m439.2804\u001b[0m  0.0770\n",
            "     44      450.5896  0.0762\n",
            "     45      452.7401  0.0833\n",
            "     46      \u001b[36m432.7354\u001b[0m  0.0744\n",
            "     47      \u001b[36m401.7860\u001b[0m  0.0736\n",
            "     48      \u001b[36m365.3892\u001b[0m  0.0744\n",
            "     49      \u001b[36m277.9100\u001b[0m  0.0859\n",
            "     50      291.9040  0.0846\n",
            "     51      281.8213  0.0792\n",
            "     52      \u001b[36m265.0309\u001b[0m  0.0777\n",
            "     53      \u001b[36m256.9875\u001b[0m  0.0829\n",
            "     54      \u001b[36m220.1414\u001b[0m  0.0813\n",
            "     55      226.3997  0.0749\n",
            "     56      233.1813  0.0767\n",
            "     57      \u001b[36m218.1231\u001b[0m  0.0747\n",
            "     58      \u001b[36m179.8564\u001b[0m  0.0761\n",
            "     59      \u001b[36m172.5637\u001b[0m  0.0796\n",
            "     60      \u001b[36m152.5847\u001b[0m  0.0811\n",
            "     61      161.2975  0.0762\n",
            "     62      \u001b[36m151.0347\u001b[0m  0.0827\n",
            "     63      \u001b[36m133.0855\u001b[0m  0.0773\n",
            "     64      \u001b[36m129.6373\u001b[0m  0.0757\n",
            "     65      137.7512  0.0855\n",
            "     66      142.2295  0.0741\n",
            "     67      \u001b[36m123.0682\u001b[0m  0.0732\n",
            "     68      124.7727  0.0733\n",
            "     69      \u001b[36m107.3330\u001b[0m  0.0761\n",
            "     70       \u001b[36m97.0096\u001b[0m  0.0765\n",
            "     71      112.6013  0.0817\n",
            "     72       \u001b[36m91.9689\u001b[0m  0.0766\n",
            "     73       \u001b[36m90.0491\u001b[0m  0.0748\n",
            "     74       \u001b[36m81.5970\u001b[0m  0.0845\n",
            "     75       \u001b[36m78.0674\u001b[0m  0.0936\n",
            "     76       91.7961  0.0848\n",
            "     77       \u001b[36m60.6576\u001b[0m  0.0800\n",
            "     78       \u001b[36m59.5307\u001b[0m  0.0763\n",
            "     79       62.5308  0.0779\n",
            "     80       \u001b[36m57.4513\u001b[0m  0.0773\n",
            "     81       \u001b[36m51.4423\u001b[0m  0.0843\n",
            "     82       66.3231  0.0763\n",
            "     83       \u001b[36m47.9602\u001b[0m  0.0759\n",
            "     84       59.0601  0.0754\n",
            "     85       \u001b[36m46.3921\u001b[0m  0.0748\n",
            "     86       51.2839  0.0847\n",
            "     87       \u001b[36m42.8570\u001b[0m  0.0851\n",
            "     88       \u001b[36m42.1028\u001b[0m  0.0766\n",
            "     89       \u001b[36m39.9053\u001b[0m  0.0758\n",
            "     90       \u001b[36m38.4154\u001b[0m  0.0776\n",
            "     91       \u001b[36m35.7904\u001b[0m  0.0774\n",
            "     92       \u001b[36m34.1803\u001b[0m  0.0742\n",
            "     93       35.9343  0.0763\n",
            "     94       \u001b[36m26.5793\u001b[0m  0.0756\n",
            "     95       29.1882  0.0779\n",
            "     96       \u001b[36m23.2939\u001b[0m  0.0784\n",
            "     97       31.1278  0.0790\n",
            "     98       27.5925  0.0810\n",
            "     99       27.7563  0.0767\n",
            "    100       \u001b[36m20.6805\u001b[0m  0.0868\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m82596.2370\u001b[0m  0.0729\n",
            "      2    \u001b[36m64511.9383\u001b[0m  0.0812\n",
            "      3    \u001b[36m51019.7827\u001b[0m  0.0754\n",
            "      4    \u001b[36m40812.8136\u001b[0m  0.0809\n",
            "      5    \u001b[36m31237.2581\u001b[0m  0.0799\n",
            "      6    \u001b[36m25368.9066\u001b[0m  0.0802\n",
            "      7    \u001b[36m19226.3115\u001b[0m  0.0741\n",
            "      8    \u001b[36m14194.4694\u001b[0m  0.0778\n",
            "      9     \u001b[36m9568.1073\u001b[0m  0.0842\n",
            "     10     \u001b[36m6811.9639\u001b[0m  0.0758\n",
            "     11     \u001b[36m3730.5957\u001b[0m  0.0753\n",
            "     12     \u001b[36m2246.4516\u001b[0m  0.0925\n",
            "     13     \u001b[36m1719.4992\u001b[0m  0.0775\n",
            "     14     \u001b[36m1650.0693\u001b[0m  0.0793\n",
            "     15     \u001b[36m1492.7213\u001b[0m  0.0733\n",
            "     16     \u001b[36m1432.6998\u001b[0m  0.0810\n",
            "     17     \u001b[36m1106.0409\u001b[0m  0.0772\n",
            "     18     1303.3165  0.0811\n",
            "     19     1214.6347  0.0772\n",
            "     20     \u001b[36m1086.4459\u001b[0m  0.0760\n",
            "     21      \u001b[36m929.0038\u001b[0m  0.0810\n",
            "     22     1138.5695  0.0765\n",
            "     23      931.8728  0.0821\n",
            "     24      \u001b[36m775.5103\u001b[0m  0.0762\n",
            "     25      834.7446  0.0869\n",
            "     26      \u001b[36m747.4364\u001b[0m  0.0782\n",
            "     27      925.2325  0.0762\n",
            "     28      \u001b[36m714.0024\u001b[0m  0.0777\n",
            "     29      718.5395  0.0759\n",
            "     30      \u001b[36m710.6595\u001b[0m  0.0766\n",
            "     31      \u001b[36m630.2719\u001b[0m  0.0789\n",
            "     32      \u001b[36m587.2281\u001b[0m  0.0822\n",
            "     33      \u001b[36m517.4481\u001b[0m  0.0765\n",
            "     34      530.7795  0.0833\n",
            "     35      627.5549  0.0765\n",
            "     36      \u001b[36m510.8985\u001b[0m  0.0750\n",
            "     37      \u001b[36m491.1286\u001b[0m  0.0857\n",
            "     38      \u001b[36m413.5243\u001b[0m  0.0828\n",
            "     39      415.7718  0.0786\n",
            "     40      \u001b[36m380.7593\u001b[0m  0.0761\n",
            "     41      402.6322  0.0767\n",
            "     42      \u001b[36m357.0484\u001b[0m  0.0768\n",
            "     43      \u001b[36m310.9091\u001b[0m  0.0766\n",
            "     44      \u001b[36m251.9645\u001b[0m  0.0770\n",
            "     45      270.2411  0.0802\n",
            "     46      275.0044  0.0767\n",
            "     47      295.1029  0.0758\n",
            "     48      277.5777  0.0755\n",
            "     49      \u001b[36m245.0247\u001b[0m  0.0753\n",
            "     50      263.6917  0.0877\n",
            "     51      251.6657  0.0784\n",
            "     52      \u001b[36m220.0984\u001b[0m  0.0924\n",
            "     53      \u001b[36m203.5289\u001b[0m  0.0771\n",
            "     54      \u001b[36m183.1947\u001b[0m  0.0818\n",
            "     55      183.3045  0.0736\n",
            "     56      \u001b[36m165.1446\u001b[0m  0.0730\n",
            "     57      \u001b[36m152.5904\u001b[0m  0.0726\n",
            "     58      169.2501  0.0736\n",
            "     59      \u001b[36m150.2787\u001b[0m  0.0770\n",
            "     60      \u001b[36m132.4526\u001b[0m  0.0825\n",
            "     61      132.4657  0.0751\n",
            "     62      \u001b[36m132.1817\u001b[0m  0.0761\n",
            "     63      \u001b[36m131.8039\u001b[0m  0.0882\n",
            "     64      147.0874  0.0752\n",
            "     65      \u001b[36m100.7283\u001b[0m  0.0741\n",
            "     66       \u001b[36m94.2443\u001b[0m  0.0805\n",
            "     67      101.4955  0.0790\n",
            "     68      114.1840  0.0819\n",
            "     69       \u001b[36m81.6575\u001b[0m  0.0802\n",
            "     70       89.7194  0.0768\n",
            "     71       \u001b[36m80.0424\u001b[0m  0.0841\n",
            "     72       \u001b[36m70.8425\u001b[0m  0.0832\n",
            "     73       72.3883  0.0740\n",
            "     74       \u001b[36m68.9408\u001b[0m  0.0767\n",
            "     75       \u001b[36m58.6937\u001b[0m  0.0836\n",
            "     76       \u001b[36m57.1298\u001b[0m  0.0817\n",
            "     77       60.5770  0.0726\n",
            "     78       \u001b[36m49.9608\u001b[0m  0.0793\n",
            "     79       \u001b[36m46.8420\u001b[0m  0.0793\n",
            "     80       53.3774  0.0793\n",
            "     81       47.5272  0.0764\n",
            "     82       47.8078  0.0801\n",
            "     83       \u001b[36m45.7247\u001b[0m  0.0772\n",
            "     84       \u001b[36m41.1453\u001b[0m  0.0808\n",
            "     85       \u001b[36m34.6603\u001b[0m  0.0755\n",
            "     86       36.7640  0.0773\n",
            "     87       \u001b[36m24.7112\u001b[0m  0.0784\n",
            "     88       34.9844  0.0945\n",
            "     89       33.5269  0.0775\n",
            "     90       \u001b[36m21.5530\u001b[0m  0.0813\n",
            "     91       33.0094  0.0790\n",
            "     92       27.2316  0.0767\n",
            "     93       26.7546  0.0783\n",
            "     94       28.5123  0.0808\n",
            "     95       \u001b[36m19.1933\u001b[0m  0.0782\n",
            "     96       21.4664  0.0766\n",
            "     97       \u001b[36m17.8106\u001b[0m  0.0845\n",
            "     98       19.7095  0.0784\n",
            "     99       \u001b[36m17.0874\u001b[0m  0.0774\n",
            "    100       \u001b[36m15.8914\u001b[0m  0.0893\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m74821.0418\u001b[0m  0.0809\n",
            "      2    \u001b[36m60055.6910\u001b[0m  0.0766\n",
            "      3    \u001b[36m46524.7363\u001b[0m  0.0775\n",
            "      4    \u001b[36m34508.6691\u001b[0m  0.0784\n",
            "      5    \u001b[36m24305.5170\u001b[0m  0.0771\n",
            "      6    \u001b[36m17133.5144\u001b[0m  0.0756\n",
            "      7    \u001b[36m10952.7601\u001b[0m  0.0771\n",
            "      8     \u001b[36m6471.9575\u001b[0m  0.0835\n",
            "      9     \u001b[36m4323.4916\u001b[0m  0.0754\n",
            "     10     \u001b[36m3206.9833\u001b[0m  0.0763\n",
            "     11     3406.4676  0.0767\n",
            "     12     \u001b[36m2589.6709\u001b[0m  0.0810\n",
            "     13     2999.2701  0.0863\n",
            "     14     2647.8356  0.0763\n",
            "     15     \u001b[36m2555.2406\u001b[0m  0.0769\n",
            "     16     \u001b[36m2373.5178\u001b[0m  0.0784\n",
            "     17     2409.8611  0.0762\n",
            "     18     \u001b[36m2050.0461\u001b[0m  0.0802\n",
            "     19     \u001b[36m1804.2715\u001b[0m  0.0828\n",
            "     20     1923.2773  0.0769\n",
            "     21     \u001b[36m1691.8644\u001b[0m  0.0781\n",
            "     22     1735.2419  0.0761\n",
            "     23     \u001b[36m1608.0106\u001b[0m  0.0782\n",
            "     24     \u001b[36m1381.8937\u001b[0m  0.0785\n",
            "     25     \u001b[36m1366.0249\u001b[0m  0.0930\n",
            "     26     \u001b[36m1099.2619\u001b[0m  0.0771\n",
            "     27     \u001b[36m1097.4340\u001b[0m  0.0766\n",
            "     28     \u001b[36m1084.9060\u001b[0m  0.0772\n",
            "     29      \u001b[36m961.7022\u001b[0m  0.0797\n",
            "     30      \u001b[36m901.9258\u001b[0m  0.0767\n",
            "     31      \u001b[36m811.5533\u001b[0m  0.0768\n",
            "     32      851.2469  0.0805\n",
            "     33      \u001b[36m800.6456\u001b[0m  0.0857\n",
            "     34      \u001b[36m686.0424\u001b[0m  0.0763\n",
            "     35      702.7697  0.0799\n",
            "     36      691.7402  0.0793\n",
            "     37      \u001b[36m636.4901\u001b[0m  0.0827\n",
            "     38      \u001b[36m541.0990\u001b[0m  0.0845\n",
            "     39      560.2930  0.0823\n",
            "     40      \u001b[36m453.7098\u001b[0m  0.0781\n",
            "     41      \u001b[36m415.2808\u001b[0m  0.0801\n",
            "     42      \u001b[36m376.6610\u001b[0m  0.0780\n",
            "     43      483.9951  0.0764\n",
            "     44      \u001b[36m356.8472\u001b[0m  0.0881\n",
            "     45      \u001b[36m316.7433\u001b[0m  0.0755\n",
            "     46      339.8660  0.0817\n",
            "     47      \u001b[36m253.0908\u001b[0m  0.0793\n",
            "     48      273.3373  0.0774\n",
            "     49      336.7433  0.0835\n",
            "     50      278.0908  0.0865\n",
            "     51      \u001b[36m225.7771\u001b[0m  0.0854\n",
            "     52      237.2873  0.0778\n",
            "     53      239.2117  0.0864\n",
            "     54      \u001b[36m212.1172\u001b[0m  0.0824\n",
            "     55      \u001b[36m166.2008\u001b[0m  0.0828\n",
            "     56      183.9480  0.0839\n",
            "     57      \u001b[36m165.2705\u001b[0m  0.0785\n",
            "     58      169.0970  0.0772\n",
            "     59      \u001b[36m162.7443\u001b[0m  0.0790\n",
            "     60      \u001b[36m140.3768\u001b[0m  0.0815\n",
            "     61      164.6014  0.0817\n",
            "     62      \u001b[36m139.4646\u001b[0m  0.0905\n",
            "     63      \u001b[36m122.4492\u001b[0m  0.0803\n",
            "     64      \u001b[36m109.4147\u001b[0m  0.0759\n",
            "     65      116.7824  0.0738\n",
            "     66      110.7482  0.0744\n",
            "     67      \u001b[36m100.2335\u001b[0m  0.0790\n",
            "     68      107.5246  0.0745\n",
            "     69       \u001b[36m91.1786\u001b[0m  0.0762\n",
            "     70       94.9585  0.0839\n",
            "     71      100.2663  0.0768\n",
            "     72      100.4372  0.0755\n",
            "     73       \u001b[36m77.0206\u001b[0m  0.0775\n",
            "     74       \u001b[36m75.5030\u001b[0m  0.0775\n",
            "     75       \u001b[36m70.3808\u001b[0m  0.0894\n",
            "     76       73.6387  0.0820\n",
            "     77       \u001b[36m62.0291\u001b[0m  0.0772\n",
            "     78       \u001b[36m61.5847\u001b[0m  0.0780\n",
            "     79       \u001b[36m53.8161\u001b[0m  0.0957\n",
            "     80       \u001b[36m47.6405\u001b[0m  0.0835\n",
            "     81       49.4175  0.0835\n",
            "     82       49.0916  0.0773\n",
            "     83       \u001b[36m45.8125\u001b[0m  0.0763\n",
            "     84       50.6909  0.0742\n",
            "     85       \u001b[36m43.6752\u001b[0m  0.0788\n",
            "     86       \u001b[36m33.6925\u001b[0m  0.0782\n",
            "     87       37.8075  0.0847\n",
            "     88       36.3315  0.0764\n",
            "     89       35.8023  0.0786\n",
            "     90       \u001b[36m29.6805\u001b[0m  0.0790\n",
            "     91       30.3893  0.0767\n",
            "     92       \u001b[36m28.3263\u001b[0m  0.0840\n",
            "     93       \u001b[36m26.5819\u001b[0m  0.0766\n",
            "     94       \u001b[36m24.2826\u001b[0m  0.0759\n",
            "     95       24.8011  0.0808\n",
            "     96       \u001b[36m23.4747\u001b[0m  0.0815\n",
            "     97       \u001b[36m21.7793\u001b[0m  0.0818\n",
            "     98       \u001b[36m18.7776\u001b[0m  0.0813\n",
            "     99       19.3528  0.0870\n",
            "    100       19.7989  0.0772\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m76476.4695\u001b[0m  0.0714\n",
            "      2    \u001b[36m62133.9274\u001b[0m  0.0830\n",
            "      3    \u001b[36m48515.1493\u001b[0m  0.0751\n",
            "      4    \u001b[36m38515.5155\u001b[0m  0.0758\n",
            "      5    \u001b[36m29491.4057\u001b[0m  0.0754\n",
            "      6    \u001b[36m22856.4525\u001b[0m  0.0887\n",
            "      7    \u001b[36m16721.7424\u001b[0m  0.0762\n",
            "      8    \u001b[36m13138.4887\u001b[0m  0.0811\n",
            "      9     \u001b[36m9469.1786\u001b[0m  0.0787\n",
            "     10     \u001b[36m5739.0515\u001b[0m  0.0743\n",
            "     11     \u001b[36m3196.7010\u001b[0m  0.0764\n",
            "     12     \u001b[36m1925.6223\u001b[0m  0.0903\n",
            "     13     \u001b[36m1680.4069\u001b[0m  0.0807\n",
            "     14     1750.4342  0.0742\n",
            "     15     1737.3820  0.0752\n",
            "     16     \u001b[36m1355.5194\u001b[0m  0.0741\n",
            "     17     \u001b[36m1266.9030\u001b[0m  0.0819\n",
            "     18     1368.7572  0.0749\n",
            "     19     1417.8167  0.0790\n",
            "     20      \u001b[36m994.5706\u001b[0m  0.0763\n",
            "     21      \u001b[36m980.5494\u001b[0m  0.0775\n",
            "     22      \u001b[36m910.4258\u001b[0m  0.0750\n",
            "     23      \u001b[36m803.5727\u001b[0m  0.0763\n",
            "     24      875.0352  0.0774\n",
            "     25      811.4130  0.0872\n",
            "     26      \u001b[36m701.3979\u001b[0m  0.0749\n",
            "     27      \u001b[36m623.9694\u001b[0m  0.0796\n",
            "     28      649.4983  0.0751\n",
            "     29      656.6057  0.0837\n",
            "     30      \u001b[36m507.4052\u001b[0m  0.0760\n",
            "     31      703.4792  0.0791\n",
            "     32      563.7380  0.0766\n",
            "     33      \u001b[36m479.1625\u001b[0m  0.0822\n",
            "     34      517.4234  0.0758\n",
            "     35      513.6185  0.0763\n",
            "     36      523.6619  0.0754\n",
            "     37      \u001b[36m378.8403\u001b[0m  0.0950\n",
            "     38      \u001b[36m325.2552\u001b[0m  0.0771\n",
            "     39      384.9717  0.0827\n",
            "     40      375.3507  0.0774\n",
            "     41      \u001b[36m309.1634\u001b[0m  0.0798\n",
            "     42      \u001b[36m291.0053\u001b[0m  0.0755\n",
            "     43      \u001b[36m262.0232\u001b[0m  0.0812\n",
            "     44      \u001b[36m244.4715\u001b[0m  0.0783\n",
            "     45      263.5661  0.0782\n",
            "     46      253.2236  0.0790\n",
            "     47      \u001b[36m237.0981\u001b[0m  0.0768\n",
            "     48      \u001b[36m200.9494\u001b[0m  0.0757\n",
            "     49      \u001b[36m190.5222\u001b[0m  0.0765\n",
            "     50      \u001b[36m172.8753\u001b[0m  0.0866\n",
            "     51      \u001b[36m158.7764\u001b[0m  0.0827\n",
            "     52      175.8441  0.0761\n",
            "     53      158.9550  0.0770\n",
            "     54      \u001b[36m145.3967\u001b[0m  0.0835\n",
            "     55      150.4150  0.0749\n",
            "     56      \u001b[36m125.9967\u001b[0m  0.0831\n",
            "     57      131.0743  0.0763\n",
            "     58      \u001b[36m104.6070\u001b[0m  0.0800\n",
            "     59      105.3213  0.0839\n",
            "     60      \u001b[36m101.3954\u001b[0m  0.0761\n",
            "     61       \u001b[36m92.5065\u001b[0m  0.0803\n",
            "     62       93.7261  0.0856\n",
            "     63       \u001b[36m83.3496\u001b[0m  0.0744\n",
            "     64       \u001b[36m81.9052\u001b[0m  0.0757\n",
            "     65       \u001b[36m75.5095\u001b[0m  0.0751\n",
            "     66       \u001b[36m65.9719\u001b[0m  0.0838\n",
            "     67       \u001b[36m57.0437\u001b[0m  0.0740\n",
            "     68       \u001b[36m52.0840\u001b[0m  0.0737\n",
            "     69       \u001b[36m46.0931\u001b[0m  0.0754\n",
            "     70       \u001b[36m45.9511\u001b[0m  0.0770\n",
            "     71       \u001b[36m37.8751\u001b[0m  0.0778\n",
            "     72       38.6146  0.0791\n",
            "     73       \u001b[36m31.9538\u001b[0m  0.0784\n",
            "     74       \u001b[36m28.4771\u001b[0m  0.0759\n",
            "     75       \u001b[36m28.4654\u001b[0m  0.0872\n",
            "     76       \u001b[36m20.3243\u001b[0m  0.0765\n",
            "     77       21.5309  0.0829\n",
            "     78       \u001b[36m17.1988\u001b[0m  0.0845\n",
            "     79       21.2446  0.0762\n",
            "     80       \u001b[36m16.2666\u001b[0m  0.0751\n",
            "     81       17.3557  0.0775\n",
            "     82       18.9103  0.0765\n",
            "     83       \u001b[36m16.0427\u001b[0m  0.0780\n",
            "     84       \u001b[36m14.7939\u001b[0m  0.0755\n",
            "     85       \u001b[36m11.9422\u001b[0m  0.0792\n",
            "     86       13.3717  0.0831\n",
            "     87        \u001b[36m9.4133\u001b[0m  0.0865\n",
            "     88       10.1879  0.0795\n",
            "     89       10.6448  0.0778\n",
            "     90        \u001b[36m6.0076\u001b[0m  0.0792\n",
            "     91       11.3737  0.0818\n",
            "     92        8.0028  0.0806\n",
            "     93       13.6775  0.0742\n",
            "     94        9.0382  0.0738\n",
            "     95        \u001b[36m5.5624\u001b[0m  0.0788\n",
            "     96       10.5954  0.0762\n",
            "     97        6.7136  0.0751\n",
            "     98       13.7843  0.0838\n",
            "     99        \u001b[36m4.1644\u001b[0m  0.0762\n",
            "    100       13.3530  0.0886\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m84848.1989\u001b[0m  0.0770\n",
            "      2    \u001b[36m69250.7302\u001b[0m  0.0828\n",
            "      3    \u001b[36m55947.4300\u001b[0m  0.0779\n",
            "      4    \u001b[36m44340.9804\u001b[0m  0.0768\n",
            "      5    \u001b[36m33992.6138\u001b[0m  0.0768\n",
            "      6    \u001b[36m27358.6265\u001b[0m  0.0772\n",
            "      7    \u001b[36m20286.8939\u001b[0m  0.0791\n",
            "      8    \u001b[36m15022.2144\u001b[0m  0.0747\n",
            "      9     \u001b[36m9752.4672\u001b[0m  0.0848\n",
            "     10     \u001b[36m5773.4345\u001b[0m  0.0865\n",
            "     11     \u001b[36m3716.6586\u001b[0m  0.0771\n",
            "     12     \u001b[36m2791.6974\u001b[0m  0.0858\n",
            "     13     \u001b[36m2738.5173\u001b[0m  0.0914\n",
            "     14     \u001b[36m2248.0071\u001b[0m  0.0770\n",
            "     15     \u001b[36m1977.8748\u001b[0m  0.0766\n",
            "     16     \u001b[36m1863.4099\u001b[0m  0.0756\n",
            "     17     \u001b[36m1652.6700\u001b[0m  0.0763\n",
            "     18     \u001b[36m1555.1799\u001b[0m  0.0755\n",
            "     19     \u001b[36m1411.1345\u001b[0m  0.0779\n",
            "     20     1509.2622  0.0796\n",
            "     21     1469.9135  0.0756\n",
            "     22     1426.9171  0.0782\n",
            "     23     \u001b[36m1353.4231\u001b[0m  0.0743\n",
            "     24     \u001b[36m1232.4956\u001b[0m  0.0740\n",
            "     25     1374.3158  0.0841\n",
            "     26     \u001b[36m1095.1465\u001b[0m  0.0732\n",
            "     27      \u001b[36m984.7439\u001b[0m  0.0791\n",
            "     28      \u001b[36m907.1733\u001b[0m  0.0801\n",
            "     29     1043.1999  0.0801\n",
            "     30      962.8115  0.0760\n",
            "     31      \u001b[36m833.7639\u001b[0m  0.0788\n",
            "     32      900.8652  0.0763\n",
            "     33      \u001b[36m755.7651\u001b[0m  0.0737\n",
            "     34      789.2274  0.0818\n",
            "     35      \u001b[36m741.5868\u001b[0m  0.0763\n",
            "     36      \u001b[36m715.6510\u001b[0m  0.0779\n",
            "     37      \u001b[36m597.4738\u001b[0m  0.0793\n",
            "     38      629.3845  0.0829\n",
            "     39      \u001b[36m596.7903\u001b[0m  0.0858\n",
            "     40      \u001b[36m562.3638\u001b[0m  0.0759\n",
            "     41      604.8642  0.0745\n",
            "     42      \u001b[36m499.9109\u001b[0m  0.0749\n",
            "     43      530.0910  0.0757\n",
            "     44      \u001b[36m434.7930\u001b[0m  0.0773\n",
            "     45      \u001b[36m409.5922\u001b[0m  0.0740\n",
            "     46      428.9263  0.0806\n",
            "     47      458.7786  0.0773\n",
            "     48      \u001b[36m308.2062\u001b[0m  0.0817\n",
            "     49      366.5238  0.0781\n",
            "     50      343.1842  0.0889\n",
            "     51      \u001b[36m294.8325\u001b[0m  0.0857\n",
            "     52      338.0275  0.0774\n",
            "     53      343.9544  0.0754\n",
            "     54      \u001b[36m253.9257\u001b[0m  0.0770\n",
            "     55      286.9245  0.0833\n",
            "     56      310.0355  0.0785\n",
            "     57      \u001b[36m228.1825\u001b[0m  0.0796\n",
            "     58      229.6765  0.0770\n",
            "     59      242.5928  0.0754\n",
            "     60      \u001b[36m225.1239\u001b[0m  0.0770\n",
            "     61      \u001b[36m197.6008\u001b[0m  0.0769\n",
            "     62      \u001b[36m187.2920\u001b[0m  0.0763\n",
            "     63      \u001b[36m182.6764\u001b[0m  0.0894\n",
            "     64      \u001b[36m159.7598\u001b[0m  0.0755\n",
            "     65      \u001b[36m153.5381\u001b[0m  0.0801\n",
            "     66      170.4247  0.0746\n",
            "     67      158.8737  0.0800\n",
            "     68      \u001b[36m135.2339\u001b[0m  0.0798\n",
            "     69      \u001b[36m133.8153\u001b[0m  0.0805\n",
            "     70      \u001b[36m130.0356\u001b[0m  0.0797\n",
            "     71      \u001b[36m114.4107\u001b[0m  0.0744\n",
            "     72      114.6483  0.0752\n",
            "     73      114.5144  0.0757\n",
            "     74      \u001b[36m110.5178\u001b[0m  0.0767\n",
            "     75       \u001b[36m86.8707\u001b[0m  0.0917\n",
            "     76       91.8744  0.0766\n",
            "     77       93.0363  0.0820\n",
            "     78       \u001b[36m85.7131\u001b[0m  0.0758\n",
            "     79       88.6713  0.0754\n",
            "     80       \u001b[36m73.8335\u001b[0m  0.0787\n",
            "     81       79.6536  0.0808\n",
            "     82       \u001b[36m73.7736\u001b[0m  0.0781\n",
            "     83       \u001b[36m63.4682\u001b[0m  0.0770\n",
            "     84       \u001b[36m51.8925\u001b[0m  0.0775\n",
            "     85       52.7873  0.0741\n",
            "     86       \u001b[36m45.1685\u001b[0m  0.0774\n",
            "     87       60.6322  0.0815\n",
            "     88       \u001b[36m41.1478\u001b[0m  0.0930\n",
            "     89       \u001b[36m40.2332\u001b[0m  0.0761\n",
            "     90       \u001b[36m37.1844\u001b[0m  0.0751\n",
            "     91       \u001b[36m30.3162\u001b[0m  0.0742\n",
            "     92       39.8569  0.0753\n",
            "     93       39.2706  0.0852\n",
            "     94       30.8759  0.0808\n",
            "     95       \u001b[36m26.7480\u001b[0m  0.0805\n",
            "     96       27.5879  0.0753\n",
            "     97       30.0308  0.0761\n",
            "     98       \u001b[36m21.0731\u001b[0m  0.0776\n",
            "     99       22.1530  0.0769\n",
            "    100       \u001b[36m18.3048\u001b[0m  0.0832\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m72577.6848\u001b[0m  0.0720\n",
            "      2    \u001b[36m55882.0724\u001b[0m  0.0843\n",
            "      3    \u001b[36m43581.6623\u001b[0m  0.0748\n",
            "      4    \u001b[36m33226.6437\u001b[0m  0.0788\n",
            "      5    \u001b[36m24777.5730\u001b[0m  0.0824\n",
            "      6    \u001b[36m18009.3628\u001b[0m  0.0792\n",
            "      7    \u001b[36m12958.5995\u001b[0m  0.0770\n",
            "      8     \u001b[36m8155.2789\u001b[0m  0.0796\n",
            "      9     \u001b[36m5252.6062\u001b[0m  0.0761\n",
            "     10     \u001b[36m2527.3770\u001b[0m  0.0753\n",
            "     11     \u001b[36m1932.8947\u001b[0m  0.0747\n",
            "     12     2081.4474  0.0817\n",
            "     13     \u001b[36m1746.8240\u001b[0m  0.0958\n",
            "     14     1815.2903  0.0760\n",
            "     15     1795.8323  0.0739\n",
            "     16     \u001b[36m1700.7977\u001b[0m  0.0768\n",
            "     17     \u001b[36m1486.8053\u001b[0m  0.0797\n",
            "     18     \u001b[36m1404.8706\u001b[0m  0.0747\n",
            "     19     \u001b[36m1264.8514\u001b[0m  0.0749\n",
            "     20     1267.6887  0.0755\n",
            "     21     \u001b[36m1035.8720\u001b[0m  0.0754\n",
            "     22     1057.7717  0.0800\n",
            "     23     1256.0894  0.0747\n",
            "     24     \u001b[36m1019.8729\u001b[0m  0.0770\n",
            "     25      \u001b[36m907.7217\u001b[0m  0.0813\n",
            "     26      \u001b[36m791.0323\u001b[0m  0.0820\n",
            "     27      \u001b[36m709.9767\u001b[0m  0.0792\n",
            "     28      742.0261  0.0756\n",
            "     29      \u001b[36m648.5814\u001b[0m  0.0769\n",
            "     30      774.7963  0.0832\n",
            "     31      742.0972  0.0739\n",
            "     32      \u001b[36m531.4347\u001b[0m  0.0745\n",
            "     33      \u001b[36m473.4419\u001b[0m  0.0737\n",
            "     34      503.2468  0.0794\n",
            "     35      \u001b[36m452.6933\u001b[0m  0.0755\n",
            "     36      481.6133  0.0884\n",
            "     37      \u001b[36m383.8686\u001b[0m  0.0786\n",
            "     38      \u001b[36m337.4696\u001b[0m  0.0964\n",
            "     39      374.3857  0.0797\n",
            "     40      339.3642  0.0746\n",
            "     41      345.6120  0.0803\n",
            "     42      \u001b[36m302.7822\u001b[0m  0.0788\n",
            "     43      308.1057  0.0766\n",
            "     44      \u001b[36m289.5242\u001b[0m  0.0764\n",
            "     45      \u001b[36m232.0975\u001b[0m  0.0758\n",
            "     46      \u001b[36m200.7157\u001b[0m  0.0747\n",
            "     47      256.1088  0.0774\n",
            "     48      \u001b[36m187.2307\u001b[0m  0.0748\n",
            "     49      \u001b[36m181.4797\u001b[0m  0.0805\n",
            "     50      \u001b[36m175.3029\u001b[0m  0.0750\n",
            "     51      187.0536  0.0924\n",
            "     52      \u001b[36m163.7741\u001b[0m  0.0814\n",
            "     53      \u001b[36m139.2850\u001b[0m  0.0785\n",
            "     54      144.8161  0.0810\n",
            "     55      140.0787  0.0811\n",
            "     56      147.0078  0.0755\n",
            "     57      \u001b[36m123.9719\u001b[0m  0.0796\n",
            "     58      \u001b[36m120.8683\u001b[0m  0.0789\n",
            "     59      \u001b[36m103.9295\u001b[0m  0.0758\n",
            "     60      107.9260  0.0769\n",
            "     61       \u001b[36m94.7258\u001b[0m  0.0813\n",
            "     62       \u001b[36m88.1007\u001b[0m  0.0863\n",
            "     63       \u001b[36m86.1641\u001b[0m  0.0870\n",
            "     64       \u001b[36m75.8128\u001b[0m  0.0752\n",
            "     65       \u001b[36m65.1067\u001b[0m  0.0755\n",
            "     66       71.7719  0.0803\n",
            "     67       68.7858  0.0783\n",
            "     68       \u001b[36m55.2670\u001b[0m  0.0785\n",
            "     69       \u001b[36m52.4573\u001b[0m  0.0833\n",
            "     70       53.1379  0.0755\n",
            "     71       \u001b[36m46.8277\u001b[0m  0.0752\n",
            "     72       54.6191  0.0841\n",
            "     73       \u001b[36m36.4776\u001b[0m  0.0875\n",
            "     74       \u001b[36m34.2381\u001b[0m  0.0789\n",
            "     75       \u001b[36m28.5396\u001b[0m  0.0811\n",
            "     76       34.7527  0.0783\n",
            "     77       29.7899  0.0786\n",
            "     78       \u001b[36m26.9483\u001b[0m  0.0780\n",
            "     79       27.7501  0.0812\n",
            "     80       \u001b[36m23.6657\u001b[0m  0.0781\n",
            "     81       \u001b[36m21.0608\u001b[0m  0.0762\n",
            "     82       \u001b[36m18.6806\u001b[0m  0.0751\n",
            "     83       \u001b[36m12.1337\u001b[0m  0.0753\n",
            "     84       12.2074  0.0807\n",
            "     85        \u001b[36m9.7680\u001b[0m  0.0741\n",
            "     86       10.5608  0.0758\n",
            "     87       11.9217  0.0849\n",
            "     88        \u001b[36m9.3929\u001b[0m  0.0890\n",
            "     89       14.1588  0.0776\n",
            "     90       14.2303  0.0792\n",
            "     91       11.1704  0.0820\n",
            "     92        \u001b[36m8.8545\u001b[0m  0.0836\n",
            "     93       10.0417  0.0755\n",
            "     94        \u001b[36m7.9716\u001b[0m  0.0746\n",
            "     95       10.0429  0.0846\n",
            "     96        \u001b[36m5.9387\u001b[0m  0.0775\n",
            "     97        9.5840  0.0781\n",
            "     98        7.9591  0.0868\n",
            "     99        6.5707  0.0777\n",
            "    100        6.6135  0.0867\n"
          ]
        }
      ],
      "source": [
        "resultados = cross_val_score(classificador_sklearn, previsores, classe, cv = 10, scoring = 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "Oo-7dNLX4uGH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "995cddd6-34a8-4a2b-fa8a-4b3b1a189d85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6151315789473684, 0.05034554727581867)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "media = resultados.mean()\n",
        "desvio = resultados.std()\n",
        "media, desvio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "pvCjaX7D4xhj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25dc0712-93d6-471e-99d5-401c107d94e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.63157895, 0.56140351, 0.61403509, 0.63157895, 0.66666667,\n",
              "       0.66666667, 0.61403509, 0.49122807, 0.64912281, 0.625     ])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GridSearch"
      ],
      "metadata": {
        "id": "9BGFtYHn6Y3a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import skorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from skorch import NeuralNetBinaryClassifier"
      ],
      "metadata": {
        "id": "UJMEFsw7uvQu"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.__version__, skorch.__version__, sklearn.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syfdTEMrv2bA",
        "outputId": "8d936430-d9df-455b-90d3-392d47af20a4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('1.10.0+cu111', '0.11.0', '1.0.2')"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqdU-pA-v3Fw",
        "outputId": "fef31d68-20a0-46ed-ab21-437f305c1022"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa2c4af7a90>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = pd.read_csv('entradas_breast.csv')\n",
        "classe = pd.read_csv('saidas_breast.csv')"
      ],
      "metadata": {
        "id": "Aay4sGOAv5UC"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = np.array(previsores, dtype = 'float32')\n",
        "classe = np.array(classe, dtype = 'float32').squeeze(1)"
      ],
      "metadata": {
        "id": "6Eqp79aIv7FO"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "previsores.shape, classe.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qxo3LjUv9Xc",
        "outputId": "171cc698-2d2d-42a4-d238-4931745e3090"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((569, 30), (569,))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "FNhrofs94zrg"
      },
      "outputs": [],
      "source": [
        "class classificador_torch(nn.Module):\n",
        "  def __init__(self, activation, neurons, initializer):\n",
        "    super().__init__()\n",
        "    # 30 -> 16 -> 16 -> 1\n",
        "    self.dense0 = nn.Linear(30, neurons)\n",
        "    initializer(self.dense0.weight)\n",
        "    self.activation0 = activation\n",
        "    self.dense1 = nn.Linear(neurons, neurons)\n",
        "    initializer(self.dense1.weight)\n",
        "    self.activation1 = activation\n",
        "    self.dense2 = nn.Linear(neurons, 1)\n",
        "    initializer(self.dense2.weight)\n",
        "    # self.output = nn.Sigmoid() ** ATUALIZAÇÃO (ver detalhes no texto acima) **\n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dense2(X)\n",
        "    # X = self.output(X) ** ATUALIZAÇÃO (ver detalhes no texto acima) **\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
        "                                                  lr = 0.001,\n",
        "                                                  optimizer__weight_decay = 0.0001,\n",
        "                                                  train_split=False)"
      ],
      "metadata": {
        "id": "sgi-P6VUwI55"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'batch_size': [10],\n",
        "          'max_epochs': [100],\n",
        "          'optimizer': [torch.optim.Adam, torch.optim.SGD],\n",
        "          'criterion': [torch.nn.BCEWithLogitsLoss], #, torch.nn.HingeEmbeddingLoss], # ** ATUALIZAÇÃO **\n",
        "          'module__activation': [F.relu, F.tanh],\n",
        "          'module__neurons': [8, 16], \n",
        "          'module__initializer': [torch.nn.init.uniform]} # _, torch.nn.init.normal_]}"
      ],
      "metadata": {
        "id": "aM02VQHixzmr"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = GridSearchCV(classificador_sklearn, params, scoring = 'accuracy', cv = 2)\n",
        "\n"
      ],
      "metadata": {
        "id": "ub5_9zI1s2pm"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid_search = grid_search.fit(previsores, classe)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEFDJSgfs7xp",
        "outputId": "62d91687-06bc-4be7-f951-abef9bdeb9ff"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m27299.8736\u001b[0m  0.0408\n",
            "      2    \u001b[36m24343.2036\u001b[0m  0.0393\n",
            "      3    \u001b[36m21607.9807\u001b[0m  0.0386\n",
            "      4    \u001b[36m19135.1212\u001b[0m  0.0387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5    \u001b[36m16931.4985\u001b[0m  0.0434\n",
            "      6    \u001b[36m14986.2365\u001b[0m  0.0373\n",
            "      7    \u001b[36m13263.7471\u001b[0m  0.0385\n",
            "      8    \u001b[36m11731.9747\u001b[0m  0.0378\n",
            "      9    \u001b[36m10367.9509\u001b[0m  0.0453\n",
            "     10     \u001b[36m9150.4847\u001b[0m  0.0389\n",
            "     11     \u001b[36m8060.7277\u001b[0m  0.0547\n",
            "     12     \u001b[36m7080.4200\u001b[0m  0.0416\n",
            "     13     \u001b[36m6192.2920\u001b[0m  0.0472\n",
            "     14     \u001b[36m5382.8836\u001b[0m  0.0402\n",
            "     15     \u001b[36m4640.1404\u001b[0m  0.0387\n",
            "     16     \u001b[36m3952.5611\u001b[0m  0.0402\n",
            "     17     \u001b[36m3309.9055\u001b[0m  0.0409\n",
            "     18     \u001b[36m2702.8676\u001b[0m  0.0387\n",
            "     19     \u001b[36m2122.0805\u001b[0m  0.0398\n",
            "     20     \u001b[36m1558.6191\u001b[0m  0.0380\n",
            "     21     \u001b[36m1003.4047\u001b[0m  0.0386\n",
            "     22      \u001b[36m478.4396\u001b[0m  0.0411\n",
            "     23      \u001b[36m138.4233\u001b[0m  0.0424\n",
            "     24       \u001b[36m90.7293\u001b[0m  0.0399\n",
            "     25       \u001b[36m88.3919\u001b[0m  0.0455\n",
            "     26       \u001b[36m77.7053\u001b[0m  0.0469\n",
            "     27       \u001b[36m70.4368\u001b[0m  0.0394\n",
            "     28       \u001b[36m64.3089\u001b[0m  0.0399\n",
            "     29       \u001b[36m58.6982\u001b[0m  0.0400\n",
            "     30       \u001b[36m54.5391\u001b[0m  0.0451\n",
            "     31       \u001b[36m52.0841\u001b[0m  0.0444\n",
            "     32       \u001b[36m48.6803\u001b[0m  0.0411\n",
            "     33       \u001b[36m46.1666\u001b[0m  0.0440\n",
            "     34       \u001b[36m44.8264\u001b[0m  0.0402\n",
            "     35       \u001b[36m43.1170\u001b[0m  0.0411\n",
            "     36       \u001b[36m41.1271\u001b[0m  0.0521\n",
            "     37       \u001b[36m40.8539\u001b[0m  0.0398\n",
            "     38       \u001b[36m40.7878\u001b[0m  0.0424\n",
            "     39       42.1404  0.0396\n",
            "     40       \u001b[36m39.8859\u001b[0m  0.0409\n",
            "     41       \u001b[36m37.9433\u001b[0m  0.0446\n",
            "     42       \u001b[36m36.3561\u001b[0m  0.0394\n",
            "     43       \u001b[36m36.2228\u001b[0m  0.0394\n",
            "     44       \u001b[36m35.5409\u001b[0m  0.0481\n",
            "     45       \u001b[36m34.3932\u001b[0m  0.0511\n",
            "     46       \u001b[36m33.9003\u001b[0m  0.0396\n",
            "     47       34.1501  0.0406\n",
            "     48       \u001b[36m33.6519\u001b[0m  0.0403\n",
            "     49       34.2759  0.0401\n",
            "     50       34.4157  0.0396\n",
            "     51       \u001b[36m33.4092\u001b[0m  0.0432\n",
            "     52       \u001b[36m33.3076\u001b[0m  0.0404\n",
            "     53       \u001b[36m32.6957\u001b[0m  0.0405\n",
            "     54       \u001b[36m31.9611\u001b[0m  0.0417\n",
            "     55       \u001b[36m31.2416\u001b[0m  0.0429\n",
            "     56       \u001b[36m30.4208\u001b[0m  0.0428\n",
            "     57       \u001b[36m30.0836\u001b[0m  0.0401\n",
            "     58       \u001b[36m29.8698\u001b[0m  0.0400\n",
            "     59       \u001b[36m29.7571\u001b[0m  0.0559\n",
            "     60       \u001b[36m29.4923\u001b[0m  0.0388\n",
            "     61       \u001b[36m29.1599\u001b[0m  0.0403\n",
            "     62       \u001b[36m28.8134\u001b[0m  0.0422\n",
            "     63       \u001b[36m28.4562\u001b[0m  0.0398\n",
            "     64       29.0983  0.0390\n",
            "     65       28.7392  0.0430\n",
            "     66       28.6527  0.0394\n",
            "     67       28.6344  0.0403\n",
            "     68       \u001b[36m28.3827\u001b[0m  0.0442\n",
            "     69       \u001b[36m28.2491\u001b[0m  0.0407\n",
            "     70       \u001b[36m27.5246\u001b[0m  0.0395\n",
            "     71       \u001b[36m26.0231\u001b[0m  0.0408\n",
            "     72       \u001b[36m24.8946\u001b[0m  0.0483\n",
            "     73       \u001b[36m22.6295\u001b[0m  0.0396\n",
            "     74       22.7438  0.0414\n",
            "     75       \u001b[36m22.5481\u001b[0m  0.0402\n",
            "     76       \u001b[36m22.4559\u001b[0m  0.0479\n",
            "     77       22.4942  0.0407\n",
            "     78       \u001b[36m22.3394\u001b[0m  0.0400\n",
            "     79       22.4535  0.0467\n",
            "     80       \u001b[36m21.7813\u001b[0m  0.0412\n",
            "     81       21.9436  0.0400\n",
            "     82       22.1564  0.0511\n",
            "     83       22.0973  0.0390\n",
            "     84       23.0600  0.0384\n",
            "     85       25.2159  0.0403\n",
            "     86       25.5142  0.0405\n",
            "     87       27.0222  0.0435\n",
            "     88       27.3080  0.0384\n",
            "     89       26.4661  0.0400\n",
            "     90       24.9383  0.0393\n",
            "     91       25.7029  0.0400\n",
            "     92       24.3999  0.0406\n",
            "     93       25.6702  0.0452\n",
            "     94       22.8678  0.0429\n",
            "     95       26.0338  0.0407\n",
            "     96       23.1988  0.0404\n",
            "     97       26.8979  0.0410\n",
            "     98       22.0646  0.0394\n",
            "     99       25.8061  0.0451\n",
            "    100       22.1818  0.0425\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m20767.3642\u001b[0m  0.0360\n",
            "      2    \u001b[36m18392.6938\u001b[0m  0.0398\n",
            "      3    \u001b[36m16303.1935\u001b[0m  0.0398\n",
            "      4    \u001b[36m14403.4171\u001b[0m  0.0434\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5    \u001b[36m12690.1410\u001b[0m  0.0563\n",
            "      6    \u001b[36m11149.3161\u001b[0m  0.0408\n",
            "      7     \u001b[36m9765.4888\u001b[0m  0.0416\n",
            "      8     \u001b[36m8523.4363\u001b[0m  0.0390\n",
            "      9     \u001b[36m7408.3096\u001b[0m  0.0391\n",
            "     10     \u001b[36m6405.5098\u001b[0m  0.0426\n",
            "     11     \u001b[36m5502.9312\u001b[0m  0.0389\n",
            "     12     \u001b[36m4687.3060\u001b[0m  0.0388\n",
            "     13     \u001b[36m3944.7730\u001b[0m  0.0458\n",
            "     14     \u001b[36m3263.5492\u001b[0m  0.0383\n",
            "     15     \u001b[36m2631.7705\u001b[0m  0.0447\n",
            "     16     \u001b[36m2037.1366\u001b[0m  0.0384\n",
            "     17     \u001b[36m1466.6371\u001b[0m  0.0394\n",
            "     18      \u001b[36m907.2859\u001b[0m  0.0402\n",
            "     19      \u001b[36m368.1897\u001b[0m  0.0394\n",
            "     20       \u001b[36m70.2290\u001b[0m  0.0388\n",
            "     21       \u001b[36m64.8931\u001b[0m  0.0422\n",
            "     22       \u001b[36m41.8883\u001b[0m  0.0403\n",
            "     23       \u001b[36m38.2925\u001b[0m  0.0400\n",
            "     24       \u001b[36m34.4358\u001b[0m  0.0431\n",
            "     25       \u001b[36m30.3832\u001b[0m  0.0390\n",
            "     26       \u001b[36m28.4991\u001b[0m  0.0384\n",
            "     27       \u001b[36m26.7977\u001b[0m  0.0390\n",
            "     28       27.0994  0.0383\n",
            "     29       \u001b[36m26.0353\u001b[0m  0.0486\n",
            "     30       \u001b[36m24.2245\u001b[0m  0.0404\n",
            "     31       \u001b[36m23.3312\u001b[0m  0.0398\n",
            "     32       \u001b[36m23.0973\u001b[0m  0.0395\n",
            "     33       \u001b[36m22.5641\u001b[0m  0.0380\n",
            "     34       \u001b[36m22.1781\u001b[0m  0.0483\n",
            "     35       \u001b[36m21.5842\u001b[0m  0.0388\n",
            "     36       \u001b[36m20.8129\u001b[0m  0.0391\n",
            "     37       \u001b[36m18.3122\u001b[0m  0.0400\n",
            "     38       \u001b[36m17.9072\u001b[0m  0.0402\n",
            "     39       18.7446  0.0390\n",
            "     40       18.8413  0.0386\n",
            "     41       18.2172  0.0388\n",
            "     42       \u001b[36m17.4941\u001b[0m  0.0388\n",
            "     43       \u001b[36m16.4748\u001b[0m  0.0406\n",
            "     44       \u001b[36m14.4956\u001b[0m  0.0449\n",
            "     45       14.7602  0.0414\n",
            "     46       15.1155  0.0405\n",
            "     47       14.9317  0.0480\n",
            "     48       \u001b[36m14.1508\u001b[0m  0.0395\n",
            "     49       \u001b[36m12.5069\u001b[0m  0.0408\n",
            "     50       12.8839  0.0418\n",
            "     51       12.7950  0.0397\n",
            "     52       \u001b[36m11.8816\u001b[0m  0.0485\n",
            "     53       \u001b[36m11.5440\u001b[0m  0.0410\n",
            "     54       \u001b[36m10.7718\u001b[0m  0.0385\n",
            "     55       \u001b[36m10.2202\u001b[0m  0.0447\n",
            "     56       \u001b[36m10.1226\u001b[0m  0.0395\n",
            "     57       10.8715  0.0403\n",
            "     58       10.6399  0.0407\n",
            "     59       10.7651  0.0388\n",
            "     60       10.6063  0.0377\n",
            "     61       10.6818  0.0412\n",
            "     62       10.3420  0.0470\n",
            "     63       10.4290  0.0397\n",
            "     64       \u001b[36m10.0209\u001b[0m  0.0401\n",
            "     65        \u001b[36m9.7477\u001b[0m  0.0405\n",
            "     66        \u001b[36m8.6890\u001b[0m  0.0417\n",
            "     67        9.1472  0.0430\n",
            "     68        9.1063  0.0402\n",
            "     69        9.1054  0.0453\n",
            "     70        9.0504  0.0395\n",
            "     71        9.1521  0.0399\n",
            "     72        8.8021  0.0404\n",
            "     73        8.7109  0.0394\n",
            "     74        \u001b[36m8.6770\u001b[0m  0.0378\n",
            "     75        \u001b[36m8.3436\u001b[0m  0.0421\n",
            "     76        \u001b[36m8.2826\u001b[0m  0.0485\n",
            "     77        \u001b[36m7.9516\u001b[0m  0.0396\n",
            "     78        8.1523  0.0475\n",
            "     79        \u001b[36m7.4398\u001b[0m  0.0395\n",
            "     80        7.6933  0.0553\n",
            "     81        7.7293  0.0457\n",
            "     82        \u001b[36m7.3104\u001b[0m  0.0439\n",
            "     83        7.3704  0.0433\n",
            "     84        \u001b[36m7.2178\u001b[0m  0.0422\n",
            "     85        \u001b[36m7.0461\u001b[0m  0.0405\n",
            "     86        \u001b[36m6.6769\u001b[0m  0.0392\n",
            "     87        6.9914  0.0392\n",
            "     88        \u001b[36m6.3969\u001b[0m  0.0390\n",
            "     89        \u001b[36m6.3437\u001b[0m  0.0444\n",
            "     90        \u001b[36m6.2766\u001b[0m  0.0414\n",
            "     91        \u001b[36m6.2591\u001b[0m  0.0439\n",
            "     92        6.4604  0.0404\n",
            "     93        \u001b[36m5.7342\u001b[0m  0.0402\n",
            "     94        6.1347  0.0414\n",
            "     95        5.7727  0.0398\n",
            "     96        5.8878  0.0404\n",
            "     97        \u001b[36m5.5249\u001b[0m  0.0383\n",
            "     98        5.6221  0.0403\n",
            "     99        5.5918  0.0511\n",
            "    100        \u001b[36m5.4108\u001b[0m  0.0394\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m3159.5048\u001b[0m  0.0284\n",
            "      2        \u001b[36m0.8183\u001b[0m  0.0394\n",
            "      3        \u001b[36m0.6970\u001b[0m  0.0317\n",
            "      4        \u001b[36m0.6965\u001b[0m  0.0329\n",
            "      5        \u001b[36m0.6960\u001b[0m  0.0324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.6956\u001b[0m  0.0326\n",
            "      7        \u001b[36m0.6951\u001b[0m  0.0302\n",
            "      8        \u001b[36m0.6946\u001b[0m  0.0312\n",
            "      9        \u001b[36m0.6942\u001b[0m  0.0310\n",
            "     10        \u001b[36m0.6937\u001b[0m  0.0330\n",
            "     11        \u001b[36m0.6933\u001b[0m  0.0327\n",
            "     12        \u001b[36m0.6928\u001b[0m  0.0335\n",
            "     13        \u001b[36m0.6924\u001b[0m  0.0346\n",
            "     14        \u001b[36m0.6920\u001b[0m  0.0348\n",
            "     15        \u001b[36m0.6916\u001b[0m  0.0338\n",
            "     16        \u001b[36m0.6912\u001b[0m  0.0308\n",
            "     17        \u001b[36m0.6907\u001b[0m  0.0319\n",
            "     18        \u001b[36m0.6903\u001b[0m  0.0319\n",
            "     19        \u001b[36m0.6900\u001b[0m  0.0328\n",
            "     20        \u001b[36m0.6896\u001b[0m  0.0351\n",
            "     21        \u001b[36m0.6892\u001b[0m  0.0324\n",
            "     22        \u001b[36m0.6888\u001b[0m  0.0327\n",
            "     23        \u001b[36m0.6884\u001b[0m  0.0328\n",
            "     24        \u001b[36m0.6881\u001b[0m  0.0319\n",
            "     25        \u001b[36m0.6877\u001b[0m  0.0314\n",
            "     26        \u001b[36m0.6873\u001b[0m  0.0357\n",
            "     27        \u001b[36m0.6870\u001b[0m  0.0356\n",
            "     28        \u001b[36m0.6866\u001b[0m  0.0330\n",
            "     29        \u001b[36m0.6863\u001b[0m  0.0359\n",
            "     30        \u001b[36m0.6859\u001b[0m  0.0315\n",
            "     31        \u001b[36m0.6856\u001b[0m  0.0406\n",
            "     32        \u001b[36m0.6853\u001b[0m  0.0326\n",
            "     33        \u001b[36m0.6850\u001b[0m  0.0323\n",
            "     34        \u001b[36m0.6846\u001b[0m  0.0330\n",
            "     35        \u001b[36m0.6843\u001b[0m  0.0320\n",
            "     36        \u001b[36m0.6840\u001b[0m  0.0387\n",
            "     37        \u001b[36m0.6837\u001b[0m  0.0323\n",
            "     38        \u001b[36m0.6834\u001b[0m  0.0322\n",
            "     39        \u001b[36m0.6831\u001b[0m  0.0341\n",
            "     40        \u001b[36m0.6828\u001b[0m  0.0319\n",
            "     41        \u001b[36m0.6825\u001b[0m  0.0318\n",
            "     42        \u001b[36m0.6822\u001b[0m  0.0355\n",
            "     43        \u001b[36m0.6819\u001b[0m  0.0346\n",
            "     44        \u001b[36m0.6817\u001b[0m  0.0332\n",
            "     45        \u001b[36m0.6814\u001b[0m  0.0357\n",
            "     46        \u001b[36m0.6811\u001b[0m  0.0346\n",
            "     47        \u001b[36m0.6808\u001b[0m  0.0318\n",
            "     48        \u001b[36m0.6806\u001b[0m  0.0317\n",
            "     49        \u001b[36m0.6803\u001b[0m  0.0279\n",
            "     50        \u001b[36m0.6801\u001b[0m  0.0347\n",
            "     51        \u001b[36m0.6798\u001b[0m  0.0320\n",
            "     52        \u001b[36m0.6796\u001b[0m  0.0325\n",
            "     53        \u001b[36m0.6793\u001b[0m  0.0332\n",
            "     54        \u001b[36m0.6791\u001b[0m  0.0330\n",
            "     55        \u001b[36m0.6788\u001b[0m  0.0478\n",
            "     56        \u001b[36m0.6786\u001b[0m  0.0322\n",
            "     57        \u001b[36m0.6784\u001b[0m  0.0331\n",
            "     58        \u001b[36m0.6781\u001b[0m  0.0334\n",
            "     59        \u001b[36m0.6779\u001b[0m  0.0318\n",
            "     60        \u001b[36m0.6777\u001b[0m  0.0328\n",
            "     61        \u001b[36m0.6775\u001b[0m  0.0368\n",
            "     62        \u001b[36m0.6772\u001b[0m  0.0330\n",
            "     63        \u001b[36m0.6770\u001b[0m  0.0332\n",
            "     64        \u001b[36m0.6768\u001b[0m  0.0323\n",
            "     65        \u001b[36m0.6766\u001b[0m  0.0314\n",
            "     66        \u001b[36m0.6764\u001b[0m  0.0320\n",
            "     67        \u001b[36m0.6762\u001b[0m  0.0371\n",
            "     68        \u001b[36m0.6760\u001b[0m  0.0313\n",
            "     69        \u001b[36m0.6758\u001b[0m  0.0337\n",
            "     70        \u001b[36m0.6756\u001b[0m  0.0342\n",
            "     71        \u001b[36m0.6754\u001b[0m  0.0329\n",
            "     72        \u001b[36m0.6752\u001b[0m  0.0313\n",
            "     73        \u001b[36m0.6750\u001b[0m  0.0335\n",
            "     74        \u001b[36m0.6749\u001b[0m  0.0322\n",
            "     75        \u001b[36m0.6747\u001b[0m  0.0317\n",
            "     76        \u001b[36m0.6745\u001b[0m  0.0315\n",
            "     77        \u001b[36m0.6743\u001b[0m  0.0318\n",
            "     78        \u001b[36m0.6742\u001b[0m  0.0368\n",
            "     79        \u001b[36m0.6740\u001b[0m  0.0314\n",
            "     80        \u001b[36m0.6738\u001b[0m  0.0324\n",
            "     81        \u001b[36m0.6736\u001b[0m  0.0330\n",
            "     82        \u001b[36m0.6735\u001b[0m  0.0325\n",
            "     83        \u001b[36m0.6733\u001b[0m  0.0386\n",
            "     84        \u001b[36m0.6732\u001b[0m  0.0360\n",
            "     85        \u001b[36m0.6730\u001b[0m  0.0315\n",
            "     86        \u001b[36m0.6728\u001b[0m  0.0405\n",
            "     87        \u001b[36m0.6727\u001b[0m  0.0321\n",
            "     88        \u001b[36m0.6725\u001b[0m  0.0326\n",
            "     89        \u001b[36m0.6724\u001b[0m  0.0328\n",
            "     90        \u001b[36m0.6722\u001b[0m  0.0347\n",
            "     91        \u001b[36m0.6721\u001b[0m  0.0321\n",
            "     92        \u001b[36m0.6719\u001b[0m  0.0321\n",
            "     93        \u001b[36m0.6718\u001b[0m  0.0306\n",
            "     94        \u001b[36m0.6717\u001b[0m  0.0333\n",
            "     95        \u001b[36m0.6715\u001b[0m  0.0319\n",
            "     96        \u001b[36m0.6714\u001b[0m  0.0327\n",
            "     97        \u001b[36m0.6713\u001b[0m  0.0346\n",
            "     98        \u001b[36m0.6711\u001b[0m  0.0360\n",
            "     99        \u001b[36m0.6710\u001b[0m  0.0323\n",
            "    100        \u001b[36m0.6709\u001b[0m  0.0319\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m3323.8658\u001b[0m  0.0281\n",
            "      2        \u001b[36m0.7311\u001b[0m  0.0374\n",
            "      3        \u001b[36m0.7243\u001b[0m  0.0305\n",
            "      4        \u001b[36m0.7234\u001b[0m  0.0305\n",
            "      5        \u001b[36m0.7224\u001b[0m  0.0322\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.7215\u001b[0m  0.0370\n",
            "      7        \u001b[36m0.7206\u001b[0m  0.0343\n",
            "      8        \u001b[36m0.7197\u001b[0m  0.0314\n",
            "      9        \u001b[36m0.7188\u001b[0m  0.0307\n",
            "     10        \u001b[36m0.7179\u001b[0m  0.0326\n",
            "     11        \u001b[36m0.7171\u001b[0m  0.0356\n",
            "     12        \u001b[36m0.7162\u001b[0m  0.0375\n",
            "     13        \u001b[36m0.7154\u001b[0m  0.0308\n",
            "     14        \u001b[36m0.7146\u001b[0m  0.0328\n",
            "     15        \u001b[36m0.7137\u001b[0m  0.0348\n",
            "     16        \u001b[36m0.7129\u001b[0m  0.0323\n",
            "     17        \u001b[36m0.7122\u001b[0m  0.0320\n",
            "     18        \u001b[36m0.7114\u001b[0m  0.0311\n",
            "     19        \u001b[36m0.7106\u001b[0m  0.0409\n",
            "     20        \u001b[36m0.7099\u001b[0m  0.0312\n",
            "     21        \u001b[36m0.7091\u001b[0m  0.0325\n",
            "     22        \u001b[36m0.7084\u001b[0m  0.0318\n",
            "     23        \u001b[36m0.7077\u001b[0m  0.0286\n",
            "     24        \u001b[36m0.7070\u001b[0m  0.0294\n",
            "     25        \u001b[36m0.7063\u001b[0m  0.0343\n",
            "     26        \u001b[36m0.7056\u001b[0m  0.0360\n",
            "     27        \u001b[36m0.7049\u001b[0m  0.0313\n",
            "     28        \u001b[36m0.7042\u001b[0m  0.0315\n",
            "     29        \u001b[36m0.7036\u001b[0m  0.0318\n",
            "     30        \u001b[36m0.7029\u001b[0m  0.0324\n",
            "     31        \u001b[36m0.7023\u001b[0m  0.0349\n",
            "     32        \u001b[36m0.7016\u001b[0m  0.0311\n",
            "     33        \u001b[36m0.7010\u001b[0m  0.0306\n",
            "     34        \u001b[36m0.7004\u001b[0m  0.0323\n",
            "     35        \u001b[36m0.6998\u001b[0m  0.0340\n",
            "     36        \u001b[36m0.6992\u001b[0m  0.0335\n",
            "     37        \u001b[36m0.6986\u001b[0m  0.0303\n",
            "     38        \u001b[36m0.6980\u001b[0m  0.0329\n",
            "     39        \u001b[36m0.6975\u001b[0m  0.0341\n",
            "     40        \u001b[36m0.6969\u001b[0m  0.0314\n",
            "     41        \u001b[36m0.6963\u001b[0m  0.0393\n",
            "     42        \u001b[36m0.6958\u001b[0m  0.0363\n",
            "     43        \u001b[36m0.6953\u001b[0m  0.0323\n",
            "     44        \u001b[36m0.6947\u001b[0m  0.0311\n",
            "     45        \u001b[36m0.6942\u001b[0m  0.0349\n",
            "     46        \u001b[36m0.6937\u001b[0m  0.0350\n",
            "     47        \u001b[36m0.6932\u001b[0m  0.0323\n",
            "     48        \u001b[36m0.6927\u001b[0m  0.0326\n",
            "     49        \u001b[36m0.6922\u001b[0m  0.0322\n",
            "     50        \u001b[36m0.6917\u001b[0m  0.0308\n",
            "     51        \u001b[36m0.6913\u001b[0m  0.0314\n",
            "     52        \u001b[36m0.6908\u001b[0m  0.0314\n",
            "     53        \u001b[36m0.6903\u001b[0m  0.0350\n",
            "     54        \u001b[36m0.6899\u001b[0m  0.0325\n",
            "     55        \u001b[36m0.6894\u001b[0m  0.0354\n",
            "     56        \u001b[36m0.6890\u001b[0m  0.0312\n",
            "     57        \u001b[36m0.6885\u001b[0m  0.0320\n",
            "     58        \u001b[36m0.6881\u001b[0m  0.0315\n",
            "     59        \u001b[36m0.6877\u001b[0m  0.0328\n",
            "     60        \u001b[36m0.6873\u001b[0m  0.0363\n",
            "     61        \u001b[36m0.6869\u001b[0m  0.0322\n",
            "     62        \u001b[36m0.6865\u001b[0m  0.0326\n",
            "     63        \u001b[36m0.6861\u001b[0m  0.0327\n",
            "     64        \u001b[36m0.6857\u001b[0m  0.0316\n",
            "     65        \u001b[36m0.6853\u001b[0m  0.0340\n",
            "     66        \u001b[36m0.6849\u001b[0m  0.0352\n",
            "     67        \u001b[36m0.6845\u001b[0m  0.0381\n",
            "     68        \u001b[36m0.6842\u001b[0m  0.0312\n",
            "     69        \u001b[36m0.6838\u001b[0m  0.0423\n",
            "     70        \u001b[36m0.6834\u001b[0m  0.0413\n",
            "     71        \u001b[36m0.6831\u001b[0m  0.0304\n",
            "     72        \u001b[36m0.6827\u001b[0m  0.0320\n",
            "     73        \u001b[36m0.6824\u001b[0m  0.0329\n",
            "     74        \u001b[36m0.6821\u001b[0m  0.0325\n",
            "     75        \u001b[36m0.6817\u001b[0m  0.0309\n",
            "     76        \u001b[36m0.6814\u001b[0m  0.0311\n",
            "     77        \u001b[36m0.6811\u001b[0m  0.0306\n",
            "     78        \u001b[36m0.6808\u001b[0m  0.0321\n",
            "     79        \u001b[36m0.6804\u001b[0m  0.0319\n",
            "     80        \u001b[36m0.6801\u001b[0m  0.0313\n",
            "     81        \u001b[36m0.6798\u001b[0m  0.0347\n",
            "     82        \u001b[36m0.6795\u001b[0m  0.0331\n",
            "     83        \u001b[36m0.6792\u001b[0m  0.0379\n",
            "     84        \u001b[36m0.6789\u001b[0m  0.0321\n",
            "     85        \u001b[36m0.6787\u001b[0m  0.0292\n",
            "     86        \u001b[36m0.6784\u001b[0m  0.0307\n",
            "     87        \u001b[36m0.6781\u001b[0m  0.0338\n",
            "     88        \u001b[36m0.6778\u001b[0m  0.0307\n",
            "     89        \u001b[36m0.6775\u001b[0m  0.0316\n",
            "     90        \u001b[36m0.6773\u001b[0m  0.0322\n",
            "     91        \u001b[36m0.6770\u001b[0m  0.0305\n",
            "     92        \u001b[36m0.6768\u001b[0m  0.0383\n",
            "     93        \u001b[36m0.6765\u001b[0m  0.0320\n",
            "     94        \u001b[36m0.6763\u001b[0m  0.0300\n",
            "     95        \u001b[36m0.6760\u001b[0m  0.0315\n",
            "     96        \u001b[36m0.6758\u001b[0m  0.0395\n",
            "     97        \u001b[36m0.6755\u001b[0m  0.0318\n",
            "     98        \u001b[36m0.6753\u001b[0m  0.0422\n",
            "     99        \u001b[36m0.6751\u001b[0m  0.0312\n",
            "    100        \u001b[36m0.6748\u001b[0m  0.0320\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m72743.7963\u001b[0m  0.0372\n",
            "      2    \u001b[36m63447.5657\u001b[0m  0.0407\n",
            "      3    \u001b[36m54938.0994\u001b[0m  0.0451\n",
            "      4    \u001b[36m47273.9098\u001b[0m  0.0400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5    \u001b[36m40394.8710\u001b[0m  0.0434\n",
            "      6    \u001b[36m34179.8138\u001b[0m  0.0403\n",
            "      7    \u001b[36m28505.4649\u001b[0m  0.0457\n",
            "      8    \u001b[36m23266.5548\u001b[0m  0.0412\n",
            "      9    \u001b[36m18374.2070\u001b[0m  0.0389\n",
            "     10    \u001b[36m13746.7662\u001b[0m  0.0395\n",
            "     11     \u001b[36m9300.1456\u001b[0m  0.0398\n",
            "     12     \u001b[36m4939.4478\u001b[0m  0.0436\n",
            "     13     \u001b[36m1247.1756\u001b[0m  0.0434\n",
            "     14      \u001b[36m178.5841\u001b[0m  0.0401\n",
            "     15      191.0518  0.0429\n",
            "     16      261.4455  0.0403\n",
            "     17      239.5685  0.0393\n",
            "     18      236.6770  0.0397\n",
            "     19      238.6056  0.0432\n",
            "     20      230.9263  0.0405\n",
            "     21      223.7866  0.0497\n",
            "     22      220.1303  0.0390\n",
            "     23      216.8515  0.0426\n",
            "     24      204.7685  0.0422\n",
            "     25      190.7831  0.0382\n",
            "     26      207.1947  0.0396\n",
            "     27      196.0289  0.0402\n",
            "     28      195.7725  0.0400\n",
            "     29      193.2576  0.0393\n",
            "     30      182.9705  0.0419\n",
            "     31      187.2862  0.0404\n",
            "     32      188.7603  0.0424\n",
            "     33      179.0847  0.0400\n",
            "     34      \u001b[36m166.9800\u001b[0m  0.0404\n",
            "     35      \u001b[36m164.1641\u001b[0m  0.0454\n",
            "     36      169.1446  0.0403\n",
            "     37      \u001b[36m161.6580\u001b[0m  0.0409\n",
            "     38      \u001b[36m153.1033\u001b[0m  0.0401\n",
            "     39      \u001b[36m140.4056\u001b[0m  0.0403\n",
            "     40      149.8989  0.0391\n",
            "     41      154.1875  0.0461\n",
            "     42      146.8439  0.0401\n",
            "     43      148.3932  0.0401\n",
            "     44      151.5975  0.0581\n",
            "     45      154.8904  0.0377\n",
            "     46      157.7281  0.0404\n",
            "     47      151.2082  0.0394\n",
            "     48      158.0973  0.0403\n",
            "     49      158.6382  0.0420\n",
            "     50      144.4038  0.0382\n",
            "     51      162.4654  0.0393\n",
            "     52      144.9112  0.0412\n",
            "     53      146.6364  0.0561\n",
            "     54      146.1846  0.0440\n",
            "     55      153.8605  0.0385\n",
            "     56      171.5127  0.0401\n",
            "     57      154.8804  0.0399\n",
            "     58      145.6485  0.0398\n",
            "     59      145.3606  0.0398\n",
            "     60      152.5491  0.0394\n",
            "     61      147.1090  0.0465\n",
            "     62      157.7893  0.0396\n",
            "     63      164.6526  0.0392\n",
            "     64      \u001b[36m125.0737\u001b[0m  0.0388\n",
            "     65      \u001b[36m105.7818\u001b[0m  0.0431\n",
            "     66       \u001b[36m88.7449\u001b[0m  0.0399\n",
            "     67       \u001b[36m87.5356\u001b[0m  0.0437\n",
            "     68       92.7460  0.0455\n",
            "     69       94.2428  0.0405\n",
            "     70       92.8626  0.0428\n",
            "     71       89.2412  0.0392\n",
            "     72       \u001b[36m80.8476\u001b[0m  0.0397\n",
            "     73       85.4664  0.0386\n",
            "     74       94.1850  0.0433\n",
            "     75      107.5800  0.0426\n",
            "     76      106.7964  0.0415\n",
            "     77      109.6740  0.0391\n",
            "     78      107.4826  0.0407\n",
            "     79      103.6865  0.0415\n",
            "     80      116.2589  0.0394\n",
            "     81      111.4269  0.0426\n",
            "     82      103.6658  0.0417\n",
            "     83      117.2129  0.0406\n",
            "     84      107.9230  0.0415\n",
            "     85      114.9784  0.0398\n",
            "     86      104.0668  0.0404\n",
            "     87      110.2298  0.0400\n",
            "     88      105.4294  0.0392\n",
            "     89       95.6510  0.0394\n",
            "     90       87.8464  0.0405\n",
            "     91       84.2209  0.0522\n",
            "     92       \u001b[36m74.6881\u001b[0m  0.0470\n",
            "     93       \u001b[36m64.9721\u001b[0m  0.0391\n",
            "     94       \u001b[36m47.2109\u001b[0m  0.0387\n",
            "     95       \u001b[36m38.6033\u001b[0m  0.0393\n",
            "     96       \u001b[36m34.5406\u001b[0m  0.0386\n",
            "     97       \u001b[36m31.3535\u001b[0m  0.0389\n",
            "     98       31.8564  0.0415\n",
            "     99       \u001b[36m28.0457\u001b[0m  0.0408\n",
            "    100       30.8852  0.0392\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m83538.3387\u001b[0m  0.0345\n",
            "      2    \u001b[36m73867.2170\u001b[0m  0.0384\n",
            "      3    \u001b[36m65350.4674\u001b[0m  0.0471\n",
            "      4    \u001b[36m57591.1609\u001b[0m  0.0401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5    \u001b[36m50579.8093\u001b[0m  0.0428\n",
            "      6    \u001b[36m44267.9956\u001b[0m  0.0397\n",
            "      7    \u001b[36m38596.0506\u001b[0m  0.0444\n",
            "      8    \u001b[36m33501.1268\u001b[0m  0.0405\n",
            "      9    \u001b[36m28921.3993\u001b[0m  0.0395\n",
            "     10    \u001b[36m24799.2329\u001b[0m  0.0396\n",
            "     11    \u001b[36m21079.1079\u001b[0m  0.0395\n",
            "     12    \u001b[36m17714.4093\u001b[0m  0.0416\n",
            "     13    \u001b[36m14659.1855\u001b[0m  0.0368\n",
            "     14    \u001b[36m11855.1438\u001b[0m  0.0508\n",
            "     15     \u001b[36m9243.7294\u001b[0m  0.0406\n",
            "     16     \u001b[36m6774.6104\u001b[0m  0.0406\n",
            "     17     \u001b[36m4394.2049\u001b[0m  0.0399\n",
            "     18     \u001b[36m2069.4893\u001b[0m  0.0402\n",
            "     19      \u001b[36m403.7687\u001b[0m  0.0407\n",
            "     20      \u001b[36m196.6151\u001b[0m  0.0444\n",
            "     21      207.4296  0.0404\n",
            "     22      \u001b[36m195.5400\u001b[0m  0.0402\n",
            "     23      \u001b[36m190.5075\u001b[0m  0.0398\n",
            "     24      \u001b[36m182.9866\u001b[0m  0.0432\n",
            "     25      \u001b[36m175.7260\u001b[0m  0.0401\n",
            "     26      \u001b[36m167.0982\u001b[0m  0.0400\n",
            "     27      \u001b[36m157.2590\u001b[0m  0.0387\n",
            "     28      \u001b[36m146.7474\u001b[0m  0.0405\n",
            "     29      \u001b[36m142.1947\u001b[0m  0.0398\n",
            "     30      \u001b[36m141.3887\u001b[0m  0.0400\n",
            "     31      \u001b[36m138.5335\u001b[0m  0.0396\n",
            "     32      \u001b[36m129.9566\u001b[0m  0.0446\n",
            "     33      133.7136  0.0461\n",
            "     34      \u001b[36m127.4330\u001b[0m  0.0389\n",
            "     35      \u001b[36m123.2514\u001b[0m  0.0400\n",
            "     36      \u001b[36m122.0910\u001b[0m  0.0405\n",
            "     37      \u001b[36m116.1482\u001b[0m  0.0452\n",
            "     38      \u001b[36m114.7149\u001b[0m  0.0437\n",
            "     39      116.2489  0.0392\n",
            "     40      \u001b[36m113.6209\u001b[0m  0.0392\n",
            "     41      \u001b[36m108.0065\u001b[0m  0.0405\n",
            "     42      \u001b[36m103.4558\u001b[0m  0.0420\n",
            "     43       \u001b[36m98.1961\u001b[0m  0.0431\n",
            "     44       \u001b[36m93.1233\u001b[0m  0.0424\n",
            "     45       \u001b[36m92.5842\u001b[0m  0.0446\n",
            "     46       \u001b[36m83.0131\u001b[0m  0.0413\n",
            "     47       83.8651  0.0404\n",
            "     48       90.4460  0.0397\n",
            "     49       92.1042  0.0400\n",
            "     50       92.5779  0.0395\n",
            "     51       89.1814  0.0403\n",
            "     52       86.7416  0.0507\n",
            "     53       87.7888  0.0393\n",
            "     54       86.0858  0.0400\n",
            "     55       85.7172  0.0402\n",
            "     56       85.6392  0.0388\n",
            "     57       \u001b[36m80.5625\u001b[0m  0.0402\n",
            "     58       82.0629  0.0394\n",
            "     59       81.1585  0.0410\n",
            "     60       \u001b[36m77.6753\u001b[0m  0.0386\n",
            "     61       78.1551  0.0600\n",
            "     62       \u001b[36m77.0566\u001b[0m  0.0407\n",
            "     63       77.2889  0.0406\n",
            "     64       \u001b[36m74.7970\u001b[0m  0.0412\n",
            "     65       74.9240  0.0404\n",
            "     66       \u001b[36m73.0690\u001b[0m  0.0431\n",
            "     67       74.5425  0.0417\n",
            "     68       \u001b[36m70.1746\u001b[0m  0.0398\n",
            "     69       75.8955  0.0403\n",
            "     70       84.9737  0.0403\n",
            "     71       79.3141  0.0432\n",
            "     72       80.0168  0.0403\n",
            "     73       79.2368  0.0409\n",
            "     74       82.5509  0.0446\n",
            "     75       78.2667  0.0425\n",
            "     76       77.0361  0.0398\n",
            "     77       78.3218  0.0404\n",
            "     78       77.5119  0.0398\n",
            "     79       73.8207  0.0401\n",
            "     80       \u001b[36m65.9812\u001b[0m  0.0405\n",
            "     81       \u001b[36m55.8535\u001b[0m  0.0462\n",
            "     82       \u001b[36m44.6645\u001b[0m  0.0405\n",
            "     83       \u001b[36m32.0545\u001b[0m  0.0460\n",
            "     84       \u001b[36m22.3591\u001b[0m  0.0511\n",
            "     85       \u001b[36m17.4549\u001b[0m  0.0397\n",
            "     86       \u001b[36m14.4711\u001b[0m  0.0413\n",
            "     87       \u001b[36m12.2467\u001b[0m  0.0410\n",
            "     88       \u001b[36m11.9567\u001b[0m  0.0433\n",
            "     89       11.9887  0.0416\n",
            "     90       \u001b[36m10.4949\u001b[0m  0.0403\n",
            "     91       10.8837  0.0449\n",
            "     92       11.0757  0.0401\n",
            "     93       11.0220  0.0452\n",
            "     94       11.9948  0.0410\n",
            "     95       10.7933  0.0392\n",
            "     96        \u001b[36m9.8635\u001b[0m  0.0397\n",
            "     97        9.9665  0.0405\n",
            "     98       10.4753  0.0393\n",
            "     99       11.6544  0.0402\n",
            "    100       14.2536  0.0386\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1     \u001b[36m9364.0237\u001b[0m  0.0371\n",
            "      2        \u001b[36m0.6723\u001b[0m  0.0316\n",
            "      3        \u001b[36m0.6721\u001b[0m  0.0318\n",
            "      4        \u001b[36m0.6720\u001b[0m  0.0339\n",
            "      5        \u001b[36m0.6718\u001b[0m  0.0318\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.6717\u001b[0m  0.0361\n",
            "      7        \u001b[36m0.6716\u001b[0m  0.0330\n",
            "      8        \u001b[36m0.6714\u001b[0m  0.0423\n",
            "      9        \u001b[36m0.6713\u001b[0m  0.0326\n",
            "     10        \u001b[36m0.6711\u001b[0m  0.0323\n",
            "     11        \u001b[36m0.6710\u001b[0m  0.0322\n",
            "     12        \u001b[36m0.6709\u001b[0m  0.0347\n",
            "     13        \u001b[36m0.6708\u001b[0m  0.0318\n",
            "     14        \u001b[36m0.6706\u001b[0m  0.0377\n",
            "     15        \u001b[36m0.6705\u001b[0m  0.0316\n",
            "     16        \u001b[36m0.6704\u001b[0m  0.0315\n",
            "     17        \u001b[36m0.6703\u001b[0m  0.0316\n",
            "     18        \u001b[36m0.6701\u001b[0m  0.0324\n",
            "     19        \u001b[36m0.6700\u001b[0m  0.0324\n",
            "     20        \u001b[36m0.6699\u001b[0m  0.0315\n",
            "     21        \u001b[36m0.6698\u001b[0m  0.0316\n",
            "     22        \u001b[36m0.6697\u001b[0m  0.0320\n",
            "     23        \u001b[36m0.6696\u001b[0m  0.0305\n",
            "     24        \u001b[36m0.6695\u001b[0m  0.0307\n",
            "     25        \u001b[36m0.6694\u001b[0m  0.0322\n",
            "     26        \u001b[36m0.6692\u001b[0m  0.0323\n",
            "     27        \u001b[36m0.6691\u001b[0m  0.0359\n",
            "     28        \u001b[36m0.6690\u001b[0m  0.0291\n",
            "     29        \u001b[36m0.6689\u001b[0m  0.0314\n",
            "     30        \u001b[36m0.6688\u001b[0m  0.0337\n",
            "     31        \u001b[36m0.6687\u001b[0m  0.0319\n",
            "     32        \u001b[36m0.6686\u001b[0m  0.0308\n",
            "     33        \u001b[36m0.6685\u001b[0m  0.0304\n",
            "     34        \u001b[36m0.6684\u001b[0m  0.0324\n",
            "     35        \u001b[36m0.6683\u001b[0m  0.0406\n",
            "     36        \u001b[36m0.6683\u001b[0m  0.0489\n",
            "     37        \u001b[36m0.6682\u001b[0m  0.0345\n",
            "     38        \u001b[36m0.6681\u001b[0m  0.0312\n",
            "     39        \u001b[36m0.6680\u001b[0m  0.0330\n",
            "     40        \u001b[36m0.6679\u001b[0m  0.0404\n",
            "     41        \u001b[36m0.6678\u001b[0m  0.0323\n",
            "     42        \u001b[36m0.6677\u001b[0m  0.0338\n",
            "     43        \u001b[36m0.6676\u001b[0m  0.0330\n",
            "     44        \u001b[36m0.6675\u001b[0m  0.0322\n",
            "     45        \u001b[36m0.6675\u001b[0m  0.0334\n",
            "     46        \u001b[36m0.6674\u001b[0m  0.0303\n",
            "     47        \u001b[36m0.6673\u001b[0m  0.0321\n",
            "     48        \u001b[36m0.6672\u001b[0m  0.0328\n",
            "     49        \u001b[36m0.6671\u001b[0m  0.0319\n",
            "     50        \u001b[36m0.6671\u001b[0m  0.0321\n",
            "     51        \u001b[36m0.6670\u001b[0m  0.0318\n",
            "     52        \u001b[36m0.6669\u001b[0m  0.0342\n",
            "     53        \u001b[36m0.6668\u001b[0m  0.0381\n",
            "     54        \u001b[36m0.6668\u001b[0m  0.0330\n",
            "     55        \u001b[36m0.6667\u001b[0m  0.0323\n",
            "     56        \u001b[36m0.6666\u001b[0m  0.0316\n",
            "     57        \u001b[36m0.6665\u001b[0m  0.0311\n",
            "     58        \u001b[36m0.6665\u001b[0m  0.0326\n",
            "     59        \u001b[36m0.6664\u001b[0m  0.0324\n",
            "     60        \u001b[36m0.6663\u001b[0m  0.0364\n",
            "     61        \u001b[36m0.6663\u001b[0m  0.0352\n",
            "     62        \u001b[36m0.6662\u001b[0m  0.0317\n",
            "     63        \u001b[36m0.6661\u001b[0m  0.0363\n",
            "     64        \u001b[36m0.6661\u001b[0m  0.0334\n",
            "     65        \u001b[36m0.6660\u001b[0m  0.0406\n",
            "     66        \u001b[36m0.6660\u001b[0m  0.0352\n",
            "     67        \u001b[36m0.6659\u001b[0m  0.0325\n",
            "     68        \u001b[36m0.6658\u001b[0m  0.0360\n",
            "     69        \u001b[36m0.6658\u001b[0m  0.0330\n",
            "     70        \u001b[36m0.6657\u001b[0m  0.0347\n",
            "     71        \u001b[36m0.6656\u001b[0m  0.0297\n",
            "     72        \u001b[36m0.6656\u001b[0m  0.0346\n",
            "     73        \u001b[36m0.6655\u001b[0m  0.0330\n",
            "     74        \u001b[36m0.6655\u001b[0m  0.0324\n",
            "     75        \u001b[36m0.6654\u001b[0m  0.0319\n",
            "     76        \u001b[36m0.6654\u001b[0m  0.0348\n",
            "     77        \u001b[36m0.6653\u001b[0m  0.0329\n",
            "     78        \u001b[36m0.6653\u001b[0m  0.0389\n",
            "     79        \u001b[36m0.6652\u001b[0m  0.0330\n",
            "     80        \u001b[36m0.6652\u001b[0m  0.0311\n",
            "     81        \u001b[36m0.6651\u001b[0m  0.0329\n",
            "     82        \u001b[36m0.6650\u001b[0m  0.0338\n",
            "     83        \u001b[36m0.6650\u001b[0m  0.0328\n",
            "     84        \u001b[36m0.6649\u001b[0m  0.0320\n",
            "     85        \u001b[36m0.6649\u001b[0m  0.0384\n",
            "     86        \u001b[36m0.6649\u001b[0m  0.0319\n",
            "     87        \u001b[36m0.6648\u001b[0m  0.0326\n",
            "     88        \u001b[36m0.6648\u001b[0m  0.0340\n",
            "     89        \u001b[36m0.6647\u001b[0m  0.0326\n",
            "     90        \u001b[36m0.6647\u001b[0m  0.0305\n",
            "     91        \u001b[36m0.6646\u001b[0m  0.0354\n",
            "     92        \u001b[36m0.6646\u001b[0m  0.0324\n",
            "     93        \u001b[36m0.6645\u001b[0m  0.0406\n",
            "     94        \u001b[36m0.6645\u001b[0m  0.0333\n",
            "     95        \u001b[36m0.6644\u001b[0m  0.0347\n",
            "     96        \u001b[36m0.6644\u001b[0m  0.0348\n",
            "     97        \u001b[36m0.6644\u001b[0m  0.0335\n",
            "     98        \u001b[36m0.6643\u001b[0m  0.0340\n",
            "     99        \u001b[36m0.6643\u001b[0m  0.0353\n",
            "    100        \u001b[36m0.6642\u001b[0m  0.0323\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m24010.5574\u001b[0m  0.0355\n",
            "      2      \u001b[36m195.9739\u001b[0m  0.0355\n",
            "      3        \u001b[36m0.7200\u001b[0m  0.0322\n",
            "      4        \u001b[36m0.7191\u001b[0m  0.0309\n",
            "      5        \u001b[36m0.7182\u001b[0m  0.0337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m0.7174\u001b[0m  0.0466\n",
            "      7        \u001b[36m0.7165\u001b[0m  0.0365\n",
            "      8        \u001b[36m0.7157\u001b[0m  0.0338\n",
            "      9        \u001b[36m0.7149\u001b[0m  0.0386\n",
            "     10        \u001b[36m0.7140\u001b[0m  0.0323\n",
            "     11        \u001b[36m0.7132\u001b[0m  0.0387\n",
            "     12        \u001b[36m0.7124\u001b[0m  0.0330\n",
            "     13        \u001b[36m0.7117\u001b[0m  0.0317\n",
            "     14        \u001b[36m0.7109\u001b[0m  0.0325\n",
            "     15        \u001b[36m0.7101\u001b[0m  0.0299\n",
            "     16        \u001b[36m0.7094\u001b[0m  0.0322\n",
            "     17        \u001b[36m0.7086\u001b[0m  0.0324\n",
            "     18        \u001b[36m0.7079\u001b[0m  0.0360\n",
            "     19        \u001b[36m0.7072\u001b[0m  0.0345\n",
            "     20        \u001b[36m0.7065\u001b[0m  0.0388\n",
            "     21        \u001b[36m0.7058\u001b[0m  0.0353\n",
            "     22        \u001b[36m0.7051\u001b[0m  0.0355\n",
            "     23        \u001b[36m0.7044\u001b[0m  0.0344\n",
            "     24        \u001b[36m0.7038\u001b[0m  0.0351\n",
            "     25        \u001b[36m0.7031\u001b[0m  0.0340\n",
            "     26        \u001b[36m0.7025\u001b[0m  0.0329\n",
            "     27        \u001b[36m0.7019\u001b[0m  0.0319\n",
            "     28        \u001b[36m0.7012\u001b[0m  0.0314\n",
            "     29        \u001b[36m0.7006\u001b[0m  0.0347\n",
            "     30        \u001b[36m0.7000\u001b[0m  0.0337\n",
            "     31        \u001b[36m0.6994\u001b[0m  0.0384\n",
            "     32        \u001b[36m0.6988\u001b[0m  0.0316\n",
            "     33        \u001b[36m0.6982\u001b[0m  0.0344\n",
            "     34        \u001b[36m0.6977\u001b[0m  0.0321\n",
            "     35        \u001b[36m0.6971\u001b[0m  0.0325\n",
            "     36        \u001b[36m0.6965\u001b[0m  0.0326\n",
            "     37        \u001b[36m0.6960\u001b[0m  0.0324\n",
            "     38        \u001b[36m0.6955\u001b[0m  0.0321\n",
            "     39        \u001b[36m0.6949\u001b[0m  0.0327\n",
            "     40        \u001b[36m0.6944\u001b[0m  0.0367\n",
            "     41        \u001b[36m0.6939\u001b[0m  0.0341\n",
            "     42        \u001b[36m0.6934\u001b[0m  0.0360\n",
            "     43        \u001b[36m0.6929\u001b[0m  0.0368\n",
            "     44        \u001b[36m0.6924\u001b[0m  0.0334\n",
            "     45        \u001b[36m0.6919\u001b[0m  0.0320\n",
            "     46        \u001b[36m0.6914\u001b[0m  0.0327\n",
            "     47        \u001b[36m0.6909\u001b[0m  0.0328\n",
            "     48        \u001b[36m0.6905\u001b[0m  0.0335\n",
            "     49        \u001b[36m0.6900\u001b[0m  0.0411\n",
            "     50        \u001b[36m0.6896\u001b[0m  0.0334\n",
            "     51        \u001b[36m0.6891\u001b[0m  0.0341\n",
            "     52        \u001b[36m0.6887\u001b[0m  0.0333\n",
            "     53        \u001b[36m0.6883\u001b[0m  0.0320\n",
            "     54        \u001b[36m0.6878\u001b[0m  0.0336\n",
            "     55        \u001b[36m0.6874\u001b[0m  0.0321\n",
            "     56        \u001b[36m0.6870\u001b[0m  0.0413\n",
            "     57        \u001b[36m0.6866\u001b[0m  0.0358\n",
            "     58        \u001b[36m0.6862\u001b[0m  0.0336\n",
            "     59        \u001b[36m0.6858\u001b[0m  0.0343\n",
            "     60        \u001b[36m0.6854\u001b[0m  0.0335\n",
            "     61        \u001b[36m0.6850\u001b[0m  0.0334\n",
            "     62        \u001b[36m0.6847\u001b[0m  0.0357\n",
            "     63        \u001b[36m0.6843\u001b[0m  0.0313\n",
            "     64        \u001b[36m0.6839\u001b[0m  0.0315\n",
            "     65        \u001b[36m0.6836\u001b[0m  0.0320\n",
            "     66        \u001b[36m0.6832\u001b[0m  0.0405\n",
            "     67        \u001b[36m0.6829\u001b[0m  0.0343\n",
            "     68        \u001b[36m0.6825\u001b[0m  0.0322\n",
            "     69        \u001b[36m0.6822\u001b[0m  0.0323\n",
            "     70        \u001b[36m0.6818\u001b[0m  0.0324\n",
            "     71        \u001b[36m0.6815\u001b[0m  0.0318\n",
            "     72        \u001b[36m0.6812\u001b[0m  0.0324\n",
            "     73        \u001b[36m0.6809\u001b[0m  0.0318\n",
            "     74        \u001b[36m0.6805\u001b[0m  0.0328\n",
            "     75        \u001b[36m0.6802\u001b[0m  0.0359\n",
            "     76        \u001b[36m0.6799\u001b[0m  0.0369\n",
            "     77        \u001b[36m0.6796\u001b[0m  0.0365\n",
            "     78        \u001b[36m0.6793\u001b[0m  0.0323\n",
            "     79        \u001b[36m0.6790\u001b[0m  0.0341\n",
            "     80        \u001b[36m0.6788\u001b[0m  0.0322\n",
            "     81        \u001b[36m0.6785\u001b[0m  0.0315\n",
            "     82        \u001b[36m0.6782\u001b[0m  0.0394\n",
            "     83        \u001b[36m0.6779\u001b[0m  0.0324\n",
            "     84        \u001b[36m0.6776\u001b[0m  0.0313\n",
            "     85        \u001b[36m0.6774\u001b[0m  0.0328\n",
            "     86        \u001b[36m0.6771\u001b[0m  0.0344\n",
            "     87        \u001b[36m0.6769\u001b[0m  0.0319\n",
            "     88        \u001b[36m0.6766\u001b[0m  0.0333\n",
            "     89        \u001b[36m0.6763\u001b[0m  0.0323\n",
            "     90        \u001b[36m0.6761\u001b[0m  0.0323\n",
            "     91        \u001b[36m0.6759\u001b[0m  0.0393\n",
            "     92        \u001b[36m0.6756\u001b[0m  0.0319\n",
            "     93        \u001b[36m0.6754\u001b[0m  0.0370\n",
            "     94        \u001b[36m0.6751\u001b[0m  0.0318\n",
            "     95        \u001b[36m0.6749\u001b[0m  0.0314\n",
            "     96        \u001b[36m0.6747\u001b[0m  0.0354\n",
            "     97        \u001b[36m0.6745\u001b[0m  0.0347\n",
            "     98        \u001b[36m0.6742\u001b[0m  0.0322\n",
            "     99        \u001b[36m0.6740\u001b[0m  0.0310\n",
            "    100        \u001b[36m0.6738\u001b[0m  0.0316\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.9235\u001b[0m  0.0443\n",
            "      2        \u001b[36m1.8575\u001b[0m  0.0416\n",
            "      3        \u001b[36m1.7890\u001b[0m  0.0587\n",
            "      4        \u001b[36m1.7189\u001b[0m  0.0400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m1.6472\u001b[0m  0.0428\n",
            "      6        \u001b[36m1.5726\u001b[0m  0.0399\n",
            "      7        \u001b[36m1.4901\u001b[0m  0.0411\n",
            "      8        \u001b[36m1.3849\u001b[0m  0.0386\n",
            "      9        \u001b[36m1.2230\u001b[0m  0.0407\n",
            "     10        \u001b[36m0.9781\u001b[0m  0.0406\n",
            "     11        \u001b[36m0.7669\u001b[0m  0.0393\n",
            "     12        \u001b[36m0.6936\u001b[0m  0.0437\n",
            "     13        \u001b[36m0.6770\u001b[0m  0.0391\n",
            "     14        \u001b[36m0.6739\u001b[0m  0.0398\n",
            "     15        \u001b[36m0.6731\u001b[0m  0.0404\n",
            "     16        \u001b[36m0.6724\u001b[0m  0.0399\n",
            "     17        \u001b[36m0.6719\u001b[0m  0.0392\n",
            "     18        \u001b[36m0.6715\u001b[0m  0.0400\n",
            "     19        \u001b[36m0.6712\u001b[0m  0.0401\n",
            "     20        \u001b[36m0.6709\u001b[0m  0.0484\n",
            "     21        \u001b[36m0.6707\u001b[0m  0.0420\n",
            "     22        \u001b[36m0.6705\u001b[0m  0.0403\n",
            "     23        \u001b[36m0.6704\u001b[0m  0.0407\n",
            "     24        \u001b[36m0.6702\u001b[0m  0.0396\n",
            "     25        \u001b[36m0.6701\u001b[0m  0.0394\n",
            "     26        \u001b[36m0.6700\u001b[0m  0.0460\n",
            "     27        \u001b[36m0.6699\u001b[0m  0.0526\n",
            "     28        \u001b[36m0.6698\u001b[0m  0.0404\n",
            "     29        \u001b[36m0.6697\u001b[0m  0.0405\n",
            "     30        \u001b[36m0.6697\u001b[0m  0.0397\n",
            "     31        \u001b[36m0.6696\u001b[0m  0.0400\n",
            "     32        \u001b[36m0.6695\u001b[0m  0.0393\n",
            "     33        \u001b[36m0.6695\u001b[0m  0.0410\n",
            "     34        \u001b[36m0.6694\u001b[0m  0.0460\n",
            "     35        \u001b[36m0.6694\u001b[0m  0.0406\n",
            "     36        \u001b[36m0.6693\u001b[0m  0.0408\n",
            "     37        \u001b[36m0.6693\u001b[0m  0.0406\n",
            "     38        \u001b[36m0.6692\u001b[0m  0.0410\n",
            "     39        \u001b[36m0.6692\u001b[0m  0.0413\n",
            "     40        \u001b[36m0.6691\u001b[0m  0.0444\n",
            "     41        \u001b[36m0.6691\u001b[0m  0.0446\n",
            "     42        \u001b[36m0.6691\u001b[0m  0.0474\n",
            "     43        \u001b[36m0.6690\u001b[0m  0.0408\n",
            "     44        \u001b[36m0.6439\u001b[0m  0.0406\n",
            "     45        0.6944  0.0420\n",
            "     46        0.6801  0.0396\n",
            "     47        0.6731  0.0420\n",
            "     48        0.6701  0.0443\n",
            "     49        0.6688  0.0412\n",
            "     50        0.6601  0.0518\n",
            "     51        0.6631  0.0470\n",
            "     52        0.6620  0.0411\n",
            "     53        0.6619  0.0422\n",
            "     54        0.6618  0.0430\n",
            "     55        0.6617  0.0398\n",
            "     56        0.6617  0.0441\n",
            "     57        0.6617  0.0396\n",
            "     58        0.6616  0.0399\n",
            "     59        0.6616  0.0406\n",
            "     60        0.6616  0.0476\n",
            "     61        0.6615  0.0444\n",
            "     62        0.6615  0.0397\n",
            "     63        0.6615  0.0402\n",
            "     64        0.6615  0.0405\n",
            "     65        0.6614  0.0391\n",
            "     66        0.6614  0.0407\n",
            "     67        0.6614  0.0394\n",
            "     68        0.6613  0.0412\n",
            "     69        0.6613  0.0395\n",
            "     70        0.6613  0.0430\n",
            "     71        0.6613  0.0458\n",
            "     72        0.6612  0.0415\n",
            "     73        0.6612  0.0513\n",
            "     74        0.6612  0.0408\n",
            "     75        0.6611  0.0403\n",
            "     76        0.6611  0.0401\n",
            "     77        0.6611  0.0412\n",
            "     78        0.6611  0.0415\n",
            "     79        0.6610  0.0480\n",
            "     80        0.6610  0.0408\n",
            "     81        0.6610  0.0415\n",
            "     82        0.6609  0.0419\n",
            "     83        0.6609  0.0409\n",
            "     84        0.6609  0.0434\n",
            "     85        0.6609  0.0408\n",
            "     86        0.6608  0.0408\n",
            "     87        0.6608  0.0568\n",
            "     88        0.6608  0.0390\n",
            "     89        0.6608  0.0408\n",
            "     90        0.6607  0.0406\n",
            "     91        0.6607  0.0401\n",
            "     92        0.6607  0.0398\n",
            "     93        0.6607  0.0418\n",
            "     94        0.6606  0.0413\n",
            "     95        0.6606  0.0445\n",
            "     96        0.6606  0.0478\n",
            "     97        0.6606  0.0415\n",
            "     98        0.6605  0.0482\n",
            "     99        0.6605  0.0410\n",
            "    100        0.6605  0.0405\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5530\u001b[0m  0.0373\n",
            "      2        \u001b[36m1.4868\u001b[0m  0.0381\n",
            "      3        \u001b[36m1.4217\u001b[0m  0.0364\n",
            "      4        \u001b[36m1.3549\u001b[0m  0.0401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m1.2859\u001b[0m  0.0411\n",
            "      6        \u001b[36m1.2117\u001b[0m  0.0451\n",
            "      7        \u001b[36m1.1254\u001b[0m  0.0503\n",
            "      8        \u001b[36m1.0169\u001b[0m  0.0408\n",
            "      9        \u001b[36m0.8868\u001b[0m  0.0410\n",
            "     10        \u001b[36m0.7715\u001b[0m  0.0400\n",
            "     11        \u001b[36m0.7064\u001b[0m  0.0414\n",
            "     12        \u001b[36m0.6806\u001b[0m  0.0413\n",
            "     13        \u001b[36m0.6718\u001b[0m  0.0407\n",
            "     14        \u001b[36m0.6686\u001b[0m  0.0514\n",
            "     15        \u001b[36m0.6674\u001b[0m  0.0407\n",
            "     16        \u001b[36m0.6667\u001b[0m  0.0413\n",
            "     17        \u001b[36m0.6664\u001b[0m  0.0393\n",
            "     18        \u001b[36m0.6661\u001b[0m  0.0498\n",
            "     19        \u001b[36m0.6660\u001b[0m  0.0401\n",
            "     20        \u001b[36m0.6658\u001b[0m  0.0418\n",
            "     21        \u001b[36m0.6657\u001b[0m  0.0408\n",
            "     22        \u001b[36m0.6656\u001b[0m  0.0452\n",
            "     23        \u001b[36m0.6656\u001b[0m  0.0409\n",
            "     24        \u001b[36m0.6655\u001b[0m  0.0400\n",
            "     25        \u001b[36m0.6654\u001b[0m  0.0397\n",
            "     26        \u001b[36m0.6654\u001b[0m  0.0391\n",
            "     27        \u001b[36m0.6653\u001b[0m  0.0435\n",
            "     28        \u001b[36m0.6653\u001b[0m  0.0427\n",
            "     29        \u001b[36m0.6653\u001b[0m  0.0397\n",
            "     30        \u001b[36m0.6652\u001b[0m  0.0443\n",
            "     31        \u001b[36m0.6652\u001b[0m  0.0393\n",
            "     32        \u001b[36m0.6652\u001b[0m  0.0393\n",
            "     33        \u001b[36m0.6651\u001b[0m  0.0394\n",
            "     34        \u001b[36m0.6651\u001b[0m  0.0398\n",
            "     35        \u001b[36m0.6651\u001b[0m  0.0389\n",
            "     36        \u001b[36m0.6651\u001b[0m  0.0398\n",
            "     37        \u001b[36m0.6650\u001b[0m  0.0432\n",
            "     38        0.6679  0.0401\n",
            "     39        0.6678  0.0412\n",
            "     40        \u001b[36m0.6648\u001b[0m  0.0417\n",
            "     41        0.6684  0.0541\n",
            "     42        0.6674  0.0400\n",
            "     43        \u001b[36m0.6640\u001b[0m  0.0410\n",
            "     44        0.6653  0.0410\n",
            "     45        \u001b[36m0.6620\u001b[0m  0.0446\n",
            "     46        \u001b[36m0.6578\u001b[0m  0.0408\n",
            "     47        0.6598  0.0410\n",
            "     48        0.6600  0.0404\n",
            "     49        0.6597  0.0406\n",
            "     50        0.6597  0.0461\n",
            "     51        0.6597  0.0407\n",
            "     52        0.6588  0.0398\n",
            "     53        \u001b[36m0.6562\u001b[0m  0.0418\n",
            "     54        \u001b[36m0.6556\u001b[0m  0.0543\n",
            "     55        \u001b[36m0.6539\u001b[0m  0.0477\n",
            "     56        \u001b[36m0.6523\u001b[0m  0.0405\n",
            "     57        \u001b[36m0.6418\u001b[0m  0.0416\n",
            "     58        \u001b[36m0.6391\u001b[0m  0.0425\n",
            "     59        0.6602  0.0418\n",
            "     60        0.6757  0.0403\n",
            "     61        0.6721  0.0389\n",
            "     62        0.6660  0.0406\n",
            "     63        0.6685  0.0404\n",
            "     64        0.6725  0.0516\n",
            "     65        \u001b[36m0.6368\u001b[0m  0.0396\n",
            "     66        \u001b[36m0.6349\u001b[0m  0.0417\n",
            "     67        \u001b[36m0.6327\u001b[0m  0.0400\n",
            "     68        \u001b[36m0.6315\u001b[0m  0.0454\n",
            "     69        \u001b[36m0.6302\u001b[0m  0.0402\n",
            "     70        \u001b[36m0.6289\u001b[0m  0.0393\n",
            "     71        \u001b[36m0.6277\u001b[0m  0.0404\n",
            "     72        \u001b[36m0.6264\u001b[0m  0.0436\n",
            "     73        \u001b[36m0.6253\u001b[0m  0.0405\n",
            "     74        \u001b[36m0.6241\u001b[0m  0.0388\n",
            "     75        \u001b[36m0.6231\u001b[0m  0.0470\n",
            "     76        \u001b[36m0.6221\u001b[0m  0.0480\n",
            "     77        \u001b[36m0.6212\u001b[0m  0.0476\n",
            "     78        \u001b[36m0.6203\u001b[0m  0.0382\n",
            "     79        \u001b[36m0.6196\u001b[0m  0.0409\n",
            "     80        \u001b[36m0.6189\u001b[0m  0.0414\n",
            "     81        \u001b[36m0.6183\u001b[0m  0.0403\n",
            "     82        \u001b[36m0.6177\u001b[0m  0.0427\n",
            "     83        \u001b[36m0.6172\u001b[0m  0.0394\n",
            "     84        \u001b[36m0.6167\u001b[0m  0.0425\n",
            "     85        \u001b[36m0.6163\u001b[0m  0.0394\n",
            "     86        \u001b[36m0.6160\u001b[0m  0.0397\n",
            "     87        \u001b[36m0.6157\u001b[0m  0.0557\n",
            "     88        \u001b[36m0.6154\u001b[0m  0.0419\n",
            "     89        \u001b[36m0.6152\u001b[0m  0.0411\n",
            "     90        \u001b[36m0.6149\u001b[0m  0.0419\n",
            "     91        \u001b[36m0.6147\u001b[0m  0.0407\n",
            "     92        \u001b[36m0.6146\u001b[0m  0.0410\n",
            "     93        \u001b[36m0.6144\u001b[0m  0.0450\n",
            "     94        \u001b[36m0.6143\u001b[0m  0.0431\n",
            "     95        \u001b[36m0.5930\u001b[0m  0.0484\n",
            "     96        0.6399  0.0429\n",
            "     97        0.6261  0.0478\n",
            "     98        0.6198  0.0399\n",
            "     99        0.6173  0.0409\n",
            "    100        0.6162  0.0424\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5762\u001b[0m  0.0292\n",
            "      2        \u001b[36m1.5422\u001b[0m  0.0331\n",
            "      3        \u001b[36m1.5085\u001b[0m  0.0353\n",
            "      4        \u001b[36m1.4751\u001b[0m  0.0384\n",
            "      5        \u001b[36m1.4420\u001b[0m  0.0330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m1.4093\u001b[0m  0.0371\n",
            "      7        \u001b[36m1.3770\u001b[0m  0.0430\n",
            "      8        \u001b[36m1.3452\u001b[0m  0.0331\n",
            "      9        \u001b[36m1.3138\u001b[0m  0.0330\n",
            "     10        \u001b[36m1.2829\u001b[0m  0.0316\n",
            "     11        \u001b[36m1.2525\u001b[0m  0.0412\n",
            "     12        \u001b[36m1.2227\u001b[0m  0.0335\n",
            "     13        \u001b[36m1.1935\u001b[0m  0.0327\n",
            "     14        \u001b[36m1.1650\u001b[0m  0.0318\n",
            "     15        \u001b[36m1.1372\u001b[0m  0.0322\n",
            "     16        \u001b[36m1.1100\u001b[0m  0.0326\n",
            "     17        \u001b[36m1.0837\u001b[0m  0.0346\n",
            "     18        \u001b[36m1.0581\u001b[0m  0.0375\n",
            "     19        \u001b[36m1.0333\u001b[0m  0.0319\n",
            "     20        \u001b[36m1.0094\u001b[0m  0.0354\n",
            "     21        \u001b[36m0.9864\u001b[0m  0.0313\n",
            "     22        \u001b[36m0.9642\u001b[0m  0.0380\n",
            "     23        \u001b[36m0.9430\u001b[0m  0.0320\n",
            "     24        \u001b[36m0.9228\u001b[0m  0.0318\n",
            "     25        \u001b[36m0.9035\u001b[0m  0.0310\n",
            "     26        \u001b[36m0.8851\u001b[0m  0.0343\n",
            "     27        \u001b[36m0.8677\u001b[0m  0.0312\n",
            "     28        \u001b[36m0.8513\u001b[0m  0.0328\n",
            "     29        \u001b[36m0.8358\u001b[0m  0.0327\n",
            "     30        \u001b[36m0.8213\u001b[0m  0.0339\n",
            "     31        \u001b[36m0.8077\u001b[0m  0.0344\n",
            "     32        \u001b[36m0.7949\u001b[0m  0.0332\n",
            "     33        \u001b[36m0.7831\u001b[0m  0.0327\n",
            "     34        \u001b[36m0.7721\u001b[0m  0.0360\n",
            "     35        \u001b[36m0.7619\u001b[0m  0.0368\n",
            "     36        \u001b[36m0.7525\u001b[0m  0.0302\n",
            "     37        \u001b[36m0.7438\u001b[0m  0.0311\n",
            "     38        \u001b[36m0.7358\u001b[0m  0.0327\n",
            "     39        \u001b[36m0.7285\u001b[0m  0.0412\n",
            "     40        \u001b[36m0.7218\u001b[0m  0.0330\n",
            "     41        \u001b[36m0.7157\u001b[0m  0.0335\n",
            "     42        \u001b[36m0.7101\u001b[0m  0.0347\n",
            "     43        \u001b[36m0.7051\u001b[0m  0.0327\n",
            "     44        \u001b[36m0.7005\u001b[0m  0.0346\n",
            "     45        \u001b[36m0.6963\u001b[0m  0.0326\n",
            "     46        \u001b[36m0.6926\u001b[0m  0.0318\n",
            "     47        \u001b[36m0.6892\u001b[0m  0.0363\n",
            "     48        \u001b[36m0.6861\u001b[0m  0.0391\n",
            "     49        \u001b[36m0.6834\u001b[0m  0.0327\n",
            "     50        \u001b[36m0.6809\u001b[0m  0.0379\n",
            "     51        \u001b[36m0.6787\u001b[0m  0.0331\n",
            "     52        \u001b[36m0.6767\u001b[0m  0.0352\n",
            "     53        \u001b[36m0.6750\u001b[0m  0.0334\n",
            "     54        \u001b[36m0.6734\u001b[0m  0.0327\n",
            "     55        \u001b[36m0.6720\u001b[0m  0.0333\n",
            "     56        \u001b[36m0.6707\u001b[0m  0.0306\n",
            "     57        \u001b[36m0.6696\u001b[0m  0.0313\n",
            "     58        \u001b[36m0.6686\u001b[0m  0.0342\n",
            "     59        \u001b[36m0.6677\u001b[0m  0.0350\n",
            "     60        \u001b[36m0.6669\u001b[0m  0.0320\n",
            "     61        \u001b[36m0.6662\u001b[0m  0.0376\n",
            "     62        \u001b[36m0.6656\u001b[0m  0.0325\n",
            "     63        \u001b[36m0.6650\u001b[0m  0.0328\n",
            "     64        \u001b[36m0.6645\u001b[0m  0.0322\n",
            "     65        \u001b[36m0.6641\u001b[0m  0.0338\n",
            "     66        \u001b[36m0.6637\u001b[0m  0.0324\n",
            "     67        \u001b[36m0.6634\u001b[0m  0.0438\n",
            "     68        \u001b[36m0.6631\u001b[0m  0.0333\n",
            "     69        \u001b[36m0.6628\u001b[0m  0.0312\n",
            "     70        \u001b[36m0.6626\u001b[0m  0.0361\n",
            "     71        \u001b[36m0.6624\u001b[0m  0.0355\n",
            "     72        \u001b[36m0.6622\u001b[0m  0.0343\n",
            "     73        \u001b[36m0.6621\u001b[0m  0.0333\n",
            "     74        \u001b[36m0.6619\u001b[0m  0.0328\n",
            "     75        \u001b[36m0.6618\u001b[0m  0.0417\n",
            "     76        \u001b[36m0.6617\u001b[0m  0.0328\n",
            "     77        \u001b[36m0.6616\u001b[0m  0.0324\n",
            "     78        \u001b[36m0.6615\u001b[0m  0.0327\n",
            "     79        \u001b[36m0.6615\u001b[0m  0.0315\n",
            "     80        \u001b[36m0.6614\u001b[0m  0.0316\n",
            "     81        \u001b[36m0.6613\u001b[0m  0.0333\n",
            "     82        \u001b[36m0.6613\u001b[0m  0.0346\n",
            "     83        \u001b[36m0.6613\u001b[0m  0.0338\n",
            "     84        \u001b[36m0.6612\u001b[0m  0.0331\n",
            "     85        \u001b[36m0.6612\u001b[0m  0.0325\n",
            "     86        \u001b[36m0.6612\u001b[0m  0.0374\n",
            "     87        \u001b[36m0.6612\u001b[0m  0.0370\n",
            "     88        \u001b[36m0.6611\u001b[0m  0.0326\n",
            "     89        \u001b[36m0.6611\u001b[0m  0.0348\n",
            "     90        \u001b[36m0.6611\u001b[0m  0.0320\n",
            "     91        \u001b[36m0.6611\u001b[0m  0.0309\n",
            "     92        \u001b[36m0.6611\u001b[0m  0.0317\n",
            "     93        \u001b[36m0.6611\u001b[0m  0.0374\n",
            "     94        \u001b[36m0.6611\u001b[0m  0.0326\n",
            "     95        \u001b[36m0.6611\u001b[0m  0.0430\n",
            "     96        \u001b[36m0.6611\u001b[0m  0.0338\n",
            "     97        \u001b[36m0.6611\u001b[0m  0.0367\n",
            "     98        \u001b[36m0.6611\u001b[0m  0.0321\n",
            "     99        \u001b[36m0.6611\u001b[0m  0.0327\n",
            "    100        \u001b[36m0.6611\u001b[0m  0.0395\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m1.5111\u001b[0m  0.0308\n",
            "      2        \u001b[36m1.4793\u001b[0m  0.0323\n",
            "      3        \u001b[36m1.4478\u001b[0m  0.0323\n",
            "      4        \u001b[36m1.4167\u001b[0m  0.0322\n",
            "      5        \u001b[36m1.3860\u001b[0m  0.0335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m1.3556\u001b[0m  0.0357\n",
            "      7        \u001b[36m1.3257\u001b[0m  0.0367\n",
            "      8        \u001b[36m1.2962\u001b[0m  0.0331\n",
            "      9        \u001b[36m1.2672\u001b[0m  0.0330\n",
            "     10        \u001b[36m1.2387\u001b[0m  0.0329\n",
            "     11        \u001b[36m1.2107\u001b[0m  0.0342\n",
            "     12        \u001b[36m1.1833\u001b[0m  0.0403\n",
            "     13        \u001b[36m1.1565\u001b[0m  0.0306\n",
            "     14        \u001b[36m1.1303\u001b[0m  0.0331\n",
            "     15        \u001b[36m1.1048\u001b[0m  0.0332\n",
            "     16        \u001b[36m1.0800\u001b[0m  0.0326\n",
            "     17        \u001b[36m1.0559\u001b[0m  0.0322\n",
            "     18        \u001b[36m1.0326\u001b[0m  0.0338\n",
            "     19        \u001b[36m1.0100\u001b[0m  0.0340\n",
            "     20        \u001b[36m0.9883\u001b[0m  0.0315\n",
            "     21        \u001b[36m0.9673\u001b[0m  0.0375\n",
            "     22        \u001b[36m0.9472\u001b[0m  0.0357\n",
            "     23        \u001b[36m0.9280\u001b[0m  0.0399\n",
            "     24        \u001b[36m0.9096\u001b[0m  0.0334\n",
            "     25        \u001b[36m0.8920\u001b[0m  0.0331\n",
            "     26        \u001b[36m0.8754\u001b[0m  0.0333\n",
            "     27        \u001b[36m0.8596\u001b[0m  0.0325\n",
            "     28        \u001b[36m0.8446\u001b[0m  0.0318\n",
            "     29        \u001b[36m0.8305\u001b[0m  0.0330\n",
            "     30        \u001b[36m0.8173\u001b[0m  0.0345\n",
            "     31        \u001b[36m0.8048\u001b[0m  0.0320\n",
            "     32        \u001b[36m0.7932\u001b[0m  0.0327\n",
            "     33        \u001b[36m0.7823\u001b[0m  0.0370\n",
            "     34        \u001b[36m0.7721\u001b[0m  0.0336\n",
            "     35        \u001b[36m0.7627\u001b[0m  0.0336\n",
            "     36        \u001b[36m0.7539\u001b[0m  0.0389\n",
            "     37        \u001b[36m0.7458\u001b[0m  0.0336\n",
            "     38        \u001b[36m0.7384\u001b[0m  0.0335\n",
            "     39        \u001b[36m0.7315\u001b[0m  0.0332\n",
            "     40        \u001b[36m0.7251\u001b[0m  0.0347\n",
            "     41        \u001b[36m0.7193\u001b[0m  0.0342\n",
            "     42        \u001b[36m0.7139\u001b[0m  0.0343\n",
            "     43        \u001b[36m0.7090\u001b[0m  0.0346\n",
            "     44        \u001b[36m0.7046\u001b[0m  0.0347\n",
            "     45        \u001b[36m0.7005\u001b[0m  0.0325\n",
            "     46        \u001b[36m0.6968\u001b[0m  0.0428\n",
            "     47        \u001b[36m0.6934\u001b[0m  0.0329\n",
            "     48        \u001b[36m0.6903\u001b[0m  0.0339\n",
            "     49        \u001b[36m0.6875\u001b[0m  0.0331\n",
            "     50        \u001b[36m0.6849\u001b[0m  0.0387\n",
            "     51        \u001b[36m0.6826\u001b[0m  0.0382\n",
            "     52        \u001b[36m0.6805\u001b[0m  0.0332\n",
            "     53        \u001b[36m0.6787\u001b[0m  0.0343\n",
            "     54        \u001b[36m0.6769\u001b[0m  0.0317\n",
            "     55        \u001b[36m0.6754\u001b[0m  0.0310\n",
            "     56        \u001b[36m0.6740\u001b[0m  0.0401\n",
            "     57        \u001b[36m0.6727\u001b[0m  0.0372\n",
            "     58        \u001b[36m0.6716\u001b[0m  0.0328\n",
            "     59        \u001b[36m0.6705\u001b[0m  0.0336\n",
            "     60        \u001b[36m0.6696\u001b[0m  0.0371\n",
            "     61        \u001b[36m0.6688\u001b[0m  0.0322\n",
            "     62        \u001b[36m0.6680\u001b[0m  0.0325\n",
            "     63        \u001b[36m0.6673\u001b[0m  0.0330\n",
            "     64        \u001b[36m0.6667\u001b[0m  0.0320\n",
            "     65        \u001b[36m0.6661\u001b[0m  0.0304\n",
            "     66        \u001b[36m0.6656\u001b[0m  0.0344\n",
            "     67        \u001b[36m0.6652\u001b[0m  0.0367\n",
            "     68        \u001b[36m0.6648\u001b[0m  0.0331\n",
            "     69        \u001b[36m0.6644\u001b[0m  0.0327\n",
            "     70        \u001b[36m0.6640\u001b[0m  0.0343\n",
            "     71        \u001b[36m0.6637\u001b[0m  0.0372\n",
            "     72        \u001b[36m0.6635\u001b[0m  0.0373\n",
            "     73        \u001b[36m0.6632\u001b[0m  0.0332\n",
            "     74        \u001b[36m0.6630\u001b[0m  0.0323\n",
            "     75        \u001b[36m0.6628\u001b[0m  0.0339\n",
            "     76        \u001b[36m0.6626\u001b[0m  0.0316\n",
            "     77        \u001b[36m0.6624\u001b[0m  0.0343\n",
            "     78        \u001b[36m0.6623\u001b[0m  0.0428\n",
            "     79        \u001b[36m0.6621\u001b[0m  0.0335\n",
            "     80        \u001b[36m0.6620\u001b[0m  0.0341\n",
            "     81        \u001b[36m0.6619\u001b[0m  0.0425\n",
            "     82        \u001b[36m0.6618\u001b[0m  0.0336\n",
            "     83        \u001b[36m0.6617\u001b[0m  0.0403\n",
            "     84        \u001b[36m0.6616\u001b[0m  0.0348\n",
            "     85        \u001b[36m0.6615\u001b[0m  0.0320\n",
            "     86        \u001b[36m0.6614\u001b[0m  0.0341\n",
            "     87        \u001b[36m0.6614\u001b[0m  0.0326\n",
            "     88        \u001b[36m0.6613\u001b[0m  0.0330\n",
            "     89        \u001b[36m0.6613\u001b[0m  0.0333\n",
            "     90        \u001b[36m0.6612\u001b[0m  0.0332\n",
            "     91        \u001b[36m0.6612\u001b[0m  0.0338\n",
            "     92        \u001b[36m0.6611\u001b[0m  0.0334\n",
            "     93        \u001b[36m0.6611\u001b[0m  0.0342\n",
            "     94        \u001b[36m0.6610\u001b[0m  0.0366\n",
            "     95        \u001b[36m0.6610\u001b[0m  0.0323\n",
            "     96        \u001b[36m0.6610\u001b[0m  0.0330\n",
            "     97        \u001b[36m0.6610\u001b[0m  0.0350\n",
            "     98        \u001b[36m0.6609\u001b[0m  0.0342\n",
            "     99        \u001b[36m0.6609\u001b[0m  0.0330\n",
            "    100        \u001b[36m0.6609\u001b[0m  0.0291\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.6974\u001b[0m  0.0384\n",
            "      2        \u001b[36m2.5707\u001b[0m  0.0412\n",
            "      3        \u001b[36m2.4390\u001b[0m  0.0405\n",
            "      4        \u001b[36m2.3043\u001b[0m  0.0475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m2.1681\u001b[0m  0.0496\n",
            "      6        \u001b[36m2.0287\u001b[0m  0.0419\n",
            "      7        \u001b[36m1.8666\u001b[0m  0.0395\n",
            "      8        \u001b[36m1.5984\u001b[0m  0.0458\n",
            "      9        \u001b[36m1.1698\u001b[0m  0.0410\n",
            "     10        \u001b[36m0.8075\u001b[0m  0.0413\n",
            "     11        \u001b[36m0.6951\u001b[0m  0.0454\n",
            "     12        \u001b[36m0.6748\u001b[0m  0.0439\n",
            "     13        \u001b[36m0.6708\u001b[0m  0.0419\n",
            "     14        \u001b[36m0.6696\u001b[0m  0.0418\n",
            "     15        \u001b[36m0.6690\u001b[0m  0.0420\n",
            "     16        \u001b[36m0.6688\u001b[0m  0.0424\n",
            "     17        \u001b[36m0.6686\u001b[0m  0.0391\n",
            "     18        \u001b[36m0.6684\u001b[0m  0.0417\n",
            "     19        \u001b[36m0.6684\u001b[0m  0.0459\n",
            "     20        \u001b[36m0.6683\u001b[0m  0.0402\n",
            "     21        \u001b[36m0.6682\u001b[0m  0.0412\n",
            "     22        \u001b[36m0.6682\u001b[0m  0.0545\n",
            "     23        \u001b[36m0.6682\u001b[0m  0.0450\n",
            "     24        \u001b[36m0.6681\u001b[0m  0.0455\n",
            "     25        \u001b[36m0.6681\u001b[0m  0.0409\n",
            "     26        \u001b[36m0.6680\u001b[0m  0.0414\n",
            "     27        \u001b[36m0.6680\u001b[0m  0.0544\n",
            "     28        \u001b[36m0.6680\u001b[0m  0.0410\n",
            "     29        \u001b[36m0.6679\u001b[0m  0.0422\n",
            "     30        \u001b[36m0.6679\u001b[0m  0.0464\n",
            "     31        \u001b[36m0.6678\u001b[0m  0.0407\n",
            "     32        \u001b[36m0.6678\u001b[0m  0.0402\n",
            "     33        \u001b[36m0.6677\u001b[0m  0.0405\n",
            "     34        \u001b[36m0.6677\u001b[0m  0.0408\n",
            "     35        \u001b[36m0.6676\u001b[0m  0.0411\n",
            "     36        \u001b[36m0.6676\u001b[0m  0.0402\n",
            "     37        \u001b[36m0.6676\u001b[0m  0.0461\n",
            "     38        \u001b[36m0.6676\u001b[0m  0.0427\n",
            "     39        \u001b[36m0.6675\u001b[0m  0.0401\n",
            "     40        \u001b[36m0.6675\u001b[0m  0.0403\n",
            "     41        \u001b[36m0.6675\u001b[0m  0.0411\n",
            "     42        \u001b[36m0.6675\u001b[0m  0.0399\n",
            "     43        0.6675  0.0402\n",
            "     44        \u001b[36m0.6674\u001b[0m  0.0414\n",
            "     45        0.6716  0.0449\n",
            "     46        0.7117  0.0410\n",
            "     47        0.6874  0.0445\n",
            "     48        0.6781  0.0417\n",
            "     49        0.6753  0.0405\n",
            "     50        0.6685  0.0515\n",
            "     51        0.7260  0.0505\n",
            "     52        0.6960  0.0389\n",
            "     53        0.6858  0.0414\n",
            "     54        0.6830  0.0400\n",
            "     55        0.6679  0.0398\n",
            "     56        0.7386  0.0410\n",
            "     57        0.6997  0.0406\n",
            "     58        0.6931  0.0416\n",
            "     59        0.6963  0.0396\n",
            "     60        0.6906  0.0414\n",
            "     61        0.6853  0.0466\n",
            "     62        0.6802  0.0398\n",
            "     63        0.6806  0.0401\n",
            "     64        0.6810  0.0407\n",
            "     65        0.6993  0.0434\n",
            "     66        0.6720  0.0481\n",
            "     67        0.6699  0.0398\n",
            "     68        \u001b[36m0.6660\u001b[0m  0.0400\n",
            "     69        \u001b[36m0.6628\u001b[0m  0.0417\n",
            "     70        \u001b[36m0.6603\u001b[0m  0.0409\n",
            "     71        \u001b[36m0.6583\u001b[0m  0.0415\n",
            "     72        \u001b[36m0.6565\u001b[0m  0.0417\n",
            "     73        \u001b[36m0.6549\u001b[0m  0.0511\n",
            "     74        \u001b[36m0.6535\u001b[0m  0.0472\n",
            "     75        \u001b[36m0.6522\u001b[0m  0.0417\n",
            "     76        \u001b[36m0.6511\u001b[0m  0.0413\n",
            "     77        \u001b[36m0.6500\u001b[0m  0.0419\n",
            "     78        \u001b[36m0.6491\u001b[0m  0.0469\n",
            "     79        \u001b[36m0.6482\u001b[0m  0.0399\n",
            "     80        \u001b[36m0.6473\u001b[0m  0.0397\n",
            "     81        \u001b[36m0.6465\u001b[0m  0.0399\n",
            "     82        \u001b[36m0.6458\u001b[0m  0.0428\n",
            "     83        \u001b[36m0.6450\u001b[0m  0.0433\n",
            "     84        \u001b[36m0.6444\u001b[0m  0.0407\n",
            "     85        \u001b[36m0.6437\u001b[0m  0.0455\n",
            "     86        \u001b[36m0.6431\u001b[0m  0.0439\n",
            "     87        \u001b[36m0.6425\u001b[0m  0.0397\n",
            "     88        \u001b[36m0.6347\u001b[0m  0.0421\n",
            "     89        0.6383  0.0413\n",
            "     90        0.6772  0.0411\n",
            "     91        0.6575  0.0411\n",
            "     92        0.6538  0.0413\n",
            "     93        0.6537  0.0394\n",
            "     94        0.6532  0.0442\n",
            "     95        0.6526  0.0411\n",
            "     96        0.6519  0.0504\n",
            "     97        0.6514  0.0415\n",
            "     98        0.6508  0.0475\n",
            "     99        0.6503  0.0400\n",
            "    100        0.6498  0.0406\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m2.2612\u001b[0m  0.0352\n",
            "      2        \u001b[36m2.1311\u001b[0m  0.0405\n",
            "      3        \u001b[36m2.0027\u001b[0m  0.0421\n",
            "      4        \u001b[36m1.8723\u001b[0m  0.0394\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      5        \u001b[36m1.7417\u001b[0m  0.0454\n",
            "      6        \u001b[36m1.6123\u001b[0m  0.0431\n",
            "      7        \u001b[36m1.4851\u001b[0m  0.0404\n",
            "      8        \u001b[36m1.3601\u001b[0m  0.0413\n",
            "      9        \u001b[36m1.2281\u001b[0m  0.0394\n",
            "     10        \u001b[36m1.0634\u001b[0m  0.0400\n",
            "     11        \u001b[36m0.8767\u001b[0m  0.0416\n",
            "     12        \u001b[36m0.7321\u001b[0m  0.0451\n",
            "     13        \u001b[36m0.6801\u001b[0m  0.0410\n",
            "     14        \u001b[36m0.6709\u001b[0m  0.0420\n",
            "     15        \u001b[36m0.6692\u001b[0m  0.0410\n",
            "     16        \u001b[36m0.6686\u001b[0m  0.0398\n",
            "     17        \u001b[36m0.6683\u001b[0m  0.0411\n",
            "     18        \u001b[36m0.6680\u001b[0m  0.0541\n",
            "     19        \u001b[36m0.6678\u001b[0m  0.0441\n",
            "     20        \u001b[36m0.6677\u001b[0m  0.0398\n",
            "     21        \u001b[36m0.6676\u001b[0m  0.0418\n",
            "     22        \u001b[36m0.6672\u001b[0m  0.0405\n",
            "     23        \u001b[36m0.6499\u001b[0m  0.0404\n",
            "     24        0.6893  0.0401\n",
            "     25        0.6823  0.0401\n",
            "     26        0.6777  0.0454\n",
            "     27        0.6753  0.0399\n",
            "     28        0.6739  0.0417\n",
            "     29        0.6729  0.0401\n",
            "     30        0.6721  0.0406\n",
            "     31        0.6714  0.0411\n",
            "     32        0.6707  0.0446\n",
            "     33        0.6700  0.0391\n",
            "     34        0.6694  0.0394\n",
            "     35        0.6687  0.0412\n",
            "     36        0.6681  0.0388\n",
            "     37        0.6674  0.0401\n",
            "     38        0.6667  0.0397\n",
            "     39        0.6661  0.0404\n",
            "     40        0.6654  0.0407\n",
            "     41        0.6647  0.0407\n",
            "     42        0.6638  0.0579\n",
            "     43        0.6629  0.0414\n",
            "     44        0.6615  0.0402\n",
            "     45        \u001b[36m0.6453\u001b[0m  0.0458\n",
            "     46        0.6760  0.0449\n",
            "     47        0.6606  0.0404\n",
            "     48        0.6525  0.0403\n",
            "     49        0.6497  0.0422\n",
            "     50        \u001b[36m0.6369\u001b[0m  0.0436\n",
            "     51        0.6614  0.0413\n",
            "     52        0.6488  0.0413\n",
            "     53        0.6456  0.0407\n",
            "     54        0.6442  0.0401\n",
            "     55        0.6431  0.0428\n",
            "     56        0.6422  0.0416\n",
            "     57        0.6413  0.0439\n",
            "     58        0.6404  0.0420\n",
            "     59        \u001b[36m0.6293\u001b[0m  0.0408\n",
            "     60        0.6637  0.0447\n",
            "     61        0.6454  0.0396\n",
            "     62        0.6409  0.0404\n",
            "     63        0.6399  0.0398\n",
            "     64        0.6392  0.0401\n",
            "     65        0.6385  0.0471\n",
            "     66        0.6379  0.0466\n",
            "     67        0.6374  0.0445\n",
            "     68        0.6370  0.0400\n",
            "     69        0.6366  0.0450\n",
            "     70        0.6362  0.0397\n",
            "     71        0.6359  0.0404\n",
            "     72        0.6356  0.0408\n",
            "     73        0.6354  0.0422\n",
            "     74        0.6351  0.0398\n",
            "     75        0.6350  0.0399\n",
            "     76        0.6349  0.0412\n",
            "     77        0.6344  0.0395\n",
            "     78        0.6342  0.0410\n",
            "     79        0.6340  0.0388\n",
            "     80        0.6338  0.0473\n",
            "     81        0.6337  0.0410\n",
            "     82        0.6335  0.0421\n",
            "     83        0.6333  0.0417\n",
            "     84        0.6332  0.0413\n",
            "     85        0.6330  0.0430\n",
            "     86        0.6329  0.0495\n",
            "     87        0.6327  0.0398\n",
            "     88        0.6326  0.0501\n",
            "     89        0.6324  0.0469\n",
            "     90        0.6323  0.0405\n",
            "     91        0.6322  0.0395\n",
            "     92        0.6320  0.0398\n",
            "     93        0.6319  0.0409\n",
            "     94        0.6318  0.0418\n",
            "     95        0.6317  0.0441\n",
            "     96        0.6316  0.0403\n",
            "     97        0.6315  0.0408\n",
            "     98        0.6313  0.0470\n",
            "     99        0.6314  0.0429\n",
            "    100        0.6311  0.0418\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m3.0678\u001b[0m  0.0281\n",
            "      2        \u001b[36m2.9978\u001b[0m  0.0337\n",
            "      3        \u001b[36m2.9278\u001b[0m  0.0334\n",
            "      4        \u001b[36m2.8579\u001b[0m  0.0370\n",
            "      5        \u001b[36m2.7880\u001b[0m  0.0313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m2.7181\u001b[0m  0.0336\n",
            "      7        \u001b[36m2.6482\u001b[0m  0.0381\n",
            "      8        \u001b[36m2.5785\u001b[0m  0.0327\n",
            "      9        \u001b[36m2.5088\u001b[0m  0.0310\n",
            "     10        \u001b[36m2.4391\u001b[0m  0.0326\n",
            "     11        \u001b[36m2.3696\u001b[0m  0.0324\n",
            "     12        \u001b[36m2.3002\u001b[0m  0.0325\n",
            "     13        \u001b[36m2.2310\u001b[0m  0.0375\n",
            "     14        \u001b[36m2.1619\u001b[0m  0.0365\n",
            "     15        \u001b[36m2.0931\u001b[0m  0.0398\n",
            "     16        \u001b[36m2.0245\u001b[0m  0.0305\n",
            "     17        \u001b[36m1.9562\u001b[0m  0.0317\n",
            "     18        \u001b[36m1.8883\u001b[0m  0.0385\n",
            "     19        \u001b[36m1.8208\u001b[0m  0.0339\n",
            "     20        \u001b[36m1.7538\u001b[0m  0.0331\n",
            "     21        \u001b[36m1.6875\u001b[0m  0.0347\n",
            "     22        \u001b[36m1.6219\u001b[0m  0.0333\n",
            "     23        \u001b[36m1.5571\u001b[0m  0.0350\n",
            "     24        \u001b[36m1.4934\u001b[0m  0.0318\n",
            "     25        \u001b[36m1.4308\u001b[0m  0.0341\n",
            "     26        \u001b[36m1.3697\u001b[0m  0.0325\n",
            "     27        \u001b[36m1.3101\u001b[0m  0.0334\n",
            "     28        \u001b[36m1.2523\u001b[0m  0.0334\n",
            "     29        \u001b[36m1.1966\u001b[0m  0.0337\n",
            "     30        \u001b[36m1.1432\u001b[0m  0.0385\n",
            "     31        \u001b[36m1.0923\u001b[0m  0.0334\n",
            "     32        \u001b[36m1.0442\u001b[0m  0.0347\n",
            "     33        \u001b[36m0.9992\u001b[0m  0.0332\n",
            "     34        \u001b[36m0.9573\u001b[0m  0.0347\n",
            "     35        \u001b[36m0.9187\u001b[0m  0.0335\n",
            "     36        \u001b[36m0.8836\u001b[0m  0.0338\n",
            "     37        \u001b[36m0.8518\u001b[0m  0.0326\n",
            "     38        \u001b[36m0.8235\u001b[0m  0.0325\n",
            "     39        \u001b[36m0.7984\u001b[0m  0.0336\n",
            "     40        \u001b[36m0.7765\u001b[0m  0.0417\n",
            "     41        \u001b[36m0.7574\u001b[0m  0.0413\n",
            "     42        \u001b[36m0.7411\u001b[0m  0.0385\n",
            "     43        \u001b[36m0.7272\u001b[0m  0.0350\n",
            "     44        \u001b[36m0.7154\u001b[0m  0.0324\n",
            "     45        \u001b[36m0.7056\u001b[0m  0.0331\n",
            "     46        \u001b[36m0.6974\u001b[0m  0.0330\n",
            "     47        \u001b[36m0.6906\u001b[0m  0.0331\n",
            "     48        \u001b[36m0.6850\u001b[0m  0.0354\n",
            "     49        \u001b[36m0.6804\u001b[0m  0.0318\n",
            "     50        \u001b[36m0.6766\u001b[0m  0.0356\n",
            "     51        \u001b[36m0.6736\u001b[0m  0.0334\n",
            "     52        \u001b[36m0.6712\u001b[0m  0.0347\n",
            "     53        \u001b[36m0.6692\u001b[0m  0.0327\n",
            "     54        \u001b[36m0.6676\u001b[0m  0.0320\n",
            "     55        \u001b[36m0.6663\u001b[0m  0.0323\n",
            "     56        \u001b[36m0.6653\u001b[0m  0.0336\n",
            "     57        \u001b[36m0.6645\u001b[0m  0.0321\n",
            "     58        \u001b[36m0.6638\u001b[0m  0.0321\n",
            "     59        \u001b[36m0.6633\u001b[0m  0.0334\n",
            "     60        \u001b[36m0.6629\u001b[0m  0.0333\n",
            "     61        \u001b[36m0.6626\u001b[0m  0.0352\n",
            "     62        \u001b[36m0.6623\u001b[0m  0.0377\n",
            "     63        \u001b[36m0.6621\u001b[0m  0.0327\n",
            "     64        \u001b[36m0.6619\u001b[0m  0.0372\n",
            "     65        \u001b[36m0.6618\u001b[0m  0.0538\n",
            "     66        \u001b[36m0.6617\u001b[0m  0.0373\n",
            "     67        \u001b[36m0.6616\u001b[0m  0.0346\n",
            "     68        \u001b[36m0.6616\u001b[0m  0.0380\n",
            "     69        \u001b[36m0.6615\u001b[0m  0.0432\n",
            "     70        \u001b[36m0.6615\u001b[0m  0.0338\n",
            "     71        \u001b[36m0.6615\u001b[0m  0.0334\n",
            "     72        \u001b[36m0.6614\u001b[0m  0.0341\n",
            "     73        \u001b[36m0.6614\u001b[0m  0.0321\n",
            "     74        \u001b[36m0.6614\u001b[0m  0.0368\n",
            "     75        \u001b[36m0.6614\u001b[0m  0.0331\n",
            "     76        \u001b[36m0.6614\u001b[0m  0.0349\n",
            "     77        \u001b[36m0.6614\u001b[0m  0.0337\n",
            "     78        \u001b[36m0.6614\u001b[0m  0.0350\n",
            "     79        \u001b[36m0.6614\u001b[0m  0.0333\n",
            "     80        \u001b[36m0.6614\u001b[0m  0.0348\n",
            "     81        \u001b[36m0.6614\u001b[0m  0.0339\n",
            "     82        \u001b[36m0.6614\u001b[0m  0.0350\n",
            "     83        \u001b[36m0.6614\u001b[0m  0.0335\n",
            "     84        \u001b[36m0.6614\u001b[0m  0.0315\n",
            "     85        0.6614  0.0320\n",
            "     86        0.6614  0.0382\n",
            "     87        0.6614  0.0342\n",
            "     88        0.6614  0.0412\n",
            "     89        0.6614  0.0328\n",
            "     90        0.6614  0.0327\n",
            "     91        0.6614  0.0335\n",
            "     92        0.6614  0.0329\n",
            "     93        0.6614  0.0303\n",
            "     94        0.6614  0.0324\n",
            "     95        0.6614  0.0345\n",
            "     96        0.6614  0.0378\n",
            "     97        0.6614  0.0345\n",
            "     98        0.6614  0.0349\n",
            "     99        0.6614  0.0337\n",
            "    100        0.6614  0.0326\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1        \u001b[36m4.1552\u001b[0m  0.0382\n",
            "      2        \u001b[36m4.0882\u001b[0m  0.0361\n",
            "      3        \u001b[36m4.0212\u001b[0m  0.0334\n",
            "      4        \u001b[36m3.9541\u001b[0m  0.0324\n",
            "      5        \u001b[36m3.8871\u001b[0m  0.0343\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1795: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      6        \u001b[36m3.8201\u001b[0m  0.0348\n",
            "      7        \u001b[36m3.7531\u001b[0m  0.0352\n",
            "      8        \u001b[36m3.6861\u001b[0m  0.0321\n",
            "      9        \u001b[36m3.6191\u001b[0m  0.0324\n",
            "     10        \u001b[36m3.5520\u001b[0m  0.0323\n",
            "     11        \u001b[36m3.4850\u001b[0m  0.0329\n",
            "     12        \u001b[36m3.4180\u001b[0m  0.0384\n",
            "     13        \u001b[36m3.3511\u001b[0m  0.0351\n",
            "     14        \u001b[36m3.2841\u001b[0m  0.0337\n",
            "     15        \u001b[36m3.2171\u001b[0m  0.0312\n",
            "     16        \u001b[36m3.1501\u001b[0m  0.0315\n",
            "     17        \u001b[36m3.0832\u001b[0m  0.0347\n",
            "     18        \u001b[36m3.0163\u001b[0m  0.0316\n",
            "     19        \u001b[36m2.9494\u001b[0m  0.0322\n",
            "     20        \u001b[36m2.8825\u001b[0m  0.0327\n",
            "     21        \u001b[36m2.8156\u001b[0m  0.0418\n",
            "     22        \u001b[36m2.7488\u001b[0m  0.0326\n",
            "     23        \u001b[36m2.6820\u001b[0m  0.0373\n",
            "     24        \u001b[36m2.6153\u001b[0m  0.0413\n",
            "     25        \u001b[36m2.5486\u001b[0m  0.0313\n",
            "     26        \u001b[36m2.4820\u001b[0m  0.0327\n",
            "     27        \u001b[36m2.4155\u001b[0m  0.0309\n",
            "     28        \u001b[36m2.3491\u001b[0m  0.0354\n",
            "     29        \u001b[36m2.2828\u001b[0m  0.0320\n",
            "     30        \u001b[36m2.2167\u001b[0m  0.0343\n",
            "     31        \u001b[36m2.1507\u001b[0m  0.0382\n",
            "     32        \u001b[36m2.0849\u001b[0m  0.0336\n",
            "     33        \u001b[36m2.0194\u001b[0m  0.0326\n",
            "     34        \u001b[36m1.9541\u001b[0m  0.0335\n",
            "     35        \u001b[36m1.8892\u001b[0m  0.0377\n",
            "     36        \u001b[36m1.8247\u001b[0m  0.0327\n",
            "     37        \u001b[36m1.7607\u001b[0m  0.0326\n",
            "     38        \u001b[36m1.6972\u001b[0m  0.0313\n",
            "     39        \u001b[36m1.6344\u001b[0m  0.0388\n",
            "     40        \u001b[36m1.5724\u001b[0m  0.0316\n",
            "     41        \u001b[36m1.5113\u001b[0m  0.0285\n",
            "     42        \u001b[36m1.4512\u001b[0m  0.0341\n",
            "     43        \u001b[36m1.3924\u001b[0m  0.0333\n",
            "     44        \u001b[36m1.3349\u001b[0m  0.0327\n",
            "     45        \u001b[36m1.2790\u001b[0m  0.0428\n",
            "     46        \u001b[36m1.2249\u001b[0m  0.0330\n",
            "     47        \u001b[36m1.1729\u001b[0m  0.0335\n",
            "     48        \u001b[36m1.1231\u001b[0m  0.0342\n",
            "     49        \u001b[36m1.0757\u001b[0m  0.0336\n",
            "     50        \u001b[36m1.0309\u001b[0m  0.0346\n",
            "     51        \u001b[36m0.9890\u001b[0m  0.0316\n",
            "     52        \u001b[36m0.9500\u001b[0m  0.0434\n",
            "     53        \u001b[36m0.9141\u001b[0m  0.0318\n",
            "     54        \u001b[36m0.8813\u001b[0m  0.0293\n",
            "     55        \u001b[36m0.8516\u001b[0m  0.0346\n",
            "     56        \u001b[36m0.8250\u001b[0m  0.0342\n",
            "     57        \u001b[36m0.8013\u001b[0m  0.0326\n",
            "     58        \u001b[36m0.7805\u001b[0m  0.0319\n",
            "     59        \u001b[36m0.7623\u001b[0m  0.0313\n",
            "     60        \u001b[36m0.7465\u001b[0m  0.0313\n",
            "     61        \u001b[36m0.7329\u001b[0m  0.0358\n",
            "     62        \u001b[36m0.7213\u001b[0m  0.0346\n",
            "     63        \u001b[36m0.7114\u001b[0m  0.0328\n",
            "     64        \u001b[36m0.7031\u001b[0m  0.0322\n",
            "     65        \u001b[36m0.6961\u001b[0m  0.0383\n",
            "     66        \u001b[36m0.6902\u001b[0m  0.0328\n",
            "     67        \u001b[36m0.6853\u001b[0m  0.0349\n",
            "     68        \u001b[36m0.6813\u001b[0m  0.0363\n",
            "     69        \u001b[36m0.6779\u001b[0m  0.0325\n",
            "     70        \u001b[36m0.6751\u001b[0m  0.0385\n",
            "     71        \u001b[36m0.6727\u001b[0m  0.0370\n",
            "     72        \u001b[36m0.6708\u001b[0m  0.0350\n",
            "     73        \u001b[36m0.6692\u001b[0m  0.0338\n",
            "     74        \u001b[36m0.6679\u001b[0m  0.0332\n",
            "     75        \u001b[36m0.6668\u001b[0m  0.0350\n",
            "     76        \u001b[36m0.6659\u001b[0m  0.0324\n",
            "     77        \u001b[36m0.6651\u001b[0m  0.0313\n",
            "     78        \u001b[36m0.6645\u001b[0m  0.0329\n",
            "     79        \u001b[36m0.6640\u001b[0m  0.0350\n",
            "     80        \u001b[36m0.6635\u001b[0m  0.0461\n",
            "     81        \u001b[36m0.6632\u001b[0m  0.0325\n",
            "     82        \u001b[36m0.6629\u001b[0m  0.0350\n",
            "     83        \u001b[36m0.6626\u001b[0m  0.0333\n",
            "     84        \u001b[36m0.6624\u001b[0m  0.0326\n",
            "     85        \u001b[36m0.6622\u001b[0m  0.0351\n",
            "     86        \u001b[36m0.6620\u001b[0m  0.0340\n",
            "     87        \u001b[36m0.6619\u001b[0m  0.0333\n",
            "     88        \u001b[36m0.6618\u001b[0m  0.0329\n",
            "     89        \u001b[36m0.6617\u001b[0m  0.0326\n",
            "     90        \u001b[36m0.6616\u001b[0m  0.0381\n",
            "     91        \u001b[36m0.6615\u001b[0m  0.0346\n",
            "     92        \u001b[36m0.6615\u001b[0m  0.0333\n",
            "     93        \u001b[36m0.6614\u001b[0m  0.0342\n",
            "     94        \u001b[36m0.6614\u001b[0m  0.0321\n",
            "     95        \u001b[36m0.6613\u001b[0m  0.0343\n",
            "     96        \u001b[36m0.6613\u001b[0m  0.0339\n",
            "     97        \u001b[36m0.6613\u001b[0m  0.0318\n",
            "     98        \u001b[36m0.6613\u001b[0m  0.0317\n",
            "     99        \u001b[36m0.6612\u001b[0m  0.0323\n",
            "    100        \u001b[36m0.6612\u001b[0m  0.0320\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m87816.7606\u001b[0m  0.0814\n",
            "      2    \u001b[36m67578.9301\u001b[0m  0.0762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: nn.init.uniform is now deprecated in favor of nn.init.uniform_.\n",
            "  if sys.path[0] == '':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      3    \u001b[36m51267.8874\u001b[0m  0.0809\n",
            "      4    \u001b[36m38467.3813\u001b[0m  0.0842\n",
            "      5    \u001b[36m28422.5022\u001b[0m  0.0783\n",
            "      6    \u001b[36m20474.0240\u001b[0m  0.0757\n",
            "      7    \u001b[36m14073.4598\u001b[0m  0.0788\n",
            "      8     \u001b[36m8759.0278\u001b[0m  0.0746\n",
            "      9     \u001b[36m4118.9133\u001b[0m  0.0746\n",
            "     10      \u001b[36m574.8676\u001b[0m  0.0778\n",
            "     11      \u001b[36m151.9111\u001b[0m  0.0744\n",
            "     12      \u001b[36m122.1277\u001b[0m  0.0743\n",
            "     13      \u001b[36m103.8000\u001b[0m  0.0787\n",
            "     14       \u001b[36m87.6229\u001b[0m  0.0735\n",
            "     15       \u001b[36m72.9789\u001b[0m  0.0765\n",
            "     16       \u001b[36m64.6352\u001b[0m  0.0769\n",
            "     17       \u001b[36m63.1611\u001b[0m  0.0811\n",
            "     18       \u001b[36m58.8906\u001b[0m  0.0755\n",
            "     19       \u001b[36m57.9270\u001b[0m  0.0757\n",
            "     20       \u001b[36m53.4348\u001b[0m  0.0775\n",
            "     21       \u001b[36m51.8312\u001b[0m  0.0776\n",
            "     22       \u001b[36m46.2688\u001b[0m  0.0838\n",
            "     23       \u001b[36m45.3725\u001b[0m  0.0748\n",
            "     24       \u001b[36m43.1940\u001b[0m  0.0785\n",
            "     25       47.5450  0.0747\n",
            "     26       54.5306  0.0767\n",
            "     27       52.1836  0.0763\n",
            "     28       45.6434  0.0729\n",
            "     29       \u001b[36m41.6177\u001b[0m  0.0937\n",
            "     30       \u001b[36m40.6210\u001b[0m  0.0758\n",
            "     31       48.2035  0.0798\n",
            "     32       52.3442  0.0839\n",
            "     33       48.4407  0.0774\n",
            "     34       47.7643  0.0772\n",
            "     35       49.8704  0.0782\n",
            "     36       52.0167  0.0836\n",
            "     37       43.9652  0.0777\n",
            "     38       51.4387  0.0777\n",
            "     39       41.7567  0.0896\n",
            "     40       41.2983  0.0762\n",
            "     41       47.0731  0.0898\n",
            "     42       \u001b[36m40.3144\u001b[0m  0.0905\n",
            "     43       42.8758  0.0789\n",
            "     44       51.1070  0.0814\n",
            "     45       \u001b[36m39.4810\u001b[0m  0.0747\n",
            "     46       42.2395  0.0783\n",
            "     47       \u001b[36m36.9766\u001b[0m  0.0771\n",
            "     48       46.1296  0.0757\n",
            "     49       \u001b[36m30.5994\u001b[0m  0.0854\n",
            "     50       42.8543  0.0837\n",
            "     51       38.6580  0.0786\n",
            "     52       \u001b[36m29.0059\u001b[0m  0.0768\n",
            "     53       29.3412  0.0803\n",
            "     54       30.8531  0.0871\n",
            "     55       \u001b[36m26.7245\u001b[0m  0.0771\n",
            "     56       \u001b[36m25.1301\u001b[0m  0.0762\n",
            "     57       \u001b[36m22.9965\u001b[0m  0.0806\n",
            "     58       27.1149  0.0789\n",
            "     59       29.3829  0.0761\n",
            "     60       32.3477  0.0778\n",
            "     61       34.7295  0.0758\n",
            "     62       39.1576  0.0802\n",
            "     63       35.8420  0.0750\n",
            "     64       26.4102  0.0743\n",
            "     65       25.7139  0.0817\n",
            "     66       35.3246  0.0874\n",
            "     67       27.1673  0.0757\n",
            "     68       25.2916  0.0735\n",
            "     69       32.5697  0.0732\n",
            "     70       25.3505  0.0835\n",
            "     71       23.7772  0.0912\n",
            "     72       \u001b[36m22.9062\u001b[0m  0.0809\n",
            "     73       \u001b[36m22.6718\u001b[0m  0.0775\n",
            "     74       \u001b[36m22.3638\u001b[0m  0.0785\n",
            "     75       22.8495  0.0815\n",
            "     76       24.4581  0.0772\n",
            "     77       22.8450  0.0758\n",
            "     78       24.7138  0.0781\n",
            "     79       \u001b[36m19.9416\u001b[0m  0.0902\n",
            "     80       22.0937  0.0781\n",
            "     81       23.9997  0.0802\n",
            "     82       20.8232  0.0759\n",
            "     83       \u001b[36m18.7978\u001b[0m  0.0771\n",
            "     84       24.9816  0.0764\n",
            "     85       19.2224  0.0765\n",
            "     86       23.6620  0.0897\n",
            "     87       24.9598  0.0775\n",
            "     88       25.1254  0.0761\n",
            "     89       25.5655  0.0776\n",
            "     90       23.0330  0.0782\n",
            "     91       24.3746  0.0764\n",
            "     92       22.1508  0.0861\n",
            "     93       \u001b[36m16.6847\u001b[0m  0.0773\n",
            "     94       \u001b[36m16.6700\u001b[0m  0.0827\n",
            "     95       19.3489  0.0806\n",
            "     96       \u001b[36m16.0795\u001b[0m  0.0772\n",
            "     97       19.6409  0.0837\n",
            "     98       \u001b[36m13.4917\u001b[0m  0.0763\n",
            "     99       17.3836  0.0788\n",
            "    100       15.5619  0.0750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "melhores_parametros = grid_search.best_params_\n",
        "melhor_precisao = grid_search.best_score_"
      ],
      "metadata": {
        "id": "iIWqvdMQtAdW"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "melhor_precisao, melhores_parametros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbwOsgoZtCzf",
        "outputId": "1316991b-0ed3-41d9-d28b-91b572216205"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8295218680504077,\n",
              " {'batch_size': 10,\n",
              "  'criterion': torch.nn.modules.loss.BCEWithLogitsLoss,\n",
              "  'max_epochs': 100,\n",
              "  'module__activation': <function torch.nn.functional.relu>,\n",
              "  'module__initializer': <function torch.nn.init._make_deprecate.<locals>.deprecated_init>,\n",
              "  'module__neurons': 16,\n",
              "  'optimizer': torch.optim.adam.Adam})"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Classificação binária: Cancer de mama.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}