{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classificação binária: Cancer de mama.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvaditya/intro_ds_and_ml/blob/main/Classifica%C3%A7%C3%A3o_bin%C3%A1ria_Cancer_de_mama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rD_RSER5Lkb5"
      },
      "source": [
        "# Projeto 1: Classificação binária: Câncer de mama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tP2BcEILoLB"
      },
      "source": [
        "## Etapa 1: Importação das bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1WlABbCcw2B"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b85d_o8BdFub"
      },
      "source": [
        "# !pip install torch==1.4.0\n",
        "\n",
        "import torch\n",
        "torch.__version__\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVO3Mj3qdjru"
      },
      "source": [
        "import torch.nn as nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0SD4dJ4MDMN"
      },
      "source": [
        "## Etapa 2: Base de dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i81g-4ADedrN"
      },
      "source": [
        "np.random.seed(123)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjbIvUYwfBH8"
      },
      "source": [
        "previsores = pd.read_csv('/content/entradas_breast.csv')\n",
        "classe = pd.read_csv('/content/saidas_breast.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFDDZfZTfOq5"
      },
      "source": [
        "previsores.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqiQvr3HfUc4"
      },
      "source": [
        "previsores.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKqSDj3bfdQB"
      },
      "source": [
        "classe.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jSqJh18fhL1"
      },
      "source": [
        "np.unique(classe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aKLO9jX0fs-3"
      },
      "source": [
        " sns.countplot(classe['0']);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UX9ZDhUMgBsv"
      },
      "source": [
        "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores,\n",
        "                                                                                              classe,\n",
        "                                                                                              test_size = 0.25)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SEVQyX9gR4O"
      },
      "source": [
        "previsores_treinamento.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA6wrOMygUmg"
      },
      "source": [
        "classe_treinamento.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKyN_plmgZzH"
      },
      "source": [
        "previsores_teste.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN_AXcfggdWC"
      },
      "source": [
        "classe_teste.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72uvlxJrOuWd"
      },
      "source": [
        "## Etapa 3: Transformação dos dados para tensores\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk5Gjgb7hBCo"
      },
      "source": [
        "type(previsores_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aIzWASyMhMmy"
      },
      "source": [
        "type(np.array(previsores_treinamento))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqPER9AYhTpt"
      },
      "source": [
        "previsores_treinamento = torch.tensor(np.array(previsores_treinamento), dtype=torch.float)\n",
        "classe_treinamento = torch.tensor(np.array(classe_treinamento), dtype = torch.float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-2HrvEJh5Km"
      },
      "source": [
        "\n",
        "type(previsores_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqL8ypLSh79u"
      },
      "source": [
        "\n",
        "type(classe_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__6a-iZhiJVI"
      },
      "source": [
        "dataset = torch.utils.data.TensorDataset(previsores_treinamento, classe_treinamento)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0sP_kvViZJl"
      },
      "source": [
        "type(dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dIWzA4wihKD"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGDLesyDQpIb"
      },
      "source": [
        "## Etapa 4: Construção do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FAFgY56jmdG"
      },
      "source": [
        " # 30 -> 16 -> 16 -> 1\n",
        "# (entradas + saida) / 2 = (30 + 1) / 2 = 16\n",
        "classificador = nn.Sequential(\n",
        "    nn.Linear(in_features=30, out_features=16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 16),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(16, 1),\n",
        "    nn.Sigmoid()\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixwI_mhZlDVW"
      },
      "source": [
        "classificador.parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--bNcvlplMh9"
      },
      "source": [
        "criterion = nn.BCELoss() #Binary Cross Entropy Loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um6Tr3s_lXHK"
      },
      "source": [
        "optimizer = torch.optim.Adam(classificador.parameters(), lr=0.001, weight_decay=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "appMwDHtRTN5"
      },
      "source": [
        "## Etapa 5: Treinamento do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exieZFSam_eI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e92f6e1-856b-4034-9542-ecbaba11d2e2"
      },
      "source": [
        "for epoch in range(100):\n",
        "  running_loss = 0.\n",
        "\n",
        "  for data in train_loader:\n",
        "    inputs, labels = data\n",
        "    #print(inputs)\n",
        "    #print('-----')\n",
        "    #print(labels)\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = classificador(inputs) # classificador.forward(inputs)\n",
        "    #print(outputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  print('Época %3d: perda %.5f' % (epoch+1, running_loss/len(train_loader)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época   1: perda 5.44077\n",
            "Época   2: perda 1.61572\n",
            "Época   3: perda 1.27111\n",
            "Época   4: perda 1.22527\n",
            "Época   5: perda 1.19481\n",
            "Época   6: perda 1.16310\n",
            "Época   7: perda 1.16480\n",
            "Época   8: perda 1.15068\n",
            "Época   9: perda 1.12336\n",
            "Época  10: perda 1.12424\n",
            "Época  11: perda 1.08099\n",
            "Época  12: perda 1.09893\n",
            "Época  13: perda 1.07530\n",
            "Época  14: perda 1.08443\n",
            "Época  15: perda 1.13997\n",
            "Época  16: perda 1.07494\n",
            "Época  17: perda 1.08882\n",
            "Época  18: perda 1.04306\n",
            "Época  19: perda 1.07964\n",
            "Época  20: perda 1.04321\n",
            "Época  21: perda 1.06220\n",
            "Época  22: perda 1.11282\n",
            "Época  23: perda 1.06123\n",
            "Época  24: perda 1.00314\n",
            "Época  25: perda 1.05587\n",
            "Época  26: perda 1.00042\n",
            "Época  27: perda 1.01152\n",
            "Época  28: perda 1.00167\n",
            "Época  29: perda 1.00211\n",
            "Época  30: perda 0.98924\n",
            "Época  31: perda 1.02455\n",
            "Época  32: perda 0.98739\n",
            "Época  33: perda 1.00291\n",
            "Época  34: perda 1.00912\n",
            "Época  35: perda 1.03670\n",
            "Época  36: perda 1.06181\n",
            "Época  37: perda 1.08788\n",
            "Época  38: perda 0.98346\n",
            "Época  39: perda 1.01909\n",
            "Época  40: perda 1.02930\n",
            "Época  41: perda 0.99214\n",
            "Época  42: perda 1.02454\n",
            "Época  43: perda 0.98409\n",
            "Época  44: perda 1.02321\n",
            "Época  45: perda 0.98676\n",
            "Época  46: perda 1.02535\n",
            "Época  47: perda 0.97214\n",
            "Época  48: perda 0.99493\n",
            "Época  49: perda 1.03030\n",
            "Época  50: perda 1.02446\n",
            "Época  51: perda 0.97262\n",
            "Época  52: perda 0.98041\n",
            "Época  53: perda 0.96995\n",
            "Época  54: perda 0.95605\n",
            "Época  55: perda 1.00890\n",
            "Época  56: perda 0.96134\n",
            "Época  57: perda 1.02496\n",
            "Época  58: perda 0.98191\n",
            "Época  59: perda 0.96819\n",
            "Época  60: perda 0.98534\n",
            "Época  61: perda 0.97077\n",
            "Época  62: perda 0.97297\n",
            "Época  63: perda 0.99980\n",
            "Época  64: perda 0.97281\n",
            "Época  65: perda 0.96358\n",
            "Época  66: perda 0.98027\n",
            "Época  67: perda 0.98177\n",
            "Época  68: perda 0.96845\n",
            "Época  69: perda 0.95040\n",
            "Época  70: perda 0.95823\n",
            "Época  71: perda 0.96146\n",
            "Época  72: perda 0.94500\n",
            "Época  73: perda 1.05587\n",
            "Época  74: perda 1.03093\n",
            "Época  75: perda 0.99874\n",
            "Época  76: perda 0.93754\n",
            "Época  77: perda 0.94369\n",
            "Época  78: perda 0.95009\n",
            "Época  79: perda 0.99155\n",
            "Época  80: perda 0.96510\n",
            "Época  81: perda 0.94045\n",
            "Época  82: perda 0.93991\n",
            "Época  83: perda 0.95029\n",
            "Época  84: perda 0.99571\n",
            "Época  85: perda 0.97533\n",
            "Época  86: perda 0.94219\n",
            "Época  87: perda 0.92881\n",
            "Época  88: perda 1.00922\n",
            "Época  89: perda 0.95272\n",
            "Época  90: perda 1.01459\n",
            "Época  91: perda 0.97182\n",
            "Época  92: perda 0.97541\n",
            "Época  93: perda 0.96125\n",
            "Época  94: perda 0.92195\n",
            "Época  95: perda 0.91932\n",
            "Época  96: perda 0.93613\n",
            "Época  97: perda 0.93785\n",
            "Época  98: perda 0.95891\n",
            "Época  99: perda 0.92925\n",
            "Época 100: perda 0.93390\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITUtUdQNSJcs"
      },
      "source": [
        "## Etapa 6: Visualização dos pesos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0E2vbaGreGc"
      },
      "source": [
        "# 30 -> 16 -> 16 -> 1\n",
        "params = list(classificador.parameters())"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2sFTNaMroyw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5ce273-1888-439c-b9be-ace4a922a902"
      },
      "source": [
        "params"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[-6.1117e-02,  1.0842e-02, -8.3451e-02,  7.3670e-02, -1.4103e-04,\n",
              "           7.1735e-03,  1.6724e-04,  3.0778e-04, -1.4554e-01,  2.3041e-05,\n",
              "           7.6860e-04,  5.7891e-02, -1.7100e-01, -1.1286e-01, -1.7372e-05,\n",
              "           9.2535e-05, -1.3769e-01,  2.1168e-05,  3.4194e-05, -4.3480e-06,\n",
              "           1.1655e-01,  2.8734e-02,  4.9158e-02,  1.6877e-01, -1.0013e-01,\n",
              "           3.5644e-02, -7.7274e-02,  1.0043e-01,  1.7117e-01, -1.2664e-01],\n",
              "         [ 1.8897e-01,  7.7857e-02,  2.9895e-01,  1.2622e-01, -3.7438e-02,\n",
              "          -4.1179e-02, -1.1583e-01, -1.0469e-01,  5.9242e-03,  5.7507e-02,\n",
              "           2.8247e-02, -5.9924e-02, -3.0952e-02,  1.7770e-01, -1.7899e-02,\n",
              "          -5.7413e-02,  2.0035e-01,  7.5741e-02,  3.3918e-01, -1.7641e-02,\n",
              "           2.1964e-01, -5.0753e-02,  2.0365e-01,  3.5049e-02,  2.8228e-02,\n",
              "          -1.8649e-01, -2.7290e-01,  1.7580e-01, -9.5777e-02, -2.6468e-01],\n",
              "         [-2.8255e-02, -2.5968e-02, -2.4523e-02, -2.3394e-02,  2.4482e-03,\n",
              "          -4.8319e-04, -1.8941e-03,  2.1316e-03, -1.3097e-04,  1.4958e-03,\n",
              "           7.3734e-03, -2.6369e-02, -2.5330e-02, -2.6464e-02, -1.4177e-03,\n",
              "           2.7950e-03, -1.5246e-04,  1.3429e-03, -1.3577e-04, -4.9527e-04,\n",
              "          -2.3301e-02, -2.4500e-02, -2.3781e-02, -2.3277e-02, -1.7480e-02,\n",
              "           3.4714e-02,  3.2937e-02,  1.5634e-03,  3.2617e-02, -1.8531e-02],\n",
              "         [-3.5007e-01,  1.0356e-01, -1.3461e-01,  9.4999e-02, -1.9671e-01,\n",
              "           6.2271e-02,  1.9657e-02, -1.3986e-02,  1.1099e-01, -3.6377e-02,\n",
              "           2.1830e-01, -1.3211e-01,  2.7908e-02,  9.1549e-02,  2.9723e-03,\n",
              "          -1.2548e-02, -7.2375e-03,  2.1100e-02,  6.3447e-02,  3.5184e-03,\n",
              "          -4.0549e-02, -8.0352e-02, -5.9510e-02,  2.2532e-02,  2.6134e-01,\n",
              "           7.7460e-02, -4.7854e-02,  1.8829e-01,  1.9418e-01,  4.0774e-01],\n",
              "         [-3.4560e-01,  7.7917e-02, -6.3553e-02, -1.3400e-01,  3.3122e-01,\n",
              "          -1.8090e-01,  1.2678e-01, -2.7901e-01, -2.3038e-01, -7.3321e-02,\n",
              "          -1.8792e-01, -1.5462e-03, -1.4905e-02,  7.8304e-02,  5.0085e-02,\n",
              "           9.4938e-02, -3.7280e-01,  5.6978e-02,  4.7704e-03,  4.0943e-01,\n",
              "          -2.1639e-01,  8.9116e-02, -1.1235e-01,  2.3176e-01,  4.8081e-02,\n",
              "          -1.5867e-01, -3.2638e-01, -1.9592e-01, -4.9159e-02,  3.7691e-01],\n",
              "         [-1.1617e-01, -9.1403e-02, -2.9783e-02,  7.2366e-02,  1.2037e-01,\n",
              "           1.2980e-01, -1.0221e-01,  1.3095e-02, -1.3498e-01, -7.1122e-05,\n",
              "           7.4419e-02,  1.3404e-01, -1.6914e-01,  1.5406e-01,  3.0584e-09,\n",
              "           7.3328e-03,  1.6990e-03,  1.6955e-07,  2.2379e-07,  9.5001e-04,\n",
              "          -3.3460e-02, -1.7988e-01, -4.7633e-02, -1.7645e-02, -2.9845e-01,\n",
              "          -1.2120e-01, -1.3647e-01, -3.9125e-02,  1.5226e-01,  1.5297e-03],\n",
              "         [-7.8812e-03, -6.3424e-03,  2.8318e-01, -1.3066e-01, -2.4095e-01,\n",
              "          -5.3265e-01, -7.1974e-02, -4.5040e-03,  2.9709e-01,  1.3646e-02,\n",
              "          -1.1110e-01, -1.5640e-01,  6.7282e-02,  1.3252e-01, -7.4042e-03,\n",
              "          -4.6722e-02,  1.9326e-02, -1.9092e-02,  7.3720e-02, -1.0220e-02,\n",
              "           7.5011e-02, -9.0724e-02,  1.8415e-01, -1.1314e-01, -1.6337e-01,\n",
              "           1.0716e-01,  4.8611e-02, -1.1310e-01, -2.6003e-01,  4.4905e-02],\n",
              "         [-2.9686e-01, -1.7839e-02, -1.4116e-01, -1.6119e-01,  1.9216e-01,\n",
              "           5.4151e-02, -6.1056e-02, -7.5336e-02,  1.2207e-01, -7.2008e-02,\n",
              "          -8.5362e-02, -1.1952e-01,  6.7643e-02,  1.1802e-01,  6.6079e-03,\n",
              "          -2.9255e-02, -1.1479e-01,  1.9956e-02, -1.7802e-01,  1.2538e-02,\n",
              "          -2.2258e-01,  5.7546e-02, -3.0261e-01,  9.8937e-02, -7.6473e-02,\n",
              "          -2.6562e-01,  8.6843e-02,  3.0431e-01, -6.2695e-02,  2.1690e-01],\n",
              "         [ 6.1605e-02, -5.9079e-02, -3.8952e-01, -6.7606e-02,  2.6187e-01,\n",
              "           1.6636e-01, -2.0350e-01, -2.0303e-01,  3.3982e-02, -6.1955e-02,\n",
              "           1.6503e-01, -1.0037e-01,  1.2897e-01,  4.2866e-03,  1.6012e-02,\n",
              "           5.9546e-02, -2.1549e-01, -1.8543e-01, -4.5341e-02,  2.2461e-01,\n",
              "          -3.6722e-01,  9.2318e-02, -2.9894e-01,  1.8776e-01,  1.9600e-01,\n",
              "           1.6674e-01, -9.9580e-02,  1.3251e-01,  8.8997e-02,  3.1036e-01],\n",
              "         [ 1.7134e-01,  1.0572e-01,  2.8693e-01, -4.9453e-03, -2.1261e-01,\n",
              "          -1.6251e-01,  1.0088e-02,  5.8671e-03, -1.3221e-02,  7.5274e-02,\n",
              "           7.5029e-02, -1.5702e-01,  1.5983e-01, -2.8192e-01, -3.2379e-02,\n",
              "           4.0865e-02,  2.1002e-01,  1.3027e-01,  5.8020e-02, -2.5497e-01,\n",
              "           3.3722e-01, -1.5185e-01,  3.2223e-01, -7.4689e-02,  2.3650e-02,\n",
              "          -2.0022e-02,  1.1848e-01, -1.5373e-01,  1.0951e-01, -1.5741e-01],\n",
              "         [-8.2718e-03,  4.1607e-02,  6.4443e-02,  5.4138e-02, -4.9270e-02,\n",
              "          -2.9665e-01, -1.8867e-01, -5.1212e-02,  1.5226e-01, -2.9940e-02,\n",
              "          -1.7448e-01,  4.0022e-02, -1.2509e-01,  1.8367e-01,  6.7385e-04,\n",
              "           2.1829e-03, -4.5242e-01, -3.1298e-01, -2.3868e-01,  1.0288e-03,\n",
              "          -1.9454e-01, -1.3282e-02,  6.3465e-02,  1.5346e-01,  3.7478e-01,\n",
              "           7.5623e-02,  2.2116e-01,  1.9567e-01,  1.2747e-02, -2.0426e-02],\n",
              "         [ 7.0662e-02, -9.6149e-02,  5.7909e-02,  1.8444e-01, -5.0453e-02,\n",
              "           1.1710e-01, -3.4662e-01,  4.3276e-01,  4.1629e-01,  1.6745e-02,\n",
              "           2.5265e-01,  1.1513e-01, -7.8689e-02, -1.4062e-01, -4.8688e-03,\n",
              "          -6.3511e-02,  4.4817e-01, -9.7024e-04,  2.1183e-02, -3.4887e-01,\n",
              "           2.9694e-01, -1.6517e-01,  2.3874e-01, -9.7119e-02, -3.0152e-01,\n",
              "           1.2019e-01, -2.3423e-01,  2.9113e-01,  3.3242e-02, -3.4020e-01],\n",
              "         [ 1.2265e-01,  1.2050e-01, -3.1586e-01, -8.4607e-02,  1.1211e-01,\n",
              "           1.5486e-01,  5.2496e-02,  2.2316e-01,  3.2415e-03, -4.3936e-02,\n",
              "           1.3696e-01, -7.4783e-02,  1.0401e-01,  1.0594e-01,  1.4221e-02,\n",
              "           1.8222e-02,  2.4149e-02, -3.4924e-02, -3.0146e-01, -6.3208e-02,\n",
              "          -8.2659e-02,  1.6938e-01, -1.0076e-01,  3.9480e-03, -2.3605e-01,\n",
              "           2.2387e-01, -1.6040e-01, -9.6170e-02,  4.2049e-02,  2.1577e-01],\n",
              "         [ 8.5684e-02, -3.1005e-02, -1.0009e-01, -2.5426e-02,  4.2305e-02,\n",
              "          -5.5419e-19,  2.9636e-28, -3.9633e-35, -1.2516e-01,  4.0102e-26,\n",
              "           5.0379e-11, -1.3070e-01, -1.5953e-01,  1.2753e-01,  4.3553e-36,\n",
              "           1.8360e-35, -2.0900e-35, -1.2386e-35, -2.3966e-35, -5.2800e-36,\n",
              "           1.1111e-01,  3.5400e-02, -8.9535e-02,  1.0164e-01, -4.7231e-15,\n",
              "          -5.3488e-06, -2.6505e-08, -6.2261e-20,  6.2961e-03, -2.3534e-19],\n",
              "         [ 7.1803e-02, -1.0759e-02,  5.3611e-02, -1.1222e-01, -1.3782e-01,\n",
              "          -3.9494e-38, -4.9829e-39, -1.2157e-39, -2.5030e-02,  1.1281e-40,\n",
              "          -3.7509e-11, -1.0491e-02, -1.4696e-02, -2.8420e-02, -1.0771e-39,\n",
              "          -1.1276e-41,  5.5390e-37, -4.3762e-39,  4.0523e-39, -4.3471e-39,\n",
              "           6.5666e-02,  9.0172e-02, -8.7505e-02, -1.5268e-01, -1.0103e-18,\n",
              "          -9.4312e-17,  1.7556e-18,  6.0013e-39, -1.1708e-01, -3.5710e-37],\n",
              "         [-6.3566e-03, -1.1047e-02, -1.3348e-02, -1.7164e-02,  2.0152e-39,\n",
              "           8.4186e-03,  2.2319e-03, -4.3227e-39,  6.4507e-39, -2.3148e-40,\n",
              "          -1.6028e-04, -2.8132e-02, -2.1156e-02, -1.7102e-02,  1.4876e-39,\n",
              "           3.9193e-39,  5.6071e-39,  1.0915e-39,  2.9591e-40,  6.0596e-39,\n",
              "          -7.8946e-03, -1.5022e-02, -1.4934e-02, -1.9658e-02, -1.2775e-03,\n",
              "           2.3690e-02, -5.2219e-03,  4.0371e-39,  7.4679e-03, -6.5125e-04]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([-7.7584e-03,  2.2811e-01, -2.0730e-02, -2.1604e-01, -6.2585e-01,\n",
              "         -4.8453e-02,  1.5903e-01, -3.0746e-01, -3.4688e-01,  4.4976e-01,\n",
              "         -2.3427e-01,  2.2919e-01, -3.4935e-01,  1.8631e-03, -1.1080e-04,\n",
              "         -4.9779e-08], requires_grad=True), Parameter containing:\n",
              " tensor([[-1.8237e-07, -1.1404e-02, -3.0073e-12, -3.9417e-39, -9.9247e-02,\n",
              "           6.0009e-03, -1.0645e-02,  5.6236e-39, -1.7061e-01, -1.7651e-01,\n",
              "          -2.1491e-01,  8.6314e-02,  1.7986e-01,  2.3011e-01,  4.0882e-02,\n",
              "           5.2530e-39],\n",
              "         [ 6.2606e-39, -4.7702e-04, -7.0227e-39, -1.4020e-03,  6.8893e-39,\n",
              "          -8.9638e-40,  2.7862e-08,  8.7907e-07, -2.3330e-03, -1.8260e-03,\n",
              "           2.3516e-39,  9.5404e-07, -3.8119e-04, -1.8302e-39,  2.2949e-39,\n",
              "           9.1383e-40],\n",
              "         [ 2.2181e-01, -2.1331e-02,  2.4531e-02,  1.5747e-01,  3.3342e-01,\n",
              "          -6.9276e-02, -6.1502e-02, -8.4797e-02,  2.3590e-01,  6.6615e-02,\n",
              "           3.2933e-02, -1.9160e-02,  2.3869e-01,  8.4256e-02,  7.2392e-02,\n",
              "           2.0148e-02],\n",
              "         [-5.2322e-02,  5.4619e-02, -2.4662e-02, -2.0935e-01, -8.4996e-03,\n",
              "          -7.9453e-04,  4.8212e-02, -5.7711e-02,  1.9846e-01,  6.8425e-02,\n",
              "          -3.2029e-01,  3.0661e-01,  1.4681e-01,  1.4104e-01,  8.5872e-02,\n",
              "          -1.9566e-02],\n",
              "         [ 3.3661e-03,  1.9389e-01,  3.1462e-02, -2.8318e-01, -1.2021e-02,\n",
              "          -8.7659e-02,  1.0481e-01,  1.4057e-01,  3.2397e-02,  2.2399e-02,\n",
              "          -3.1126e-01,  1.5157e-01, -1.1652e-01, -6.9308e-02, -8.6296e-02,\n",
              "          -5.3418e-39],\n",
              "         [ 3.9200e-40, -2.3727e-11,  2.2241e-39,  1.3998e-39, -1.1265e-03,\n",
              "          -2.2955e-39, -1.0533e-39,  1.0492e-39, -1.1352e-02, -2.6913e-05,\n",
              "          -4.1430e-05,  1.6080e-03, -7.8057e-03, -7.8953e-17,  1.5756e-16,\n",
              "          -2.5461e-39],\n",
              "         [-1.4715e-01, -4.3397e-02,  1.4057e-09, -1.2126e-05,  9.7334e-02,\n",
              "           1.2110e-01,  8.8039e-02, -4.6165e-40, -1.7826e-01, -2.1136e-01,\n",
              "           5.0421e-02,  1.4973e-02,  2.1706e-01,  2.2482e-01,  5.8573e-02,\n",
              "          -1.5712e-39],\n",
              "         [ 3.4670e-02,  8.3163e-02, -2.3499e-02, -7.8767e-02, -3.4875e-01,\n",
              "           1.7584e-01,  4.5660e-04, -2.5159e-01, -4.4850e-02,  1.9133e-01,\n",
              "          -2.7526e-02,  2.0928e-01, -6.2716e-03, -2.1660e-01,  1.5951e-39,\n",
              "          -1.9117e-02],\n",
              "         [-8.0707e-02,  1.8833e-01, -1.0550e-08, -5.9227e-02,  1.5987e-01,\n",
              "           1.7315e-01,  9.9038e-02,  9.2946e-02, -1.1097e-01, -1.8412e-01,\n",
              "           1.1603e-01, -1.8657e-02, -7.0245e-02,  2.0816e-01, -1.2872e-01,\n",
              "           6.4984e-39],\n",
              "         [ 1.9869e-01,  1.1039e-01, -2.7324e-02,  9.0940e-02, -7.9768e-02,\n",
              "           9.1140e-02,  2.0868e-01, -2.1327e-01, -1.1228e-01,  2.0006e-01,\n",
              "          -3.0044e-01, -1.8968e-01, -1.0029e-01, -4.4450e-02,  8.8265e-03,\n",
              "           1.6350e-02],\n",
              "         [ 1.3132e-01, -9.1782e-02,  4.5135e-02, -3.9492e-01, -3.5286e-01,\n",
              "          -1.4847e-02,  1.6778e-02, -1.1367e-03,  1.5375e-03, -5.9879e-02,\n",
              "           2.4164e-01,  8.0978e-02,  2.1008e-01,  1.6164e-01,  1.5519e-02,\n",
              "          -1.3601e-02],\n",
              "         [ 1.0329e-01,  2.2491e-01, -1.3710e-06,  1.5235e-04,  3.9124e-02,\n",
              "           2.5300e-01, -2.0028e-39, -6.1932e-39, -1.9067e-01, -7.6081e-02,\n",
              "          -8.9933e-02,  2.5203e-01, -3.8382e-03, -1.2633e-02,  7.0436e-04,\n",
              "          -6.8538e-39],\n",
              "         [-1.2840e-01, -6.6123e-02,  2.4731e-02, -1.4740e-01, -1.2012e-01,\n",
              "          -1.6234e-01,  4.5299e-02,  3.9070e-02,  1.8290e-01, -4.0705e-02,\n",
              "           2.5014e-01,  1.2433e-01,  7.0396e-02, -1.4669e-01, -3.5378e-03,\n",
              "           1.9040e-02],\n",
              "         [-5.8377e-02,  2.3290e-01,  4.2282e-02,  9.8555e-03, -4.8022e-02,\n",
              "           1.0769e-01, -2.0151e-01, -2.0892e-01, -1.2394e-01,  3.9474e-02,\n",
              "           3.2583e-02,  1.5846e-01, -5.6787e-02,  1.4422e-02, -8.4986e-02,\n",
              "           1.5114e-02],\n",
              "         [ 9.6666e-02,  2.3843e-01,  2.1832e-03,  5.2001e-02,  6.3911e-03,\n",
              "          -2.2020e-02, -1.5243e-01, -1.4253e-01, -1.3117e-01, -6.4708e-04,\n",
              "           1.9821e-01,  1.3001e-02, -8.4522e-02, -2.3048e-01,  8.8382e-02,\n",
              "          -1.8276e-39],\n",
              "         [ 7.4943e-12, -1.3363e-02,  8.2786e-40, -1.7066e-02, -1.1528e-02,\n",
              "          -2.6273e-09, -1.3237e-02, -1.4731e-02, -1.4970e-02, -1.5011e-02,\n",
              "           5.6789e-03,  1.1503e-02, -1.6890e-02,  6.3259e-39, -5.0867e-39,\n",
              "          -2.7407e-39]], requires_grad=True), Parameter containing:\n",
              " tensor([-6.2662e-02, -5.0554e-39, -7.0109e-01,  4.2369e-01,  7.4960e-02,\n",
              "         -4.0462e-39,  7.3580e-02,  7.7551e-01, -2.3583e-01,  5.6782e-01,\n",
              "          1.6926e-01, -3.3939e-02, -5.0169e-01,  2.9505e-01,  7.8148e-02,\n",
              "         -3.5300e-03], requires_grad=True), Parameter containing:\n",
              " tensor([[-0.1179, -0.0049, -0.1032,  0.1272,  0.0157, -0.0010, -0.1867,  0.0924,\n",
              "           0.1652,  0.2353,  0.1177,  0.2062, -0.0550,  0.2246,  0.1572, -0.0121]],\n",
              "        requires_grad=True), Parameter containing:\n",
              " tensor([0.6008], requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaU6bV7lrusK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60124772-3163-4b77-9595-b6265ebbaa15"
      },
      "source": [
        "# 30 -> 16 -> 16 -> 1\n",
        "pesos0 = params[0]\n",
        "pesos0.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRIKPKKgr94O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a630af1-865c-45d4-8e75-ee6a1e4e7cec"
      },
      "source": [
        "print(pesos0)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-6.1117e-02,  1.0842e-02, -8.3451e-02,  7.3670e-02, -1.4103e-04,\n",
            "          7.1735e-03,  1.6724e-04,  3.0778e-04, -1.4554e-01,  2.3041e-05,\n",
            "          7.6860e-04,  5.7891e-02, -1.7100e-01, -1.1286e-01, -1.7372e-05,\n",
            "          9.2535e-05, -1.3769e-01,  2.1168e-05,  3.4194e-05, -4.3480e-06,\n",
            "          1.1655e-01,  2.8734e-02,  4.9158e-02,  1.6877e-01, -1.0013e-01,\n",
            "          3.5644e-02, -7.7274e-02,  1.0043e-01,  1.7117e-01, -1.2664e-01],\n",
            "        [ 1.8897e-01,  7.7857e-02,  2.9895e-01,  1.2622e-01, -3.7438e-02,\n",
            "         -4.1179e-02, -1.1583e-01, -1.0469e-01,  5.9242e-03,  5.7507e-02,\n",
            "          2.8247e-02, -5.9924e-02, -3.0952e-02,  1.7770e-01, -1.7899e-02,\n",
            "         -5.7413e-02,  2.0035e-01,  7.5741e-02,  3.3918e-01, -1.7641e-02,\n",
            "          2.1964e-01, -5.0753e-02,  2.0365e-01,  3.5049e-02,  2.8228e-02,\n",
            "         -1.8649e-01, -2.7290e-01,  1.7580e-01, -9.5777e-02, -2.6468e-01],\n",
            "        [-2.8255e-02, -2.5968e-02, -2.4523e-02, -2.3394e-02,  2.4482e-03,\n",
            "         -4.8319e-04, -1.8941e-03,  2.1316e-03, -1.3097e-04,  1.4958e-03,\n",
            "          7.3734e-03, -2.6369e-02, -2.5330e-02, -2.6464e-02, -1.4177e-03,\n",
            "          2.7950e-03, -1.5246e-04,  1.3429e-03, -1.3577e-04, -4.9527e-04,\n",
            "         -2.3301e-02, -2.4500e-02, -2.3781e-02, -2.3277e-02, -1.7480e-02,\n",
            "          3.4714e-02,  3.2937e-02,  1.5634e-03,  3.2617e-02, -1.8531e-02],\n",
            "        [-3.5007e-01,  1.0356e-01, -1.3461e-01,  9.4999e-02, -1.9671e-01,\n",
            "          6.2271e-02,  1.9657e-02, -1.3986e-02,  1.1099e-01, -3.6377e-02,\n",
            "          2.1830e-01, -1.3211e-01,  2.7908e-02,  9.1549e-02,  2.9723e-03,\n",
            "         -1.2548e-02, -7.2375e-03,  2.1100e-02,  6.3447e-02,  3.5184e-03,\n",
            "         -4.0549e-02, -8.0352e-02, -5.9510e-02,  2.2532e-02,  2.6134e-01,\n",
            "          7.7460e-02, -4.7854e-02,  1.8829e-01,  1.9418e-01,  4.0774e-01],\n",
            "        [-3.4560e-01,  7.7917e-02, -6.3553e-02, -1.3400e-01,  3.3122e-01,\n",
            "         -1.8090e-01,  1.2678e-01, -2.7901e-01, -2.3038e-01, -7.3321e-02,\n",
            "         -1.8792e-01, -1.5462e-03, -1.4905e-02,  7.8304e-02,  5.0085e-02,\n",
            "          9.4938e-02, -3.7280e-01,  5.6978e-02,  4.7704e-03,  4.0943e-01,\n",
            "         -2.1639e-01,  8.9116e-02, -1.1235e-01,  2.3176e-01,  4.8081e-02,\n",
            "         -1.5867e-01, -3.2638e-01, -1.9592e-01, -4.9159e-02,  3.7691e-01],\n",
            "        [-1.1617e-01, -9.1403e-02, -2.9783e-02,  7.2366e-02,  1.2037e-01,\n",
            "          1.2980e-01, -1.0221e-01,  1.3095e-02, -1.3498e-01, -7.1122e-05,\n",
            "          7.4419e-02,  1.3404e-01, -1.6914e-01,  1.5406e-01,  3.0584e-09,\n",
            "          7.3328e-03,  1.6990e-03,  1.6955e-07,  2.2379e-07,  9.5001e-04,\n",
            "         -3.3460e-02, -1.7988e-01, -4.7633e-02, -1.7645e-02, -2.9845e-01,\n",
            "         -1.2120e-01, -1.3647e-01, -3.9125e-02,  1.5226e-01,  1.5297e-03],\n",
            "        [-7.8812e-03, -6.3424e-03,  2.8318e-01, -1.3066e-01, -2.4095e-01,\n",
            "         -5.3265e-01, -7.1974e-02, -4.5040e-03,  2.9709e-01,  1.3646e-02,\n",
            "         -1.1110e-01, -1.5640e-01,  6.7282e-02,  1.3252e-01, -7.4042e-03,\n",
            "         -4.6722e-02,  1.9326e-02, -1.9092e-02,  7.3720e-02, -1.0220e-02,\n",
            "          7.5011e-02, -9.0724e-02,  1.8415e-01, -1.1314e-01, -1.6337e-01,\n",
            "          1.0716e-01,  4.8611e-02, -1.1310e-01, -2.6003e-01,  4.4905e-02],\n",
            "        [-2.9686e-01, -1.7839e-02, -1.4116e-01, -1.6119e-01,  1.9216e-01,\n",
            "          5.4151e-02, -6.1056e-02, -7.5336e-02,  1.2207e-01, -7.2008e-02,\n",
            "         -8.5362e-02, -1.1952e-01,  6.7643e-02,  1.1802e-01,  6.6079e-03,\n",
            "         -2.9255e-02, -1.1479e-01,  1.9956e-02, -1.7802e-01,  1.2538e-02,\n",
            "         -2.2258e-01,  5.7546e-02, -3.0261e-01,  9.8937e-02, -7.6473e-02,\n",
            "         -2.6562e-01,  8.6843e-02,  3.0431e-01, -6.2695e-02,  2.1690e-01],\n",
            "        [ 6.1605e-02, -5.9079e-02, -3.8952e-01, -6.7606e-02,  2.6187e-01,\n",
            "          1.6636e-01, -2.0350e-01, -2.0303e-01,  3.3982e-02, -6.1955e-02,\n",
            "          1.6503e-01, -1.0037e-01,  1.2897e-01,  4.2866e-03,  1.6012e-02,\n",
            "          5.9546e-02, -2.1549e-01, -1.8543e-01, -4.5341e-02,  2.2461e-01,\n",
            "         -3.6722e-01,  9.2318e-02, -2.9894e-01,  1.8776e-01,  1.9600e-01,\n",
            "          1.6674e-01, -9.9580e-02,  1.3251e-01,  8.8997e-02,  3.1036e-01],\n",
            "        [ 1.7134e-01,  1.0572e-01,  2.8693e-01, -4.9453e-03, -2.1261e-01,\n",
            "         -1.6251e-01,  1.0088e-02,  5.8671e-03, -1.3221e-02,  7.5274e-02,\n",
            "          7.5029e-02, -1.5702e-01,  1.5983e-01, -2.8192e-01, -3.2379e-02,\n",
            "          4.0865e-02,  2.1002e-01,  1.3027e-01,  5.8020e-02, -2.5497e-01,\n",
            "          3.3722e-01, -1.5185e-01,  3.2223e-01, -7.4689e-02,  2.3650e-02,\n",
            "         -2.0022e-02,  1.1848e-01, -1.5373e-01,  1.0951e-01, -1.5741e-01],\n",
            "        [-8.2718e-03,  4.1607e-02,  6.4443e-02,  5.4138e-02, -4.9270e-02,\n",
            "         -2.9665e-01, -1.8867e-01, -5.1212e-02,  1.5226e-01, -2.9940e-02,\n",
            "         -1.7448e-01,  4.0022e-02, -1.2509e-01,  1.8367e-01,  6.7385e-04,\n",
            "          2.1829e-03, -4.5242e-01, -3.1298e-01, -2.3868e-01,  1.0288e-03,\n",
            "         -1.9454e-01, -1.3282e-02,  6.3465e-02,  1.5346e-01,  3.7478e-01,\n",
            "          7.5623e-02,  2.2116e-01,  1.9567e-01,  1.2747e-02, -2.0426e-02],\n",
            "        [ 7.0662e-02, -9.6149e-02,  5.7909e-02,  1.8444e-01, -5.0453e-02,\n",
            "          1.1710e-01, -3.4662e-01,  4.3276e-01,  4.1629e-01,  1.6745e-02,\n",
            "          2.5265e-01,  1.1513e-01, -7.8689e-02, -1.4062e-01, -4.8688e-03,\n",
            "         -6.3511e-02,  4.4817e-01, -9.7024e-04,  2.1183e-02, -3.4887e-01,\n",
            "          2.9694e-01, -1.6517e-01,  2.3874e-01, -9.7119e-02, -3.0152e-01,\n",
            "          1.2019e-01, -2.3423e-01,  2.9113e-01,  3.3242e-02, -3.4020e-01],\n",
            "        [ 1.2265e-01,  1.2050e-01, -3.1586e-01, -8.4607e-02,  1.1211e-01,\n",
            "          1.5486e-01,  5.2496e-02,  2.2316e-01,  3.2415e-03, -4.3936e-02,\n",
            "          1.3696e-01, -7.4783e-02,  1.0401e-01,  1.0594e-01,  1.4221e-02,\n",
            "          1.8222e-02,  2.4149e-02, -3.4924e-02, -3.0146e-01, -6.3208e-02,\n",
            "         -8.2659e-02,  1.6938e-01, -1.0076e-01,  3.9480e-03, -2.3605e-01,\n",
            "          2.2387e-01, -1.6040e-01, -9.6170e-02,  4.2049e-02,  2.1577e-01],\n",
            "        [ 8.5684e-02, -3.1005e-02, -1.0009e-01, -2.5426e-02,  4.2305e-02,\n",
            "         -5.5419e-19,  2.9636e-28, -3.9633e-35, -1.2516e-01,  4.0102e-26,\n",
            "          5.0379e-11, -1.3070e-01, -1.5953e-01,  1.2753e-01,  4.3553e-36,\n",
            "          1.8360e-35, -2.0900e-35, -1.2386e-35, -2.3966e-35, -5.2800e-36,\n",
            "          1.1111e-01,  3.5400e-02, -8.9535e-02,  1.0164e-01, -4.7231e-15,\n",
            "         -5.3488e-06, -2.6505e-08, -6.2261e-20,  6.2961e-03, -2.3534e-19],\n",
            "        [ 7.1803e-02, -1.0759e-02,  5.3611e-02, -1.1222e-01, -1.3782e-01,\n",
            "         -3.9494e-38, -4.9829e-39, -1.2157e-39, -2.5030e-02,  1.1281e-40,\n",
            "         -3.7509e-11, -1.0491e-02, -1.4696e-02, -2.8420e-02, -1.0771e-39,\n",
            "         -1.1276e-41,  5.5390e-37, -4.3762e-39,  4.0523e-39, -4.3471e-39,\n",
            "          6.5666e-02,  9.0172e-02, -8.7505e-02, -1.5268e-01, -1.0103e-18,\n",
            "         -9.4312e-17,  1.7556e-18,  6.0013e-39, -1.1708e-01, -3.5710e-37],\n",
            "        [-6.3566e-03, -1.1047e-02, -1.3348e-02, -1.7164e-02,  2.0152e-39,\n",
            "          8.4186e-03,  2.2319e-03, -4.3227e-39,  6.4507e-39, -2.3148e-40,\n",
            "         -1.6028e-04, -2.8132e-02, -2.1156e-02, -1.7102e-02,  1.4876e-39,\n",
            "          3.9193e-39,  5.6071e-39,  1.0915e-39,  2.9591e-40,  6.0596e-39,\n",
            "         -7.8946e-03, -1.5022e-02, -1.4934e-02, -1.9658e-02, -1.2775e-03,\n",
            "          2.3690e-02, -5.2219e-03,  4.0371e-39,  7.4679e-03, -6.5125e-04]],\n",
            "       requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q42zQLHFsIWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69a6e394-1a74-4b5f-f68f-7ba79a04d87d"
      },
      "source": [
        "# 30 -> 16 -> 16 -> 1\n",
        "bias0 = params[1]\n",
        "bias0.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IWG8GFjsTr5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53d4a8f6-c1ad-43ea-d7f3-2e7fd4cd7ff6"
      },
      "source": [
        "pesos1 = params[2]\n",
        "pesos1.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 16])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfgtWyWrsbbY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a458330d-b074-46b8-fae9-39c25367c02b"
      },
      "source": [
        "bias1 = params[3]\n",
        "bias1.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyTjLzELSdQF"
      },
      "source": [
        "## Etapa 7: Avaliação do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZafmlssFs5SG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e92b3a7f-6bee-4d80-e33f-28dbab3e2682"
      },
      "source": [
        "classificador.eval()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=30, out_features=16, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=16, out_features=16, bias=True)\n",
              "  (3): ReLU()\n",
              "  (4): Linear(in_features=16, out_features=1, bias=True)\n",
              "  (5): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C3BgZGGtJvp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0131e97-71d6-4d1c-bbfc-971ab8f05cb8"
      },
      "source": [
        "type(previsores_teste)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuL49MUEtOrh"
      },
      "source": [
        "previsores_teste = torch.tensor(np.array(previsores_teste), dtype=torch.float)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmAqJEHHtZNC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8365ebb-d560-429b-9274-a1dc0f4bd94a"
      },
      "source": [
        "type(previsores_teste)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe8muTxbtc1G"
      },
      "source": [
        "previsoes = classificador.forward(previsores_teste)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn0leHiAtqpx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d815ca-e9af-4794-dd8f-50439a725be5"
      },
      "source": [
        "previsoes"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9.9513e-01],\n",
              "        [1.0000e+00],\n",
              "        [4.7650e-01],\n",
              "        [1.0000e+00],\n",
              "        [4.0390e-05],\n",
              "        [9.5113e-01],\n",
              "        [9.8119e-01],\n",
              "        [9.9999e-01],\n",
              "        [8.3207e-01],\n",
              "        [2.5404e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.7957e-01],\n",
              "        [9.1944e-01],\n",
              "        [9.9232e-01],\n",
              "        [8.8875e-01],\n",
              "        [9.6189e-01],\n",
              "        [9.9218e-01],\n",
              "        [1.0000e+00],\n",
              "        [2.0592e-01],\n",
              "        [9.9921e-01],\n",
              "        [4.1809e-11],\n",
              "        [6.5122e-03],\n",
              "        [9.1510e-01],\n",
              "        [1.0000e+00],\n",
              "        [8.8206e-01],\n",
              "        [7.9449e-04],\n",
              "        [6.4811e-01],\n",
              "        [1.0000e+00],\n",
              "        [2.3643e-05],\n",
              "        [9.9706e-01],\n",
              "        [2.5161e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.5667e-01],\n",
              "        [9.6297e-01],\n",
              "        [5.8473e-01],\n",
              "        [9.9722e-01],\n",
              "        [2.5094e-01],\n",
              "        [9.9916e-01],\n",
              "        [1.0000e+00],\n",
              "        [5.0961e-06],\n",
              "        [3.3133e-03],\n",
              "        [9.9701e-01],\n",
              "        [7.2742e-08],\n",
              "        [5.8812e-01],\n",
              "        [2.4005e-06],\n",
              "        [9.3366e-01],\n",
              "        [6.9857e-04],\n",
              "        [1.0000e+00],\n",
              "        [9.8149e-01],\n",
              "        [4.4403e-04],\n",
              "        [9.9978e-01],\n",
              "        [1.3762e-17],\n",
              "        [9.3789e-01],\n",
              "        [9.8793e-01],\n",
              "        [9.9760e-01],\n",
              "        [8.4814e-01],\n",
              "        [9.9943e-01],\n",
              "        [1.5750e-09],\n",
              "        [1.0591e-05],\n",
              "        [9.9989e-01],\n",
              "        [3.6986e-04],\n",
              "        [9.9671e-01],\n",
              "        [9.9904e-01],\n",
              "        [9.9934e-01],\n",
              "        [9.4318e-01],\n",
              "        [7.5827e-10],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [9.6952e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9489e-01],\n",
              "        [1.4150e-01],\n",
              "        [9.6871e-01],\n",
              "        [8.0670e-05],\n",
              "        [1.0000e+00],\n",
              "        [9.5239e-01],\n",
              "        [2.9639e-12],\n",
              "        [1.0000e+00],\n",
              "        [8.0191e-02],\n",
              "        [9.3528e-01],\n",
              "        [5.4488e-05],\n",
              "        [6.5514e-07],\n",
              "        [9.8841e-01],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [3.4662e-01],\n",
              "        [9.9323e-01],\n",
              "        [3.3371e-04],\n",
              "        [9.1547e-01],\n",
              "        [1.9126e-03],\n",
              "        [9.9887e-01],\n",
              "        [9.9719e-01],\n",
              "        [4.5053e-03],\n",
              "        [9.9598e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9995e-01],\n",
              "        [9.9983e-01],\n",
              "        [3.4394e-03],\n",
              "        [1.0000e+00],\n",
              "        [9.9999e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9550e-01],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [9.9758e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9634e-01],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [7.7080e-01],\n",
              "        [1.2158e-05],\n",
              "        [9.6401e-01],\n",
              "        [1.3240e-04],\n",
              "        [9.9784e-01],\n",
              "        [2.6572e-02],\n",
              "        [9.9761e-01],\n",
              "        [9.9007e-01],\n",
              "        [9.8571e-01],\n",
              "        [9.9189e-01],\n",
              "        [1.0000e+00],\n",
              "        [9.9534e-01],\n",
              "        [8.1624e-09],\n",
              "        [9.9966e-01],\n",
              "        [1.6880e-01],\n",
              "        [2.8131e-01],\n",
              "        [1.0000e+00],\n",
              "        [1.0000e+00],\n",
              "        [1.5789e-11],\n",
              "        [9.9971e-01],\n",
              "        [1.0000e+00],\n",
              "        [1.5496e-02],\n",
              "        [1.0000e+00],\n",
              "        [9.6410e-01],\n",
              "        [9.9404e-01],\n",
              "        [9.9862e-01],\n",
              "        [4.6917e-01],\n",
              "        [1.7570e-04],\n",
              "        [1.9688e-07],\n",
              "        [9.8340e-01],\n",
              "        [2.1562e-14]], grad_fn=<SigmoidBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzALzgDet3Hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8fc7ff1-615d-4d36-fd48-dfa47ab8bbbf"
      },
      "source": [
        "previsoes = np.array(previsoes > 0.5)\n",
        "previsoes"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [ True],\n",
              "       [False],\n",
              "       [False],\n",
              "       [False],\n",
              "       [ True],\n",
              "       [False]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVPFTbGeuSU5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c49b8bf4-81c8-4159-ebf0-2d5c5ddf3661"
      },
      "source": [
        "classe_teste"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8f2ea6e7-35b2-4dc9-93e7-94a8e303dea9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>143 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f2ea6e7-35b2-4dc9-93e7-94a8e303dea9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f2ea6e7-35b2-4dc9-93e7-94a8e303dea9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f2ea6e7-35b2-4dc9-93e7-94a8e303dea9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     0\n",
              "333  1\n",
              "273  1\n",
              "201  0\n",
              "178  1\n",
              "85   0\n",
              "..  ..\n",
              "230  0\n",
              "282  0\n",
              "535  0\n",
              "436  1\n",
              "236  0\n",
              "\n",
              "[143 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7jfnFtZuNVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adf1f6a8-5fd5-47d5-d752-9e3b614ee27a"
      },
      "source": [
        "taxa_acerto = accuracy_score(classe_teste, previsoes)\n",
        "taxa_acerto"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8741258741258742"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0Z3LgbcutQD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dbe2d4a-72e3-4bb5-d487-395b7ba97764"
      },
      "source": [
        "matriz = confusion_matrix(classe_teste, previsoes)\n",
        "matriz"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[40, 14],\n",
              "       [ 4, 85]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlaTftH_uzpv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "92c98f0c-25ee-4dfa-c38e-d63c04a22078"
      },
      "source": [
        "sns.heatmap(matriz, annot=True);"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validação cruzada e Skorch"
      ],
      "metadata": {
        "id": "n7DqJGrxSoS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importar o skorch , que é scikit learn + pytorch\n",
        "!pip install skorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm2yFq0tSIrS",
        "outputId": "02913a99-6471-4b2a-c205-879f67b0d53c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skorch in /usr/local/lib/python3.7/dist-packages (0.11.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from skorch) (0.8.9)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from skorch) (1.0.2)\n",
            "Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.7/dist-packages (from skorch) (4.62.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->skorch) (3.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch import NeuralNetBinaryClassifier\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict"
      ],
      "metadata": {
        "id": "U_LMpyygTe6B"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Criar a estrutura da rede neural"
      ],
      "metadata": {
        "id": "Lv5RXyjwg5iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class classificador_torch(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # 30 -> 16 -> 16 -> 1\n",
        "    self.dense0 = nn.Linear(30, 16)\n",
        "    torch.nn.init.uniform_(self.dense0.weight)\n",
        "    self.activation0 = nn.ReLU()\n",
        "    self.dense1 = nn.Linear(16, 16)\n",
        "    torch.nn.init.uniform_(self.dense1.weight)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    self.dense2 = nn.Linear(16, 1)\n",
        "    torch.nn.init.uniform_(self.dense2.weight)\n",
        "    # self.output = nn.Sigmoid() \n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dense2(X)\n",
        "    # X = self.output(X) \n",
        "    return X"
      ],
      "metadata": {
        "id": "0EBQksiPT-Mz"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Skorch, convertendo de PyTorch + Sklearn"
      ],
      "metadata": {
        "id": "Jz4Ds0vNmuui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "previsores = np.array(previsores, dtype='float32')\n",
        "classe = np.array(classe, dtype='float32').squeeze(1)"
      ],
      "metadata": {
        "id": "Y1vIqdk4oAnx"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
        "                                                  criterion=torch.nn.BCEWithLogitsLoss, # ** ATUALIZAÇÃO **\n",
        "                                                  optimizer=torch.optim.Adam,\n",
        "                                                  lr=0.001,\n",
        "                                                  optimizer__weight_decay=0.0001,\n",
        "                                                  max_epochs=100,\n",
        "                                                  batch_size=10,\n",
        "                                                  train_split=False)"
      ],
      "metadata": {
        "id": "D5zoCKpjlO79"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validação cruzada"
      ],
      "metadata": {
        "id": "BBUccbJYm922"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = cross_val_score(classificador_sklearn, previsores, classe, cv = 10, scoring = 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFYbVlwdm8K-",
        "outputId": "ea6e2fa2-624f-4a3a-d13a-9ef5910acdef"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m96846.8728\u001b[0m  0.0949\n",
            "      2    \u001b[36m77311.9348\u001b[0m  0.0832\n",
            "      3    \u001b[36m61014.5157\u001b[0m  0.0886\n",
            "      4    \u001b[36m48012.4113\u001b[0m  0.0847\n",
            "      5    \u001b[36m37804.0061\u001b[0m  0.0822\n",
            "      6    \u001b[36m29768.0487\u001b[0m  0.0965\n",
            "      7    \u001b[36m23366.1714\u001b[0m  0.0840\n",
            "      8    \u001b[36m18213.9767\u001b[0m  0.0816\n",
            "      9    \u001b[36m14017.9092\u001b[0m  0.0922\n",
            "     10    \u001b[36m10531.9261\u001b[0m  0.0888\n",
            "     11     \u001b[36m7549.8456\u001b[0m  0.0838\n",
            "     12     \u001b[36m4892.3121\u001b[0m  0.1003\n",
            "     13     \u001b[36m2392.8047\u001b[0m  0.0999\n",
            "     14      \u001b[36m349.9506\u001b[0m  0.0807\n",
            "     15       \u001b[36m72.8066\u001b[0m  0.0801\n",
            "     16       \u001b[36m64.0642\u001b[0m  0.0823\n",
            "     17       \u001b[36m55.9782\u001b[0m  0.0801\n",
            "     18       \u001b[36m49.9750\u001b[0m  0.0868\n",
            "     19       \u001b[36m41.6763\u001b[0m  0.0801\n",
            "     20       \u001b[36m34.7018\u001b[0m  0.0870\n",
            "     21       \u001b[36m29.5083\u001b[0m  0.0803\n",
            "     22       \u001b[36m25.7502\u001b[0m  0.0796\n",
            "     23       \u001b[36m24.1378\u001b[0m  0.0839\n",
            "     24       \u001b[36m22.1750\u001b[0m  0.0951\n",
            "     25       \u001b[36m22.0445\u001b[0m  0.0795\n",
            "     26       \u001b[36m20.8348\u001b[0m  0.0870\n",
            "     27       21.0951  0.0883\n",
            "     28       \u001b[36m20.1159\u001b[0m  0.0821\n",
            "     29       \u001b[36m18.9567\u001b[0m  0.0808\n",
            "     30       19.4074  0.0824\n",
            "     31       \u001b[36m18.8248\u001b[0m  0.0778\n",
            "     32       \u001b[36m17.6493\u001b[0m  0.0801\n",
            "     33       17.6809  0.0814\n",
            "     34       \u001b[36m16.2212\u001b[0m  0.0919\n",
            "     35       \u001b[36m16.1535\u001b[0m  0.0851\n",
            "     36       \u001b[36m16.1525\u001b[0m  0.0871\n",
            "     37       \u001b[36m16.0366\u001b[0m  0.0891\n",
            "     38       16.6642  0.0845\n",
            "     39       16.9008  0.0890\n",
            "     40       \u001b[36m13.6960\u001b[0m  0.0790\n",
            "     41       \u001b[36m12.2808\u001b[0m  0.0886\n",
            "     42       \u001b[36m12.0347\u001b[0m  0.0798\n",
            "     43       13.2353  0.0804\n",
            "     44       \u001b[36m11.6459\u001b[0m  0.0794\n",
            "     45       11.9467  0.0779\n",
            "     46       \u001b[36m11.1720\u001b[0m  0.0817\n",
            "     47       \u001b[36m11.1142\u001b[0m  0.0802\n",
            "     48       11.2907  0.1026\n",
            "     49       11.5805  0.0811\n",
            "     50       11.7503  0.0788\n",
            "     51       12.0547  0.0805\n",
            "     52       11.8406  0.0831\n",
            "     53       \u001b[36m11.0898\u001b[0m  0.0801\n",
            "     54       \u001b[36m10.0591\u001b[0m  0.0862\n",
            "     55       11.3695  0.0869\n",
            "     56       13.4391  0.0788\n",
            "     57       15.5640  0.0832\n",
            "     58       11.9152  0.0805\n",
            "     59        \u001b[36m8.1825\u001b[0m  0.0881\n",
            "     60        9.5272  0.0821\n",
            "     61       10.0006  0.0801\n",
            "     62        \u001b[36m7.6627\u001b[0m  0.0978\n",
            "     63        8.5805  0.0865\n",
            "     64        9.6204  0.0837\n",
            "     65        \u001b[36m7.5220\u001b[0m  0.0880\n",
            "     66        8.6766  0.0920\n",
            "     67        8.8951  0.0796\n",
            "     68        7.5737  0.0839\n",
            "     69        8.4044  0.0795\n",
            "     70        7.5840  0.0904\n",
            "     71        \u001b[36m7.3518\u001b[0m  0.0954\n",
            "     72        \u001b[36m6.7018\u001b[0m  0.0885\n",
            "     73        \u001b[36m5.6419\u001b[0m  0.0785\n",
            "     74        6.9472  0.0799\n",
            "     75        5.9761  0.1005\n",
            "     76        6.1992  0.0822\n",
            "     77        \u001b[36m5.3664\u001b[0m  0.0793\n",
            "     78        5.9948  0.0820\n",
            "     79        7.1166  0.0921\n",
            "     80        6.1609  0.0799\n",
            "     81        7.6356  0.0809\n",
            "     82        \u001b[36m4.9614\u001b[0m  0.0802\n",
            "     83        \u001b[36m4.3783\u001b[0m  0.0885\n",
            "     84        6.2170  0.0828\n",
            "     85        4.7879  0.0796\n",
            "     86        5.8384  0.0870\n",
            "     87        4.7142  0.0816\n",
            "     88        \u001b[36m3.7154\u001b[0m  0.0833\n",
            "     89        4.9536  0.0805\n",
            "     90        4.8212  0.0866\n",
            "     91        5.7068  0.0781\n",
            "     92        4.5753  0.0835\n",
            "     93        4.3664  0.0933\n",
            "     94        4.1991  0.0893\n",
            "     95        4.8831  0.0795\n",
            "     96        4.7344  0.0794\n",
            "     97        4.0698  0.0818\n",
            "     98        4.3508  0.0776\n",
            "     99        \u001b[36m3.3223\u001b[0m  0.0861\n",
            "    100        3.9676  0.0875\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m71247.7537\u001b[0m  0.0748\n",
            "      2    \u001b[36m54470.8542\u001b[0m  0.0812\n",
            "      3    \u001b[36m40784.7110\u001b[0m  0.0830\n",
            "      4    \u001b[36m29795.4251\u001b[0m  0.0780\n",
            "      5    \u001b[36m20751.9384\u001b[0m  0.0868\n",
            "      6    \u001b[36m12967.8967\u001b[0m  0.0873\n",
            "      7     \u001b[36m5827.7125\u001b[0m  0.0889\n",
            "      8      \u001b[36m796.5320\u001b[0m  0.0811\n",
            "      9      \u001b[36m179.4452\u001b[0m  0.0797\n",
            "     10       \u001b[36m90.4088\u001b[0m  0.0823\n",
            "     11       \u001b[36m67.6847\u001b[0m  0.0803\n",
            "     12       \u001b[36m53.6017\u001b[0m  0.0799\n",
            "     13       \u001b[36m45.7188\u001b[0m  0.0786\n",
            "     14       \u001b[36m37.2018\u001b[0m  0.0924\n",
            "     15       37.8137  0.0822\n",
            "     16       39.9041  0.0811\n",
            "     17       \u001b[36m25.6042\u001b[0m  0.0798\n",
            "     18       27.5053  0.0909\n",
            "     19       37.3368  0.0895\n",
            "     20       30.3592  0.0792\n",
            "     21       31.8544  0.0887\n",
            "     22       31.6789  0.0782\n",
            "     23       39.7309  0.0801\n",
            "     24       \u001b[36m25.4843\u001b[0m  0.0795\n",
            "     25       \u001b[36m18.7889\u001b[0m  0.0808\n",
            "     26       24.6456  0.0805\n",
            "     27       \u001b[36m18.1365\u001b[0m  0.0811\n",
            "     28       \u001b[36m15.3795\u001b[0m  0.0898\n",
            "     29       27.6844  0.0805\n",
            "     30       16.0473  0.0844\n",
            "     31       \u001b[36m13.3569\u001b[0m  0.0784\n",
            "     32       18.2109  0.0764\n",
            "     33       21.7815  0.0774\n",
            "     34       17.4251  0.0798\n",
            "     35       \u001b[36m12.5597\u001b[0m  0.0857\n",
            "     36        \u001b[36m7.7771\u001b[0m  0.0853\n",
            "     37        8.5769  0.0802\n",
            "     38       19.4155  0.0861\n",
            "     39        \u001b[36m5.8813\u001b[0m  0.0863\n",
            "     40       13.9434  0.0849\n",
            "     41       14.3551  0.0822\n",
            "     42       15.3235  0.0989\n",
            "     43        9.7498  0.0834\n",
            "     44        8.4101  0.0813\n",
            "     45       10.6663  0.0849\n",
            "     46       10.6685  0.0774\n",
            "     47       11.6940  0.0843\n",
            "     48        6.9456  0.0787\n",
            "     49       10.7061  0.0783\n",
            "     50        \u001b[36m5.1438\u001b[0m  0.0810\n",
            "     51       13.3469  0.0785\n",
            "     52       14.8473  0.0824\n",
            "     53        7.3311  0.0798\n",
            "     54       14.5068  0.0903\n",
            "     55        \u001b[36m4.7034\u001b[0m  0.0870\n",
            "     56        6.0428  0.0848\n",
            "     57        \u001b[36m4.4669\u001b[0m  0.0813\n",
            "     58        5.1737  0.0957\n",
            "     59        5.3445  0.0788\n",
            "     60       11.2919  0.0874\n",
            "     61        6.7274  0.0772\n",
            "     62       18.0347  0.0823\n",
            "     63        5.1240  0.0888\n",
            "     64        5.3864  0.0873\n",
            "     65        6.4928  0.0809\n",
            "     66        \u001b[36m3.8107\u001b[0m  0.0907\n",
            "     67        7.2136  0.0774\n",
            "     68        6.9466  0.0842\n",
            "     69        8.0567  0.0841\n",
            "     70       15.1992  0.0920\n",
            "     71        7.1220  0.0808\n",
            "     72        7.4260  0.0831\n",
            "     73        4.9014  0.0773\n",
            "     74        8.9289  0.0848\n",
            "     75        4.9010  0.0808\n",
            "     76        7.4671  0.0867\n",
            "     77        \u001b[36m3.7537\u001b[0m  0.0949\n",
            "     78        7.0360  0.0770\n",
            "     79        7.5249  0.0814\n",
            "     80        5.0196  0.0792\n",
            "     81        7.0031  0.0824\n",
            "     82        9.2488  0.0773\n",
            "     83        4.3417  0.0820\n",
            "     84        \u001b[36m3.1874\u001b[0m  0.0841\n",
            "     85        9.1752  0.0758\n",
            "     86        7.5272  0.0781\n",
            "     87        4.2958  0.0799\n",
            "     88        4.4394  0.0796\n",
            "     89        3.6335  0.0889\n",
            "     90        6.0952  0.0890\n",
            "     91        8.0935  0.0894\n",
            "     92        3.7007  0.0851\n",
            "     93        8.6668  0.0781\n",
            "     94        4.0404  0.0785\n",
            "     95        4.2371  0.0768\n",
            "     96        4.2469  0.0800\n",
            "     97        5.6625  0.0776\n",
            "     98        4.8870  0.0828\n",
            "     99        5.8053  0.0877\n",
            "    100        7.5232  0.0824\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m89810.1735\u001b[0m  0.0789\n",
            "      2    \u001b[36m71562.7728\u001b[0m  0.0912\n",
            "      3    \u001b[36m56475.6212\u001b[0m  0.0787\n",
            "      4    \u001b[36m44427.1327\u001b[0m  0.0779\n",
            "      5    \u001b[36m34812.1394\u001b[0m  0.0822\n",
            "      6    \u001b[36m27079.8020\u001b[0m  0.0868\n",
            "      7    \u001b[36m20803.0782\u001b[0m  0.0776\n",
            "      8    \u001b[36m15635.8570\u001b[0m  0.0787\n",
            "      9    \u001b[36m11292.1975\u001b[0m  0.0882\n",
            "     10     \u001b[36m7526.1499\u001b[0m  0.0839\n",
            "     11     \u001b[36m4125.5128\u001b[0m  0.0848\n",
            "     12     \u001b[36m1123.9084\u001b[0m  0.0806\n",
            "     13       \u001b[36m98.8196\u001b[0m  0.0971\n",
            "     14       \u001b[36m92.2049\u001b[0m  0.0860\n",
            "     15       \u001b[36m78.0545\u001b[0m  0.0844\n",
            "     16       \u001b[36m70.4118\u001b[0m  0.0818\n",
            "     17       \u001b[36m65.1665\u001b[0m  0.0825\n",
            "     18       \u001b[36m59.6190\u001b[0m  0.0827\n",
            "     19       \u001b[36m57.1853\u001b[0m  0.0781\n",
            "     20       \u001b[36m54.3144\u001b[0m  0.0856\n",
            "     21       \u001b[36m50.7158\u001b[0m  0.0804\n",
            "     22       \u001b[36m49.0746\u001b[0m  0.0811\n",
            "     23       \u001b[36m46.6755\u001b[0m  0.0831\n",
            "     24       \u001b[36m44.3397\u001b[0m  0.0810\n",
            "     25       \u001b[36m41.7065\u001b[0m  0.0967\n",
            "     26       \u001b[36m40.1240\u001b[0m  0.0825\n",
            "     27       \u001b[36m37.1495\u001b[0m  0.0930\n",
            "     28       \u001b[36m29.1338\u001b[0m  0.0817\n",
            "     29       \u001b[36m27.8263\u001b[0m  0.0798\n",
            "     30       \u001b[36m25.3332\u001b[0m  0.0811\n",
            "     31       \u001b[36m25.0441\u001b[0m  0.0899\n",
            "     32       \u001b[36m23.1232\u001b[0m  0.0826\n",
            "     33       \u001b[36m21.6551\u001b[0m  0.0847\n",
            "     34       \u001b[36m21.0645\u001b[0m  0.0868\n",
            "     35       \u001b[36m19.2450\u001b[0m  0.0800\n",
            "     36       \u001b[36m17.8542\u001b[0m  0.0824\n",
            "     37       \u001b[36m16.2664\u001b[0m  0.0897\n",
            "     38       23.3243  0.0808\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m75170.0386\u001b[0m  0.0937\n",
            "      2    \u001b[36m58560.5340\u001b[0m  0.0776\n",
            "      3    \u001b[36m44872.0566\u001b[0m  0.0784\n",
            "      4    \u001b[36m33872.1161\u001b[0m  0.0797\n",
            "      5    \u001b[36m25031.9940\u001b[0m  0.0821\n",
            "      6    \u001b[36m17879.8076\u001b[0m  0.0803\n",
            "      7    \u001b[36m12035.4019\u001b[0m  0.0859\n",
            "      8     \u001b[36m7155.5026\u001b[0m  0.0799\n",
            "      9     \u001b[36m2808.6254\u001b[0m  0.0885\n",
            "     10      \u001b[36m206.2900\u001b[0m  0.0881\n",
            "     11      \u001b[36m129.0370\u001b[0m  0.0843\n",
            "     12      \u001b[36m121.1058\u001b[0m  0.0808\n",
            "     13      \u001b[36m113.9348\u001b[0m  0.0878\n",
            "     14      \u001b[36m106.1507\u001b[0m  0.0820\n",
            "     15      \u001b[36m104.5477\u001b[0m  0.0853\n",
            "     16      \u001b[36m101.7716\u001b[0m  0.0804\n",
            "     17      \u001b[36m101.1483\u001b[0m  0.0807\n",
            "     18      \u001b[36m100.6950\u001b[0m  0.0789\n",
            "     19      104.1665  0.0839\n",
            "     20       \u001b[36m98.6833\u001b[0m  0.0783\n",
            "     21      104.3681  0.0847\n",
            "     22       \u001b[36m95.8792\u001b[0m  0.0892\n",
            "     23       \u001b[36m72.3896\u001b[0m  0.0858\n",
            "     24       \u001b[36m63.1665\u001b[0m  0.0832\n",
            "     25       \u001b[36m56.6640\u001b[0m  0.0795\n",
            "     26       77.6705  0.0854\n",
            "     27       \u001b[36m50.8597\u001b[0m  0.0794\n",
            "     28       \u001b[36m49.9143\u001b[0m  0.0877\n",
            "     29       60.2793  0.0815\n",
            "     30       49.9539  0.0845\n",
            "     31       \u001b[36m47.7009\u001b[0m  0.0797\n",
            "     32       50.1501  0.0799\n",
            "     33       50.1596  0.0786\n",
            "     34       \u001b[36m46.4582\u001b[0m  0.0942\n",
            "     35       50.2351  0.0791\n",
            "     36       47.8206  0.0845\n",
            "     37       50.5218  0.0809\n",
            "     38       \u001b[36m43.7009\u001b[0m  0.0846\n",
            "     39       \u001b[36m43.5092\u001b[0m  0.0832\n",
            "     40       \u001b[36m38.9501\u001b[0m  0.0940\n",
            "     41       42.7819  0.0793\n",
            "     42       \u001b[36m35.7541\u001b[0m  0.0789\n",
            "     43       \u001b[36m30.9918\u001b[0m  0.0830\n",
            "     44       75.4287  0.0801\n",
            "     45       \u001b[36m20.1997\u001b[0m  0.0890\n",
            "     46       42.6758  0.0802\n",
            "     47       29.0748  0.0826\n",
            "     48       41.6554  0.0776\n",
            "     49       34.8873  0.0782\n",
            "     50       39.3034  0.0778\n",
            "     51       22.2391  0.0777\n",
            "     52       40.1204  0.0840\n",
            "     53       29.4331  0.0803\n",
            "     54       44.8272  0.0884\n",
            "     55       \u001b[36m17.7048\u001b[0m  0.0850\n",
            "     56       35.9698  0.0817\n",
            "     57       37.1718  0.0879\n",
            "     58       26.2904  0.0853\n",
            "     59       34.5063  0.0844\n",
            "     60       34.9296  0.0796\n",
            "     61       32.6696  0.0835\n",
            "     62       29.0233  0.0809\n",
            "     63       31.3279  0.0777\n",
            "     64       19.5035  0.0788\n",
            "     65       33.5644  0.0914\n",
            "     66       30.4202  0.0768\n",
            "     67       30.9083  0.0790\n",
            "     68       21.0560  0.0809\n",
            "     69       29.9486  0.0807\n",
            "     70       \u001b[36m14.9471\u001b[0m  0.0906\n",
            "     71       17.0108  0.0797\n",
            "     72       31.3890  0.0793\n",
            "     73       30.9240  0.0838\n",
            "     74       21.3758  0.0790\n",
            "     75       36.7441  0.0805\n",
            "     76       21.9665  0.0810\n",
            "     77       31.1765  0.0839\n",
            "     78       \u001b[36m12.6765\u001b[0m  0.0802\n",
            "     79       17.0868  0.0822\n",
            "     80       34.7266  0.0801\n",
            "     81       21.3754  0.0819\n",
            "     82       34.2746  0.0862\n",
            "     83       \u001b[36m12.2724\u001b[0m  0.0783\n",
            "     84       15.3571  0.0776\n",
            "     85       \u001b[36m12.1254\u001b[0m  0.0784\n",
            "     86       15.2483  0.0844\n",
            "     87       21.1000  0.0818\n",
            "     88       32.8623  0.0826\n",
            "     89       20.4475  0.0823\n",
            "     90       25.3143  0.0875\n",
            "     91       27.5690  0.0819\n",
            "     92       18.2801  0.0825\n",
            "     93       18.8957  0.0810\n",
            "     94       20.8450  0.0902\n",
            "     95       19.2134  0.0870\n",
            "     96       22.5846  0.0790\n",
            "     97       18.7275  0.0798\n",
            "     98       20.1039  0.0808\n",
            "     99       15.6102  0.0807\n",
            "    100       19.8543  0.0877\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m81038.5429\u001b[0m  0.0777\n",
            "      2    \u001b[36m62614.4624\u001b[0m  0.0790\n",
            "      3    \u001b[36m47538.3862\u001b[0m  0.0839\n",
            "      4    \u001b[36m35556.5752\u001b[0m  0.0832\n",
            "      5    \u001b[36m26000.1589\u001b[0m  0.0894\n",
            "      6    \u001b[36m18242.8011\u001b[0m  0.0867\n",
            "      7    \u001b[36m11744.7548\u001b[0m  0.0819\n",
            "      8     \u001b[36m6036.0449\u001b[0m  0.0782\n",
            "      9     \u001b[36m1189.4521\u001b[0m  0.0769\n",
            "     10      \u001b[36m154.0822\u001b[0m  0.0784\n",
            "     11      \u001b[36m128.1895\u001b[0m  0.0842\n",
            "     12      \u001b[36m116.7458\u001b[0m  0.0834\n",
            "     13      \u001b[36m107.1917\u001b[0m  0.0824\n",
            "     14      \u001b[36m104.0009\u001b[0m  0.0842\n",
            "     15       \u001b[36m99.0544\u001b[0m  0.0861\n",
            "     16       \u001b[36m80.2865\u001b[0m  0.0880\n",
            "     17       \u001b[36m58.7342\u001b[0m  0.0872\n",
            "     18       \u001b[36m48.4070\u001b[0m  0.0817\n",
            "     19       \u001b[36m38.1219\u001b[0m  0.0820\n",
            "     20       73.1318  0.0847\n",
            "     21       \u001b[36m24.9116\u001b[0m  0.0793\n",
            "     22       75.3310  0.0803\n",
            "     23       \u001b[36m18.6366\u001b[0m  0.0789\n",
            "     24       \u001b[36m17.2183\u001b[0m  0.0838\n",
            "     25       22.7156  0.0869\n",
            "     26       \u001b[36m16.8295\u001b[0m  0.0790\n",
            "     27       \u001b[36m14.7692\u001b[0m  0.0782\n",
            "     28       18.4276  0.0785\n",
            "     29       15.1654  0.0832\n",
            "     30       21.0384  0.0829\n",
            "     31       14.8106  0.0813\n",
            "     32       18.0481  0.0789\n",
            "     33       20.3418  0.0828\n",
            "     34       \u001b[36m10.4707\u001b[0m  0.0794\n",
            "     35       22.3426  0.0856\n",
            "     36       19.0763  0.0769\n",
            "     37        \u001b[36m9.7587\u001b[0m  0.0790\n",
            "     38       16.0187  0.0833\n",
            "     39       13.7462  0.0834\n",
            "     40       12.0454  0.0831\n",
            "     41       20.0116  0.0808\n",
            "     42       18.5499  0.0974\n",
            "     43        \u001b[36m6.5153\u001b[0m  0.0804\n",
            "     44       22.9759  0.0810\n",
            "     45        \u001b[36m6.2084\u001b[0m  0.0820\n",
            "     46       24.2999  0.0998\n",
            "     47       21.5320  0.0801\n",
            "     48       12.4980  0.0815\n",
            "     49       11.7445  0.0798\n",
            "     50       12.9650  0.0848\n",
            "     51       15.7778  0.0887\n",
            "     52        7.4692  0.0811\n",
            "     53        9.0923  0.0892\n",
            "     54       15.9480  0.0790\n",
            "     55       11.1237  0.0810\n",
            "     56       10.3591  0.0838\n",
            "     57        6.3524  0.0860\n",
            "     58        8.7259  0.0812\n",
            "     59       15.4574  0.0945\n",
            "     60       22.2024  0.0883\n",
            "     61       22.6032  0.0857\n",
            "     62       21.5279  0.0836\n",
            "     63       12.9758  0.0809\n",
            "     64        9.9905  0.0869\n",
            "     65        8.4678  0.0907\n",
            "     66        8.4526  0.0811\n",
            "     67       14.0285  0.0813\n",
            "     68        7.6879  0.0790\n",
            "     69        7.5959  0.0869\n",
            "     70        9.9343  0.0876\n",
            "     71       11.4916  0.0809\n",
            "     72       11.0440  0.0798\n",
            "     73        8.7353  0.0832\n",
            "     74        6.9046  0.0811\n",
            "     75        \u001b[36m5.9662\u001b[0m  0.0822\n",
            "     76        6.4861  0.0810\n",
            "     77        \u001b[36m5.5132\u001b[0m  0.0881\n",
            "     78       11.4178  0.0782\n",
            "     79        8.6703  0.0788\n",
            "     80        7.3105  0.0825\n",
            "     81        9.1628  0.1042\n",
            "     82        6.3917  0.0826\n",
            "     83        6.5127  0.0812\n",
            "     84        7.4103  0.0820\n",
            "     85        \u001b[36m5.2688\u001b[0m  0.0845\n",
            "     86        5.7020  0.0878\n",
            "     87        \u001b[36m3.1202\u001b[0m  0.0799\n",
            "     88        4.6210  0.0831\n",
            "     89        4.4150  0.0903\n",
            "     90        6.7067  0.0856\n",
            "     91       15.9395  0.0945\n",
            "     92       26.4103  0.0783\n",
            "     93       10.1280  0.0786\n",
            "     94        7.0910  0.0785\n",
            "     95        3.7906  0.0808\n",
            "     96        6.3261  0.0808\n",
            "     97        4.3004  0.0910\n",
            "     98        6.4418  0.0796\n",
            "     99        6.1938  0.0787\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m71681.9599\u001b[0m  0.0859\n",
            "      2    \u001b[36m55515.0853\u001b[0m  0.0797\n",
            "      3    \u001b[36m42550.8002\u001b[0m  0.0769\n",
            "      4    \u001b[36m32393.3372\u001b[0m  0.0781\n",
            "      5    \u001b[36m24372.0962\u001b[0m  0.0895\n",
            "      6    \u001b[36m17941.0358\u001b[0m  0.0818\n",
            "      7    \u001b[36m12678.6780\u001b[0m  0.0776\n",
            "      8     \u001b[36m8236.8299\u001b[0m  0.0819\n",
            "      9     \u001b[36m4305.3095\u001b[0m  0.0782\n",
            "     10     \u001b[36m1001.4426\u001b[0m  0.0807\n",
            "     11      \u001b[36m285.9182\u001b[0m  0.0823\n",
            "     12      \u001b[36m236.7346\u001b[0m  0.0793\n",
            "     13      \u001b[36m202.6857\u001b[0m  0.0902\n",
            "     14      \u001b[36m165.1817\u001b[0m  0.0901\n",
            "     15      \u001b[36m137.6454\u001b[0m  0.0812\n",
            "     16      \u001b[36m112.7170\u001b[0m  0.0930\n",
            "     17       \u001b[36m92.5676\u001b[0m  0.0819\n",
            "     18       \u001b[36m76.8887\u001b[0m  0.0836\n",
            "     19       \u001b[36m63.6834\u001b[0m  0.0803\n",
            "     20       \u001b[36m57.0376\u001b[0m  0.0868\n",
            "     21       \u001b[36m49.5731\u001b[0m  0.0801\n",
            "     22       \u001b[36m44.7721\u001b[0m  0.0839\n",
            "     23       \u001b[36m41.7057\u001b[0m  0.0819\n",
            "     24       \u001b[36m39.1192\u001b[0m  0.0934\n",
            "     25       \u001b[36m33.7456\u001b[0m  0.0799\n",
            "     26       36.3698  0.0923\n",
            "     27       \u001b[36m33.0860\u001b[0m  0.0835\n",
            "     28       39.0908  0.0769\n",
            "     29       \u001b[36m31.8650\u001b[0m  0.0766\n",
            "     30       35.1051  0.0775\n",
            "     31       \u001b[36m30.3944\u001b[0m  0.0801\n",
            "     32       30.8538  0.0880\n",
            "     33       30.8805  0.0797\n",
            "     34       \u001b[36m29.5958\u001b[0m  0.0791\n",
            "     35       \u001b[36m28.9703\u001b[0m  0.0772\n",
            "     36       \u001b[36m28.6193\u001b[0m  0.0885\n",
            "     37       29.0701  0.0834\n",
            "     38       29.0981  0.0791\n",
            "     39       28.7057  0.0780\n",
            "     40       \u001b[36m27.5339\u001b[0m  0.0794\n",
            "     41       \u001b[36m27.3205\u001b[0m  0.0951\n",
            "     42       \u001b[36m27.1907\u001b[0m  0.0783\n",
            "     43       \u001b[36m27.0833\u001b[0m  0.0798\n",
            "     44       \u001b[36m26.8443\u001b[0m  0.0790\n",
            "     45       \u001b[36m25.8900\u001b[0m  0.0761\n",
            "     46       \u001b[36m23.3429\u001b[0m  0.0844\n",
            "     47       \u001b[36m23.0772\u001b[0m  0.0814\n",
            "     48       \u001b[36m21.2799\u001b[0m  0.0804\n",
            "     49       \u001b[36m17.4847\u001b[0m  0.0873\n",
            "     50       20.2412  0.0846\n",
            "     51       19.1772  0.0869\n",
            "     52       \u001b[36m13.0417\u001b[0m  0.0813\n",
            "     53       \u001b[36m12.8040\u001b[0m  0.0794\n",
            "     54       \u001b[36m11.1336\u001b[0m  0.0861\n",
            "     55       11.7572  0.0809\n",
            "     56       13.7241  0.0877\n",
            "     57       13.1691  0.0772\n",
            "     58       12.9926  0.0773\n",
            "     59       11.6513  0.0815\n",
            "     60       12.3270  0.0783\n",
            "     61       \u001b[36m10.0636\u001b[0m  0.0870\n",
            "     62       10.8141  0.0859\n",
            "     63        \u001b[36m8.6153\u001b[0m  0.0865\n",
            "     64        \u001b[36m8.5679\u001b[0m  0.0791\n",
            "     65        8.8647  0.0788\n",
            "     66        \u001b[36m8.3490\u001b[0m  0.0791\n",
            "     67        \u001b[36m7.6693\u001b[0m  0.0848\n",
            "     68        9.9230  0.0785\n",
            "     69       10.2249  0.0774\n",
            "     70        8.1116  0.0761\n",
            "     71        \u001b[36m6.5818\u001b[0m  0.0822\n",
            "     72        7.1332  0.0730\n",
            "     73        \u001b[36m6.0603\u001b[0m  0.0873\n",
            "     74        6.7063  0.0772\n",
            "     75        7.0382  0.0794\n",
            "     76        \u001b[36m5.6627\u001b[0m  0.0964\n",
            "     77        \u001b[36m5.6005\u001b[0m  0.0815\n",
            "     78        \u001b[36m4.7516\u001b[0m  0.0787\n",
            "     79        \u001b[36m4.3704\u001b[0m  0.0824\n",
            "     80        5.0889  0.0797\n",
            "     81        4.7845  0.0921\n",
            "     82        \u001b[36m3.5390\u001b[0m  0.0957\n",
            "     83        5.0226  0.0802\n",
            "     84        3.8495  0.0799\n",
            "     85        4.5161  0.0909\n",
            "     86        5.1477  0.0779\n",
            "     87        4.8328  0.0852\n",
            "     88        5.3522  0.0775\n",
            "     89        3.9023  0.0814\n",
            "     90        \u001b[36m3.3543\u001b[0m  0.0856\n",
            "     91        4.0408  0.0833\n",
            "     92        4.3983  0.0794\n",
            "     93        5.5574  0.0763\n",
            "     94        7.4104  0.0830\n",
            "     95        \u001b[36m3.2461\u001b[0m  0.0792\n",
            "     96        7.1555  0.0781\n",
            "     97        7.2973  0.0909\n",
            "     98        4.5256  0.0792\n",
            "     99        4.6804  0.0850\n",
            "    100        3.9194  0.0811\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m74162.6851\u001b[0m  0.0773\n",
            "      2    \u001b[36m57719.5399\u001b[0m  0.0821\n",
            "      3    \u001b[36m44247.2022\u001b[0m  0.0827\n",
            "      4    \u001b[36m33419.5170\u001b[0m  0.0913\n",
            "      5    \u001b[36m24632.0068\u001b[0m  0.0792\n",
            "      6    \u001b[36m17390.4729\u001b[0m  0.0793\n",
            "      7    \u001b[36m11285.0133\u001b[0m  0.0813\n",
            "      8     \u001b[36m5905.3103\u001b[0m  0.0892\n",
            "      9     \u001b[36m1241.8354\u001b[0m  0.0913\n",
            "     10      \u001b[36m109.9672\u001b[0m  0.0783\n",
            "     11       \u001b[36m94.9307\u001b[0m  0.0917\n",
            "     12       \u001b[36m86.1061\u001b[0m  0.0814\n",
            "     13       \u001b[36m71.4352\u001b[0m  0.0832\n",
            "     14       \u001b[36m67.7054\u001b[0m  0.0875\n",
            "     15       \u001b[36m58.0101\u001b[0m  0.0862\n",
            "     16       63.4232  0.0855\n",
            "     17       65.0715  0.0806\n",
            "     18       62.0321  0.0797\n",
            "     19       62.8796  0.0801\n",
            "     20       59.3796  0.0849\n",
            "     21       \u001b[36m54.3581\u001b[0m  0.0835\n",
            "     22       54.4704  0.0852\n",
            "     23       \u001b[36m50.2619\u001b[0m  0.0790\n",
            "     24       \u001b[36m43.5458\u001b[0m  0.0789\n",
            "     25       59.3472  0.0815\n",
            "     26       \u001b[36m30.2062\u001b[0m  0.0857\n",
            "     27       36.6356  0.0844\n",
            "     28       35.3147  0.0800\n",
            "     29       35.3288  0.0842\n",
            "     30       35.0156  0.0771\n",
            "     31       36.7092  0.0854\n",
            "     32       36.9474  0.0991\n",
            "     33       43.9910  0.0764\n",
            "     34       38.5173  0.0814\n",
            "     35       38.5539  0.0824\n",
            "     36       38.6611  0.0772\n",
            "     37       31.8286  0.0883\n",
            "     38       35.5730  0.0813\n",
            "     39       39.8931  0.0787\n",
            "     40       40.8580  0.0781\n",
            "     41       37.0530  0.0827\n",
            "     42       \u001b[36m20.7889\u001b[0m  0.0762\n",
            "     43       \u001b[36m15.1001\u001b[0m  0.0781\n",
            "     44       \u001b[36m12.4255\u001b[0m  0.0789\n",
            "     45       \u001b[36m11.8988\u001b[0m  0.0868\n",
            "     46       13.1435  0.0838\n",
            "     47       12.5594  0.0808\n",
            "     48       11.9932  0.0838\n",
            "     49       15.0788  0.0849\n",
            "     50       17.4786  0.0817\n",
            "     51       12.2032  0.0855\n",
            "     52       \u001b[36m11.1752\u001b[0m  0.0826\n",
            "     53       \u001b[36m10.5985\u001b[0m  0.0853\n",
            "     54       12.7127  0.0788\n",
            "     55       10.7795  0.0886\n",
            "     56       13.0688  0.0922\n",
            "     57       14.5579  0.0933\n",
            "     58       11.7304  0.0799\n",
            "     59       11.6585  0.0781\n",
            "     60        \u001b[36m9.4866\u001b[0m  0.0797\n",
            "     61        \u001b[36m8.9494\u001b[0m  0.0800\n",
            "     62       13.0329  0.0833\n",
            "     63       11.9600  0.0784\n",
            "     64       12.8482  0.0846\n",
            "     65        9.7763  0.0789\n",
            "     66       10.9459  0.0816\n",
            "     67       11.9838  0.0794\n",
            "     68       11.4670  0.0933\n",
            "     69       11.9648  0.0844\n",
            "     70       11.0290  0.0788\n",
            "     71       15.0341  0.0823\n",
            "     72       12.4875  0.0894\n",
            "     73       14.9640  0.0783\n",
            "     74       12.1221  0.0792\n",
            "     75       12.7693  0.0788\n",
            "     76       12.0491  0.0801\n",
            "     77       12.7787  0.0808\n",
            "     78       16.4256  0.0867\n",
            "     79       19.0622  0.0814\n",
            "     80       16.4401  0.0890\n",
            "     81       20.9996  0.0841\n",
            "     82       16.0827  0.0798\n",
            "     83       20.0037  0.0804\n",
            "     84       15.9796  0.0833\n",
            "     85       13.4946  0.0835\n",
            "     86       16.1403  0.0864\n",
            "     87       14.4269  0.0817\n",
            "     88       19.0195  0.0813\n",
            "     89       17.2060  0.0799\n",
            "     90       16.5539  0.0789\n",
            "     91       12.0589  0.0806\n",
            "     92       14.7734  0.0948\n",
            "     93       12.9035  0.0805\n",
            "     94       14.8067  0.0792\n",
            "     95       11.8214  0.0849\n",
            "     96       14.9157  0.0841\n",
            "     97       11.8386  0.0802\n",
            "     98       18.4277  0.0797\n",
            "     99       15.3323  0.0837\n",
            "    100       14.9515  0.0857\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m76225.4866\u001b[0m  0.0897\n",
            "      2    \u001b[36m59946.1637\u001b[0m  0.0937\n",
            "      3    \u001b[36m46658.1545\u001b[0m  0.0801\n",
            "      4    \u001b[36m36059.4291\u001b[0m  0.0885\n",
            "      5    \u001b[36m27562.9855\u001b[0m  0.0808\n",
            "      6    \u001b[36m20690.2095\u001b[0m  0.0840\n",
            "      7    \u001b[36m15116.4058\u001b[0m  0.0859\n",
            "      8    \u001b[36m10549.0088\u001b[0m  0.0800\n",
            "      9     \u001b[36m6700.8715\u001b[0m  0.0801\n",
            "     10     \u001b[36m3294.9253\u001b[0m  0.0856\n",
            "     11      \u001b[36m570.5348\u001b[0m  0.0812\n",
            "     12      \u001b[36m149.2303\u001b[0m  0.0788\n",
            "     13      \u001b[36m128.6435\u001b[0m  0.0873\n",
            "     14      \u001b[36m115.3033\u001b[0m  0.0785\n",
            "     15      \u001b[36m101.5710\u001b[0m  0.0828\n",
            "     16       \u001b[36m89.0615\u001b[0m  0.0903\n",
            "     17       \u001b[36m78.0763\u001b[0m  0.0824\n",
            "     18       \u001b[36m71.2225\u001b[0m  0.0812\n",
            "     19       \u001b[36m68.5755\u001b[0m  0.0938\n",
            "     20       \u001b[36m55.8376\u001b[0m  0.0806\n",
            "     21       \u001b[36m50.1925\u001b[0m  0.0795\n",
            "     22       \u001b[36m48.9789\u001b[0m  0.0807\n",
            "     23       \u001b[36m43.7509\u001b[0m  0.0859\n",
            "     24       \u001b[36m40.2464\u001b[0m  0.0817\n",
            "     25       \u001b[36m38.4660\u001b[0m  0.0815\n",
            "     26       \u001b[36m36.0125\u001b[0m  0.0825\n",
            "     27       \u001b[36m33.4363\u001b[0m  0.0927\n",
            "     28       33.8747  0.0851\n",
            "     29       \u001b[36m33.3942\u001b[0m  0.0823\n",
            "     30       36.8991  0.0848\n",
            "     31       \u001b[36m29.9257\u001b[0m  0.0829\n",
            "     32       30.8404  0.0804\n",
            "     33       32.7542  0.0850\n",
            "     34       34.5754  0.0790\n",
            "     35       \u001b[36m29.7333\u001b[0m  0.0829\n",
            "     36       36.8266  0.0792\n",
            "     37       \u001b[36m22.1838\u001b[0m  0.0810\n",
            "     38       25.3460  0.0951\n",
            "     39       29.3195  0.0901\n",
            "     40       27.8335  0.0818\n",
            "     41       26.5068  0.0830\n",
            "     42       \u001b[36m21.2265\u001b[0m  0.0889\n",
            "     43       27.0757  0.0791\n",
            "     44       25.5153  0.0811\n",
            "     45       25.3922  0.0806\n",
            "     46       22.0321  0.0804\n",
            "     47       38.5721  0.0861\n",
            "     48       28.9392  0.0897\n",
            "     49       24.8613  0.0795\n",
            "     50       \u001b[36m18.6389\u001b[0m  0.0808\n",
            "     51       24.1931  0.0916\n",
            "     52       30.9917  0.0849\n",
            "     53       19.9654  0.0821\n",
            "     54       21.9135  0.0815\n",
            "     55       21.4896  0.0858\n",
            "     56       26.7799  0.0808\n",
            "     57       30.3024  0.0809\n",
            "     58       20.4513  0.0796\n",
            "     59       \u001b[36m14.3450\u001b[0m  0.0859\n",
            "     60       33.5751  0.0816\n",
            "     61       19.2644  0.0810\n",
            "     62       18.6806  0.0908\n",
            "     63       26.2836  0.0894\n",
            "     64       22.5917  0.0778\n",
            "     65       \u001b[36m11.5745\u001b[0m  0.0818\n",
            "     66        \u001b[36m8.8956\u001b[0m  0.0808\n",
            "     67       10.2213  0.0848\n",
            "     68       14.3918  0.0767\n",
            "     69       10.9060  0.0794\n",
            "     70       23.7732  0.0818\n",
            "     71       26.9600  0.0891\n",
            "     72       12.3149  0.0892\n",
            "     73       13.5331  0.0780\n",
            "     74        \u001b[36m7.7264\u001b[0m  0.0796\n",
            "     75       11.3956  0.0872\n",
            "     76       22.5927  0.0882\n",
            "     77       28.6960  0.0785\n",
            "     78       27.1961  0.0805\n",
            "     79       25.9371  0.0806\n",
            "     80       26.4453  0.0761\n",
            "     81       25.9831  0.0836\n",
            "     82       22.6239  0.0788\n",
            "     83       22.8361  0.0805\n",
            "     84       20.3706  0.0858\n",
            "     85       28.2041  0.0802\n",
            "     86       20.5656  0.0828\n",
            "     87       19.9606  0.0992\n",
            "     88       18.3973  0.0815\n",
            "     89       12.6333  0.0791\n",
            "     90        9.0670  0.0856\n",
            "     91        7.8007  0.0781\n",
            "     92        \u001b[36m4.4794\u001b[0m  0.0792\n",
            "     93        7.2187  0.0776\n",
            "     94        4.8998  0.0780\n",
            "     95        \u001b[36m3.4851\u001b[0m  0.0844\n",
            "     96        5.6240  0.0795\n",
            "     97        6.8183  0.0990\n",
            "     98       10.0910  0.0843\n",
            "     99        4.7447  0.0926\n",
            "    100        \u001b[36m3.2846\u001b[0m  0.0860\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m91653.1394\u001b[0m  0.0790\n",
            "      2    \u001b[36m72636.3227\u001b[0m  0.0810\n",
            "      3    \u001b[36m56681.3835\u001b[0m  0.0812\n",
            "      4    \u001b[36m43424.1701\u001b[0m  0.0820\n",
            "      5    \u001b[36m32163.3057\u001b[0m  0.0786\n",
            "      6    \u001b[36m22276.6126\u001b[0m  0.0809\n",
            "      7    \u001b[36m13224.6452\u001b[0m  0.0834\n",
            "      8     \u001b[36m4586.1355\u001b[0m  0.0949\n",
            "      9      \u001b[36m398.3520\u001b[0m  0.0812\n",
            "     10      \u001b[36m264.9462\u001b[0m  0.0795\n",
            "     11      \u001b[36m220.0764\u001b[0m  0.0961\n",
            "     12      \u001b[36m214.4706\u001b[0m  0.0813\n",
            "     13      \u001b[36m210.6417\u001b[0m  0.0880\n",
            "     14      \u001b[36m205.7891\u001b[0m  0.0850\n",
            "     15      \u001b[36m195.0774\u001b[0m  0.0809\n",
            "     16      \u001b[36m180.7471\u001b[0m  0.0767\n",
            "     17      191.4362  0.0831\n",
            "     18      \u001b[36m171.6879\u001b[0m  0.0927\n",
            "     19      \u001b[36m134.4680\u001b[0m  0.0801\n",
            "     20      \u001b[36m111.5958\u001b[0m  0.0945\n",
            "     21       \u001b[36m98.3471\u001b[0m  0.0803\n",
            "     22       \u001b[36m97.4274\u001b[0m  0.1028\n",
            "     23       \u001b[36m95.8816\u001b[0m  0.0799\n",
            "     24       \u001b[36m94.8488\u001b[0m  0.0781\n",
            "     25       \u001b[36m85.5568\u001b[0m  0.0787\n",
            "     26       94.6219  0.0784\n",
            "     27       \u001b[36m59.4741\u001b[0m  0.0780\n",
            "     28       63.8286  0.0786\n",
            "     29       \u001b[36m59.4317\u001b[0m  0.0785\n",
            "     30       76.5826  0.0806\n",
            "     31       \u001b[36m56.7398\u001b[0m  0.0847\n",
            "     32       \u001b[36m48.5922\u001b[0m  0.0966\n",
            "     33       55.2729  0.0817\n",
            "     34       70.4916  0.0916\n",
            "     35       66.7374  0.0831\n",
            "     36       67.9973  0.0820\n",
            "     37       81.6253  0.0891\n",
            "     38       86.2118  0.0792\n",
            "     39       75.1488  0.0803\n",
            "     40       75.2270  0.0805\n",
            "     41       75.0086  0.0818\n",
            "     42       71.3024  0.0909\n",
            "     43       49.4666  0.0884\n",
            "     44       \u001b[36m40.4432\u001b[0m  0.0854\n",
            "     45       \u001b[36m34.7908\u001b[0m  0.0837\n",
            "     46       \u001b[36m22.6135\u001b[0m  0.0952\n",
            "     47       \u001b[36m16.8397\u001b[0m  0.0856\n",
            "     48       19.3065  0.0821\n",
            "     49       \u001b[36m15.8798\u001b[0m  0.0831\n",
            "     50       17.9092  0.0870\n",
            "     51       \u001b[36m12.5210\u001b[0m  0.0827\n",
            "     52       14.6459  0.0886\n",
            "     53       35.2987  0.0843\n",
            "     54       12.5258  0.0813\n",
            "     55       12.5233  0.0874\n",
            "     56       33.1720  0.0882\n",
            "     57       38.3158  0.0863\n",
            "     58       15.6151  0.0903\n",
            "     59       16.1222  0.0807\n",
            "     60        \u001b[36m9.5120\u001b[0m  0.0824\n",
            "     61       12.1486  0.0823\n",
            "     62       14.6867  0.0872\n",
            "     63       13.0249  0.0809\n",
            "     64       16.0630  0.0814\n",
            "     65       23.0923  0.0794\n",
            "     66       34.8480  0.0929\n",
            "     67       11.8942  0.0817\n",
            "     68        9.8983  0.0823\n",
            "     69       10.4668  0.1024\n",
            "     70       21.5390  0.0821\n",
            "     71       17.4823  0.0882\n",
            "     72       12.0560  0.0813\n",
            "     73       18.3181  0.0807\n",
            "     74       10.0806  0.0806\n",
            "     75        \u001b[36m6.2985\u001b[0m  0.0849\n",
            "     76       12.7921  0.0811\n",
            "     77       10.4031  0.0755\n",
            "     78       11.5939  0.0799\n",
            "     79       34.5641  0.0821\n",
            "     80       25.9476  0.0835\n",
            "     81       13.2622  0.0988\n",
            "     82       11.5191  0.0802\n",
            "     83       11.2589  0.0872\n",
            "     84        8.9450  0.0801\n",
            "     85        7.7672  0.0783\n",
            "     86        \u001b[36m6.2182\u001b[0m  0.0778\n",
            "     87        \u001b[36m5.0607\u001b[0m  0.0810\n",
            "     88       14.3613  0.0876\n",
            "     89        7.0915  0.0823\n",
            "     90        \u001b[36m4.7345\u001b[0m  0.0804\n",
            "     91       13.1295  0.0806\n",
            "     92        8.7046  0.0890\n",
            "     93        5.3415  0.0895\n",
            "     94        6.2429  0.0812\n",
            "     95        5.4684  0.0852\n",
            "     96       21.7488  0.0810\n",
            "     97       36.3828  0.0787\n",
            "     98       18.7920  0.0816\n",
            "     99        8.9745  0.0787\n",
            "    100        6.1807  0.0795\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m99997.0592\u001b[0m  0.0840\n",
            "      2    \u001b[36m79860.6229\u001b[0m  0.0852\n",
            "      3    \u001b[36m62674.8889\u001b[0m  0.0821\n",
            "      4    \u001b[36m48238.3030\u001b[0m  0.0833\n",
            "      5    \u001b[36m36169.3103\u001b[0m  0.0933\n",
            "      6    \u001b[36m26029.5822\u001b[0m  0.0765\n",
            "      7    \u001b[36m17381.6469\u001b[0m  0.0924\n",
            "      8     \u001b[36m9786.8325\u001b[0m  0.0796\n",
            "      9     \u001b[36m2895.9333\u001b[0m  0.0769\n",
            "     10      \u001b[36m159.6658\u001b[0m  0.0800\n",
            "     11      \u001b[36m143.3437\u001b[0m  0.0850\n",
            "     12      \u001b[36m117.4232\u001b[0m  0.0856\n",
            "     13       \u001b[36m97.2950\u001b[0m  0.0823\n",
            "     14       \u001b[36m72.3268\u001b[0m  0.0793\n",
            "     15       \u001b[36m63.6928\u001b[0m  0.0909\n",
            "     16       \u001b[36m48.0796\u001b[0m  0.0844\n",
            "     17       64.0445  0.0939\n",
            "     18       51.6654  0.0816\n",
            "     19       \u001b[36m41.8150\u001b[0m  0.0799\n",
            "     20       61.4536  0.0804\n",
            "     21       \u001b[36m41.5993\u001b[0m  0.0803\n",
            "     22       41.7174  0.0870\n",
            "     23       42.2553  0.0892\n",
            "     24       61.8520  0.0847\n",
            "     25       50.6040  0.0880\n",
            "     26       46.0446  0.0859\n",
            "     27       \u001b[36m40.5630\u001b[0m  0.0858\n",
            "     28       66.1170  0.0920\n",
            "     29       47.6317  0.0806\n",
            "     30       60.2357  0.0836\n",
            "     31       47.6334  0.0866\n",
            "     32       \u001b[36m38.3026\u001b[0m  0.0906\n",
            "     33       \u001b[36m35.7481\u001b[0m  0.0807\n",
            "     34       41.3085  0.0836\n",
            "     35       37.6363  0.0849\n",
            "     36       40.0860  0.0842\n",
            "     37       \u001b[36m35.2479\u001b[0m  0.0861\n",
            "     38       64.1060  0.0957\n",
            "     39       \u001b[36m32.2832\u001b[0m  0.1000\n",
            "     40       \u001b[36m25.9346\u001b[0m  0.0933\n",
            "     41       47.7871  0.0831\n",
            "     42       34.4733  0.0820\n",
            "     43       53.9636  0.0807\n",
            "     44       37.7626  0.0850\n",
            "     45       44.4213  0.0815\n",
            "     46       34.3738  0.0878\n",
            "     47       46.5421  0.0830\n",
            "     48       44.2352  0.0872\n",
            "     49       41.4624  0.0866\n",
            "     50       27.3012  0.0903\n",
            "     51       48.8160  0.0942\n",
            "     52       31.5129  0.0872\n",
            "     53       46.1972  0.0839\n",
            "     54       33.5583  0.0837\n",
            "     55       43.7273  0.0805\n",
            "     56       37.3441  0.0911\n",
            "     57       38.1300  0.0822\n",
            "     58       31.6267  0.0823\n",
            "     59       43.6810  0.0821\n",
            "     60       37.0245  0.0850\n",
            "     61       33.4405  0.0883\n",
            "     62       54.2704  0.0907\n",
            "     63       31.3223  0.0925\n",
            "     64       46.5975  0.0820\n",
            "     65       38.7601  0.0857\n",
            "     66       36.9627  0.0875\n",
            "     67       27.0914  0.0818\n",
            "     68       36.1009  0.0832\n",
            "     69       37.1233  0.0866\n",
            "     70       33.2292  0.0832\n",
            "     71       32.8654  0.0865\n",
            "     72       44.8321  0.0843\n",
            "     73       \u001b[36m22.1773\u001b[0m  0.0846\n",
            "     74       39.2434  0.0877\n",
            "     75       36.1569  0.0911\n",
            "     76       36.3957  0.0869\n",
            "     77       \u001b[36m20.8188\u001b[0m  0.0837\n",
            "     78       34.4058  0.0849\n",
            "     79       41.4271  0.0905\n",
            "     80       38.8587  0.0892\n",
            "     81       29.1341  0.0790\n",
            "     82       27.8846  0.0800\n",
            "     83       31.5140  0.0863\n",
            "     84       32.4490  0.0805\n",
            "     85       40.9331  0.0846\n",
            "     86       \u001b[36m19.9470\u001b[0m  0.0865\n",
            "     87       29.9796  0.0873\n",
            "     88       34.6336  0.0799\n",
            "     89       39.4555  0.0820\n",
            "     90       26.8541  0.0914\n",
            "     91       \u001b[36m18.0071\u001b[0m  0.0798\n",
            "     92       29.7181  0.0813\n",
            "     93       42.6269  0.0797\n",
            "     94       25.2069  0.0833\n",
            "     95       26.5277  0.0853\n",
            "     96       24.5680  0.0805\n",
            "     97       37.8315  0.0818\n",
            "     98       37.6368  0.0907\n",
            "     99       24.5763  0.0802\n",
            "    100       22.2655  0.0858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b59ZmYdYnUdG",
        "outputId": "779e7a1e-78f9-4730-b42e-fa5f870089ba"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvvC0QeEnXKS",
        "outputId": "5325875a-c0bb-4213-9822-6f7f843fb077"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.80701754, 0.80701754, 0.66666667, 0.9122807 , 0.80701754,\n",
              "       0.80701754, 0.9122807 , 0.9122807 , 0.8245614 , 0.85714286])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "media = resultados.mean()\n",
        "media"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dy0_aD_pnas0",
        "outputId": "c8cfe9f4-6141-4de7-bd98-b54416afbb54"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8313283208020051"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desvio = resultados.std()\n",
        "desvio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzHqT10FpoZr",
        "outputId": "2cfc618e-2f77-4ac0-cea3-778c9ea787d2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07060422171972054"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adicionando a camada de Dropout"
      ],
      "metadata": {
        "id": "05AngLcN3LPp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class classificador_torch(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # 30 -> 16 -> 16 -> 1\n",
        "    self.dense0 = nn.Linear(30, 16)\n",
        "    torch.nn.init.uniform_(self.dense0.weight)\n",
        "    self.activation0 = nn.ReLU()\n",
        "    self.dropout0 = nn.Dropout(0.2)\n",
        "    self.dense1 = nn.Linear(16, 16)\n",
        "    torch.nn.init.uniform_(self.dense1.weight)\n",
        "    self.activation1 = nn.ReLU()\n",
        "    self.dropout1 = nn.Dropout(0.2)\n",
        "    self.dense2 = nn.Linear(16, 1)\n",
        "    torch.nn.init.uniform_(self.dense2.weight)\n",
        "    # self.output = nn.Sigmoid() \n",
        "\n",
        "  def forward(self, X):\n",
        "    X = self.dense0(X)\n",
        "    X = self.activation0(X)\n",
        "    X = self.dropout0(X)\n",
        "    X = self.dense1(X)\n",
        "    X = self.activation1(X)\n",
        "    X = self.dropout1(X)\n",
        "    X = self.dense2(X)\n",
        "    # X = self.output(X) \n",
        "    return X"
      ],
      "metadata": {
        "id": "IUoAkIYv3R9F"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador_sklearn = NeuralNetBinaryClassifier(module=classificador_torch,\n",
        "                                                  criterion=torch.nn.BCEWithLogitsLoss, # ** ATUALIZAÇÃO **\n",
        "                                                  optimizer=torch.optim.Adam,\n",
        "                                                  lr=0.001,\n",
        "                                                  optimizer__weight_decay=0.0001,\n",
        "                                                  max_epochs=100,\n",
        "                                                  batch_size=10,\n",
        "                                                  train_split=False)"
      ],
      "metadata": {
        "id": "NwXGdVst4pTd"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = cross_val_score(classificador_sklearn, previsores, classe, cv = 10, scoring = 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0ftiiog4r8b",
        "outputId": "3d8c7634-2fb2-401f-b381-fa7a7c55d2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m66583.2662\u001b[0m  0.0889\n",
            "      2    \u001b[36m50180.3124\u001b[0m  0.0904\n",
            "      3    \u001b[36m38177.0126\u001b[0m  0.0884\n",
            "      4    \u001b[36m27919.7162\u001b[0m  0.0889\n",
            "      5    \u001b[36m20249.3896\u001b[0m  0.0899\n",
            "      6    \u001b[36m12721.2728\u001b[0m  0.0876\n",
            "      7     \u001b[36m6711.0621\u001b[0m  0.0912\n",
            "      8     \u001b[36m3574.7294\u001b[0m  0.0952\n",
            "      9     \u001b[36m3523.6403\u001b[0m  0.1061\n",
            "     10     \u001b[36m3210.6631\u001b[0m  0.0881\n",
            "     11     \u001b[36m3102.7053\u001b[0m  0.0848\n",
            "     12     \u001b[36m2516.2270\u001b[0m  0.1022\n",
            "     13     2719.4414  0.1064\n",
            "     14     2577.8773  0.0905\n",
            "     15     \u001b[36m2408.4717\u001b[0m  0.0949\n",
            "     16     \u001b[36m2078.3861\u001b[0m  0.0946\n",
            "     17     \u001b[36m2016.7819\u001b[0m  0.0905\n",
            "     18     \u001b[36m1624.7645\u001b[0m  0.1005\n",
            "     19     1710.2459  0.0928\n",
            "     20     \u001b[36m1573.8037\u001b[0m  0.0980\n",
            "     21     \u001b[36m1477.7375\u001b[0m  0.0932\n",
            "     22     \u001b[36m1435.3963\u001b[0m  0.0914\n",
            "     23     1440.4865  0.0884\n",
            "     24     \u001b[36m1328.5110\u001b[0m  0.0972\n",
            "     25     \u001b[36m1238.5139\u001b[0m  0.0976\n",
            "     26      \u001b[36m966.6223\u001b[0m  0.0966\n",
            "     27      969.9189  0.0892\n",
            "     28      \u001b[36m920.1372\u001b[0m  0.0876\n",
            "     29     1119.0867  0.1002\n",
            "     30      973.2929  0.0975\n",
            "     31      \u001b[36m691.0039\u001b[0m  0.0872\n",
            "     32      705.5551  0.0864\n",
            "     33      737.6329  0.0918\n",
            "     34      \u001b[36m603.9276\u001b[0m  0.0930\n",
            "     35      623.1591  0.0894\n",
            "     36      \u001b[36m527.7990\u001b[0m  0.0954\n",
            "     37      554.7275  0.0994\n",
            "     38      \u001b[36m436.8407\u001b[0m  0.0909\n",
            "     39      \u001b[36m432.7065\u001b[0m  0.0997\n",
            "     40      436.7983  0.0895\n",
            "     41      \u001b[36m425.8064\u001b[0m  0.0906\n",
            "     42      \u001b[36m347.1048\u001b[0m  0.0890\n",
            "     43      401.2494  0.1026\n",
            "     44      \u001b[36m274.7435\u001b[0m  0.0900\n",
            "     45      301.2523  0.0898\n",
            "     46      \u001b[36m273.2035\u001b[0m  0.0915\n",
            "     47      \u001b[36m244.2816\u001b[0m  0.0900\n",
            "     48      246.6882  0.0976\n",
            "     49      \u001b[36m217.0280\u001b[0m  0.0946\n",
            "     50      217.0910  0.1087\n",
            "     51      \u001b[36m199.6823\u001b[0m  0.0886\n",
            "     52      \u001b[36m187.0788\u001b[0m  0.1012\n",
            "     53      \u001b[36m178.0961\u001b[0m  0.0896\n",
            "     54      \u001b[36m171.0267\u001b[0m  0.0924\n",
            "     55      \u001b[36m142.8156\u001b[0m  0.0882\n",
            "     56      154.4295  0.1059\n",
            "     57      \u001b[36m123.9562\u001b[0m  0.0915\n",
            "     58      146.3267  0.0910\n",
            "     59      137.9187  0.0977\n",
            "     60      \u001b[36m115.1066\u001b[0m  0.0920\n",
            "     61      116.9378  0.0997\n",
            "     62       \u001b[36m83.7162\u001b[0m  0.0962\n",
            "     63       90.4678  0.0925\n",
            "     64       95.2720  0.0917\n",
            "     65       \u001b[36m80.4556\u001b[0m  0.0917\n",
            "     66       \u001b[36m74.2872\u001b[0m  0.0894\n",
            "     67       \u001b[36m70.4508\u001b[0m  0.0892\n",
            "     68       74.4966  0.0941\n",
            "     69       \u001b[36m55.6855\u001b[0m  0.0905\n",
            "     70       \u001b[36m54.8056\u001b[0m  0.0883\n",
            "     71       60.8995  0.0911\n",
            "     72       56.1153  0.1053\n",
            "     73       \u001b[36m52.5431\u001b[0m  0.0883\n",
            "     74       \u001b[36m38.9208\u001b[0m  0.1012\n",
            "     75       45.3889  0.0918\n",
            "     76       39.4550  0.0886\n",
            "     77       \u001b[36m37.6581\u001b[0m  0.0888\n",
            "     78       \u001b[36m35.3835\u001b[0m  0.0917\n",
            "     79       35.6170  0.0873\n",
            "     80       \u001b[36m29.8911\u001b[0m  0.0955\n",
            "     81       32.6559  0.0997\n",
            "     82       30.4593  0.0957\n",
            "     83       \u001b[36m24.2839\u001b[0m  0.0850\n",
            "     84       \u001b[36m24.0800\u001b[0m  0.0891\n",
            "     85       29.9488  0.0847\n",
            "     86       \u001b[36m20.3114\u001b[0m  0.0932\n",
            "     87       26.6654  0.0987\n",
            "     88       24.0507  0.0905\n",
            "     89       22.6239  0.0870\n",
            "     90       \u001b[36m20.1415\u001b[0m  0.0913\n",
            "     91       \u001b[36m17.3042\u001b[0m  0.0922\n",
            "     92       \u001b[36m13.3827\u001b[0m  0.0879\n",
            "     93       17.8211  0.1050\n",
            "     94       15.4443  0.0965\n",
            "     95       14.2687  0.0939\n",
            "     96       13.5967  0.0889\n",
            "     97       \u001b[36m11.9937\u001b[0m  0.0863\n",
            "     98        \u001b[36m9.3770\u001b[0m  0.1003\n",
            "     99        \u001b[36m7.6578\u001b[0m  0.0932\n",
            "    100       10.0565  0.0853\n",
            "  epoch    train_loss     dur\n",
            "-------  ------------  ------\n",
            "      1    \u001b[36m60144.1699\u001b[0m  0.0827\n",
            "      2    \u001b[36m46188.1464\u001b[0m  0.0909\n",
            "      3    \u001b[36m33723.5842\u001b[0m  0.0917\n",
            "      4    \u001b[36m22505.3491\u001b[0m  0.0970\n",
            "      5    \u001b[36m13991.8610\u001b[0m  0.0939\n",
            "      6     \u001b[36m6796.7329\u001b[0m  0.0900\n",
            "      7     \u001b[36m3599.6520\u001b[0m  0.0945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "media = resultados.mean()\n",
        "desvio = resultados.std()\n",
        "media, desvio"
      ],
      "metadata": {
        "id": "Oo-7dNLX4uGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados"
      ],
      "metadata": {
        "id": "pvCjaX7D4xhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FNhrofs94zrg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}