{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[ML9] Cross-validation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tvaditya/intro_ds_and_ml/blob/main/%5BML9%5D_Cross_validation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksWyf0umtPGH"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "co9IDgIytZ1c"
      },
      "source": [
        "# Cross-Validation\n",
        "\n",
        "Como eu comentei na última aula, você não pode assumir que o seu modelo está bom apenas olhando os dados de treino e teste.\n",
        "\n",
        "A filosofia que você deve ter na cabeça é que **o primeiro contato de um modelo de machine learning com dados de teste, deve ocorrer apenas na última etapa do processo.**\n",
        "\n",
        "<center><img src=\"https://images.unsplash.com/photo-1507925921958-8a62f3d1a50d?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1055&q=80\"width=\"70%\"></center>\n",
        "\n",
        "Dentre todos os fatores que nos levam a chegar a essa conclusão, estão os fatos que usar datasets de testes para ajustes, levarão a um provável **overfitting** e carregarão um *bias* (viés).\n",
        "\n",
        "Assim, para que você possa aprender os parâmetros de um modelo e preservar os dados de teste, mostrarei a técnica de **cross-validation**, seguindo o fluxograma da documentação oficial do `sklearn`.\n",
        "\n",
        "<center><img alt=\"Colaboratory logo\" width=\"40%\" src=\"https://raw.githubusercontent.com/carlosfab/dsnp2/master/img/grid_search_workflow.png\"></center>\n",
        "\n",
        "Em tempo, veremos em outra aula como determinar os parâmetros do modelo usando uma técnica conhecida como `grid search`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmQVl6ryvnds"
      },
      "source": [
        "# importar os pacotes necessários\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# garantir replicabilidade\n",
        "np.random.seed(42)\n",
        "\n",
        "# importar o arquivo\n",
        "df = pd.read_csv(\"http://dl.dropboxusercontent.com/s/6d91j46mkcdj4qv/heart-disease-clean.csv?dl=1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOotj1ppwhE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "659f2a26-cc21-41ca-f996-df1bb94be7c1"
      },
      "source": [
        "# 1. escolher e importar um modelo\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# 2. Instanciar e escolher os hyperparameters\n",
        "model = LogisticRegression()\n",
        "\n",
        "# 3. Separar os dados entre feature matrix e target vector \n",
        "X = df.drop('num', axis=1)\n",
        "y = df['num']\n",
        "\n",
        "# 3.1 Dividir o dataset entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "# 3.2 Padronizar os dados de treino\n",
        "scaler = StandardScaler().fit(X_train)\n",
        "X_train_transformed = scaler.transform(X_train)\n",
        "\n",
        "# 4. Cross-validation\n",
        "scores = cross_val_score(model, X_train_transformed, y_train, cv=5)\n",
        "\n",
        "print(\"scores: \", scores)\n",
        "print(\"Acurácia: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scores:  [0.80434783 0.84782609 0.82222222 0.84444444 0.86666667]\n",
            "Acurácia: 0.84 (+/- 0.04)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfCPGRCUyxW-"
      },
      "source": [
        "Acima, você pode ver o score médio e o intervalo de confiança de 95%.\n",
        "\n",
        "Por padrão, o score é computado de acordo com o método de score do próprio estimador. No entanto, é possível escolher outra métrica mais alinhada com a realidade do seu dataset.\n",
        "\n",
        "Para conhecer as métricas possíveis, [acesse este link](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q3J2ER0wvU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0debd33-3209-4fb9-dc0f-4ca90301e5a8"
      },
      "source": [
        "scores = cross_val_score(model, X_train_transformed, y_train, cv=5, scoring=\"f1\")\n",
        "print(\"scores: \", scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scores:  [0.79069767 0.82051282 0.78947368 0.78787879 0.85714286]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYmEoRlV055i"
      },
      "source": [
        "Aqui eu quero chamar a atenção para uma coisa. Repare que no primeiro modelo, fizemos a padronização do nosso `X_train_transformed = scaler.transform(X_train)` e somente após usamos a técnica de cross-validation.\n",
        "\n",
        "Vou explicar o motivo dessa não ser uma prática adequada. Veja na imagem abaixo que a cada rodada do nosso k-fold (técnica básica de cross-validation), o subconjunto em azul é deixado como \"teste\". \n",
        "\n",
        "<center><img alt=\"Colaboratory logo\" width=\"40%\" src=\"https://raw.githubusercontent.com/carlosfab/dsnp2/master/img/grid_search_cross_validation.png\"></center>\n",
        "\n",
        "Isso não é ideal, pois queremos simular uma condição onde nosso modelo de machine learning nunca tenha visto esse subconjunto.\n",
        "\n",
        "Essa etapa de padronização ou qualquer outra de pré-processamento, pode ser estruturada com um `pipeline`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN445UErytCH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fbe7981-47a9-4d93-e8a9-72e26a64af38"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "model = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "\n",
        "print(\"scores: \", scores)\n",
        "print(\"Acurácia: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "scores:  [0.80434783 0.84782609 0.82222222 0.84444444 0.86666667]\n",
            "Acurácia: 0.84 (+/- 0.04)\n"
          ]
        }
      ]
    }
  ]
}